{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pm_india_nhs_inform_hi_en_bt.ipynb","provenance":[{"file_id":"1iWMz-yldTsGfGSZrDkz0yYSihmAZk_Ok","timestamp":1631643992412},{"file_id":"1MqnQkcAuLdLxAxq3COya8LUa-CcegGVa","timestamp":1631223860805},{"file_id":"1SQCeu-Pzo-YSUjEf8Y9tIq5rvgRkvYLi","timestamp":1630933562735}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOO0peDfyfgCAxTp0Gmc3PV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Usd4GZry1YOk","executionInfo":{"status":"ok","timestamp":1632137160091,"user_tz":-60,"elapsed":33886,"user":{"displayName":"prathyusha emilya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5IYFecnx3cxca5vOVpF0DuHxaxAztIW-WIhNSRA=s64","userId":"01406194847381075901"}},"outputId":"13c8ecf0-cb38-48a0-e5a7-648c097a6d39"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dg2fa5Ij15sn","executionInfo":{"status":"ok","timestamp":1632137553838,"user_tz":-60,"elapsed":387844,"user":{"displayName":"prathyusha emilya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5IYFecnx3cxca5vOVpF0DuHxaxAztIW-WIhNSRA=s64","userId":"01406194847381075901"}},"outputId":"14d7d2cd-91ec-4659-9f2e-bf7fb33d5ac6"},"source":["# installing necessary applications for \n","!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n","!sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n","!sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n","!sudo add-apt-repository \"deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/\"\n","!sudo apt-get update\n","!sudo apt-get -y install cuda\n","\n","# Install JoeyNMT\n","! git clone https://github.com/may-/joeynmt.git\n","! cd joeynmt; pip3 install .\n","# Install Pytorch with GPU support v1.9.0\n","! pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-09-20 11:26:05--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n","Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n","Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 190 [application/octet-stream]\n","Saving to: ‘cuda-ubuntu1804.pin’\n","\n","\rcuda-ubuntu1804.pin   0%[                    ]       0  --.-KB/s               \rcuda-ubuntu1804.pin 100%[===================>]     190  --.-KB/s    in 0s      \n","\n","2021-09-20 11:26:06 (10.5 MB/s) - ‘cuda-ubuntu1804.pin’ saved [190/190]\n","\n","Executing: /tmp/apt-key-gpghome.tU925R4z3r/gpg.1.sh --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n","gpg: requesting key from 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub'\n","gpg: key F60F4B3D7FA2AF80: \"cudatools <cudatools@nvidia.com>\" not changed\n","gpg: Total number processed: 1\n","gpg:              unchanged: 1\n","Error: 'deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/' invalid\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [67.4 kB]\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:10 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,326 kB]\n","Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,428 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,761 kB]\n","Hit:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,802 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,202 kB]\n","Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [922 kB]\n","Fetched 11.8 MB in 4s (3,180 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  cuda-11-4 cuda-cccl-11-4 cuda-command-line-tools-11-4 cuda-compiler-11-4\n","  cuda-cudart-11-4 cuda-cudart-dev-11-4 cuda-cuobjdump-11-4 cuda-cupti-11-4\n","  cuda-cupti-dev-11-4 cuda-cuxxfilt-11-4 cuda-demo-suite-11-4\n","  cuda-documentation-11-4 cuda-driver-dev-11-4 cuda-gdb-11-4\n","  cuda-libraries-11-4 cuda-libraries-dev-11-4 cuda-memcheck-11-4\n","  cuda-nsight-11-4 cuda-nsight-compute-11-4 cuda-nsight-systems-11-4\n","  cuda-nvcc-11-4 cuda-nvdisasm-11-4 cuda-nvml-dev-11-4 cuda-nvprof-11-4\n","  cuda-nvprune-11-4 cuda-nvrtc-11-4 cuda-nvrtc-dev-11-4 cuda-nvtx-11-4\n","  cuda-nvvp-11-4 cuda-runtime-11-4 cuda-samples-11-4 cuda-sanitizer-11-4\n","  cuda-toolkit-11-4 cuda-toolkit-11-4-config-common\n","  cuda-toolkit-11-config-common cuda-toolkit-config-common cuda-tools-11-4\n","  cuda-visual-tools-11-4 gds-tools-11-4 libcublas-11-4 libcublas-dev-11-4\n","  libcufft-11-4 libcufft-dev-11-4 libcufile-11-4 libcufile-dev-11-4\n","  libcurand-11-4 libcurand-dev-11-4 libcusolver-11-4 libcusolver-dev-11-4\n","  libcusparse-11-4 libcusparse-dev-11-4 libnpp-11-4 libnpp-dev-11-4\n","  libnvjpeg-11-4 libnvjpeg-dev-11-4 liburcu6\n","The following NEW packages will be installed:\n","  cuda cuda-11-4 cuda-cccl-11-4 cuda-command-line-tools-11-4\n","  cuda-compiler-11-4 cuda-cudart-11-4 cuda-cudart-dev-11-4 cuda-cuobjdump-11-4\n","  cuda-cupti-11-4 cuda-cupti-dev-11-4 cuda-cuxxfilt-11-4 cuda-demo-suite-11-4\n","  cuda-documentation-11-4 cuda-driver-dev-11-4 cuda-gdb-11-4\n","  cuda-libraries-11-4 cuda-libraries-dev-11-4 cuda-memcheck-11-4\n","  cuda-nsight-11-4 cuda-nsight-compute-11-4 cuda-nsight-systems-11-4\n","  cuda-nvcc-11-4 cuda-nvdisasm-11-4 cuda-nvml-dev-11-4 cuda-nvprof-11-4\n","  cuda-nvprune-11-4 cuda-nvrtc-11-4 cuda-nvrtc-dev-11-4 cuda-nvtx-11-4\n","  cuda-nvvp-11-4 cuda-runtime-11-4 cuda-samples-11-4 cuda-sanitizer-11-4\n","  cuda-toolkit-11-4 cuda-toolkit-11-4-config-common\n","  cuda-toolkit-11-config-common cuda-toolkit-config-common cuda-tools-11-4\n","  cuda-visual-tools-11-4 gds-tools-11-4 libcublas-11-4 libcublas-dev-11-4\n","  libcufft-11-4 libcufft-dev-11-4 libcufile-11-4 libcufile-dev-11-4\n","  libcurand-11-4 libcurand-dev-11-4 libcusolver-11-4 libcusolver-dev-11-4\n","  libcusparse-11-4 libcusparse-dev-11-4 libnpp-11-4 libnpp-dev-11-4\n","  libnvjpeg-11-4 libnvjpeg-dev-11-4 liburcu6\n","0 upgraded, 57 newly installed, 0 to remove and 56 not upgraded.\n","Need to get 1,678 MB of archives.\n","After this operation, 4,909 MB of additional disk space will be used.\n","Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-toolkit-config-common 11.4.108-1 [16.2 kB]\n","Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-toolkit-11-config-common 11.4.108-1 [16.3 kB]\n","Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-toolkit-11-4-config-common 11.4.108-1 [16.2 kB]\n","Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-11-4 11.4.108-1 [158 kB]\n","Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvrtc-11-4 11.4.120-1 [14.7 MB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 liburcu6 amd64 0.10.1-1ubuntu1 [52.2 kB]\n","Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas-11-4 11.6.1.51-1 [200 MB]\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcufft-11-4 10.5.2.100-1 [80.9 MB]\n","Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcufile-11-4 1.0.2.10-1 [424 kB]\n","Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcurand-11-4 10.2.5.120-1 [39.4 MB]\n","Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusolver-11-4 11.2.0.120-1 [91.2 MB]\n","Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusparse-11-4 11.6.0.120-1 [104 MB]\n","Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnpp-11-4 11.4.0.110-1 [75.5 MB]\n","Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnvjpeg-11-4 11.5.2.120-1 [1,716 kB]\n","Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-libraries-11-4 11.4.2-1 [2,510 B]\n","Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-runtime-11-4 11.4.2-1 [2,420 B]\n","Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cuobjdump-11-4 11.4.120-1 [112 kB]\n","Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cuxxfilt-11-4 11.4.120-1 [180 kB]\n","Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cccl-11-4 11.4.122-1 [985 kB]\n","Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-driver-dev-11-4 11.4.108-1 [26.9 kB]\n","Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-dev-11-4 11.4.108-1 [739 kB]\n","Get:22 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvcc-11-4 11.4.120-1 [36.0 MB]\n","Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvprune-11-4 11.4.120-1 [55.0 kB]\n","Get:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-compiler-11-4 11.4.2-1 [2,424 B]\n","Get:25 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvrtc-dev-11-4 11.4.120-1 [23.8 kB]\n","Get:26 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas-dev-11-4 11.6.1.51-1 [205 MB]\n","Get:27 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcufft-dev-11-4 10.5.2.100-1 [178 MB]\n","Get:28 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcufile-dev-11-4 1.0.2.10-1 [6,779 kB]\n","Get:29 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcurand-dev-11-4 10.2.5.120-1 [39.9 MB]\n","Get:30 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusolver-dev-11-4 11.2.0.120-1 [22.7 MB]\n","Get:31 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusparse-dev-11-4 11.6.0.120-1 [105 MB]\n","Get:32 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnpp-dev-11-4 11.4.0.110-1 [73.5 MB]\n","Get:33 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnvjpeg-dev-11-4 11.5.2.120-1 [1,392 kB]\n","Get:34 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-libraries-dev-11-4 11.4.2-1 [2,540 B]\n","Get:35 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cupti-11-4 11.4.120-1 [12.9 MB]\n","Get:36 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cupti-dev-11-4 11.4.120-1 [2,430 kB]\n","Get:37 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvdisasm-11-4 11.4.120-1 [32.9 MB]\n","Get:38 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-gdb-11-4 11.4.120-1 [4,102 kB]\n","Get:39 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-memcheck-11-4 11.4.120-1 [142 kB]\n","Get:40 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvprof-11-4 11.4.120-1 [1,947 kB]\n","Get:41 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvtx-11-4 11.4.120-1 [51.4 kB]\n","Get:42 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-sanitizer-11-4 11.4.120-1 [7,730 kB]\n","Get:43 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-command-line-tools-11-4 11.4.2-1 [2,470 B]\n","Get:44 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-compute-11-4 11.4.2-1 [3,698 B]\n","Get:45 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-systems-11-4 11.4.2-1 [3,302 B]\n","Get:46 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-11-4 11.4.120-1 [119 MB]\n","Get:47 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvml-dev-11-4 11.4.120-1 [74.9 kB]\n","Get:48 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvvp-11-4 11.4.120-1 [118 MB]\n","Get:49 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-visual-tools-11-4 11.4.2-1 [2,866 B]\n","Get:50 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  gds-tools-11-4 1.0.2.10-1 [38.7 MB]\n","Get:51 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-tools-11-4 11.4.2-1 [2,384 B]\n","Get:52 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-samples-11-4 11.4.120-1 [58.2 MB]\n","Get:53 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-documentation-11-4 11.4.126-1 [49.2 kB]\n","Get:54 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-toolkit-11-4 11.4.2-1 [3,328 B]\n","Get:55 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-demo-suite-11-4 11.4.100-1 [3,987 kB]\n","Get:56 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-11-4 11.4.2-1 [2,448 B]\n","Get:57 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda 11.4.2-1 [2,392 B]\n","Fetched 1,678 MB in 27s (61.6 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 57.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package cuda-toolkit-config-common.\n","(Reading database ... 155013 files and directories currently installed.)\n","Preparing to unpack .../00-cuda-toolkit-config-common_11.4.108-1_all.deb ...\n","Unpacking cuda-toolkit-config-common (11.4.108-1) ...\n","Selecting previously unselected package cuda-toolkit-11-config-common.\n","Preparing to unpack .../01-cuda-toolkit-11-config-common_11.4.108-1_all.deb ...\n","Unpacking cuda-toolkit-11-config-common (11.4.108-1) ...\n","Selecting previously unselected package cuda-toolkit-11-4-config-common.\n","Preparing to unpack .../02-cuda-toolkit-11-4-config-common_11.4.108-1_all.deb ...\n","Unpacking cuda-toolkit-11-4-config-common (11.4.108-1) ...\n","Selecting previously unselected package cuda-cudart-11-4.\n","Preparing to unpack .../03-cuda-cudart-11-4_11.4.108-1_amd64.deb ...\n","Unpacking cuda-cudart-11-4 (11.4.108-1) ...\n","Selecting previously unselected package cuda-nvrtc-11-4.\n","Preparing to unpack .../04-cuda-nvrtc-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-nvrtc-11-4 (11.4.120-1) ...\n","Selecting previously unselected package libcublas-11-4.\n","Preparing to unpack .../05-libcublas-11-4_11.6.1.51-1_amd64.deb ...\n","Unpacking libcublas-11-4 (11.6.1.51-1) ...\n","Selecting previously unselected package libcufft-11-4.\n","Preparing to unpack .../06-libcufft-11-4_10.5.2.100-1_amd64.deb ...\n","Unpacking libcufft-11-4 (10.5.2.100-1) ...\n","Selecting previously unselected package liburcu6:amd64.\n","Preparing to unpack .../07-liburcu6_0.10.1-1ubuntu1_amd64.deb ...\n","Unpacking liburcu6:amd64 (0.10.1-1ubuntu1) ...\n","Selecting previously unselected package libcufile-11-4.\n","Preparing to unpack .../08-libcufile-11-4_1.0.2.10-1_amd64.deb ...\n","Unpacking libcufile-11-4 (1.0.2.10-1) ...\n","Selecting previously unselected package libcurand-11-4.\n","Preparing to unpack .../09-libcurand-11-4_10.2.5.120-1_amd64.deb ...\n","Unpacking libcurand-11-4 (10.2.5.120-1) ...\n","Selecting previously unselected package libcusolver-11-4.\n","Preparing to unpack .../10-libcusolver-11-4_11.2.0.120-1_amd64.deb ...\n","Unpacking libcusolver-11-4 (11.2.0.120-1) ...\n","Selecting previously unselected package libcusparse-11-4.\n","Preparing to unpack .../11-libcusparse-11-4_11.6.0.120-1_amd64.deb ...\n","Unpacking libcusparse-11-4 (11.6.0.120-1) ...\n","Selecting previously unselected package libnpp-11-4.\n","Preparing to unpack .../12-libnpp-11-4_11.4.0.110-1_amd64.deb ...\n","Unpacking libnpp-11-4 (11.4.0.110-1) ...\n","Selecting previously unselected package libnvjpeg-11-4.\n","Preparing to unpack .../13-libnvjpeg-11-4_11.5.2.120-1_amd64.deb ...\n","Unpacking libnvjpeg-11-4 (11.5.2.120-1) ...\n","Selecting previously unselected package cuda-libraries-11-4.\n","Preparing to unpack .../14-cuda-libraries-11-4_11.4.2-1_amd64.deb ...\n","Unpacking cuda-libraries-11-4 (11.4.2-1) ...\n","Selecting previously unselected package cuda-runtime-11-4.\n","Preparing to unpack .../15-cuda-runtime-11-4_11.4.2-1_amd64.deb ...\n","Unpacking cuda-runtime-11-4 (11.4.2-1) ...\n","Selecting previously unselected package cuda-cuobjdump-11-4.\n","Preparing to unpack .../16-cuda-cuobjdump-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-cuobjdump-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-cuxxfilt-11-4.\n","Preparing to unpack .../17-cuda-cuxxfilt-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-cuxxfilt-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-cccl-11-4.\n","Preparing to unpack .../18-cuda-cccl-11-4_11.4.122-1_amd64.deb ...\n","Unpacking cuda-cccl-11-4 (11.4.122-1) ...\n","Selecting previously unselected package cuda-driver-dev-11-4.\n","Preparing to unpack .../19-cuda-driver-dev-11-4_11.4.108-1_amd64.deb ...\n","Unpacking cuda-driver-dev-11-4 (11.4.108-1) ...\n","Selecting previously unselected package cuda-cudart-dev-11-4.\n","Preparing to unpack .../20-cuda-cudart-dev-11-4_11.4.108-1_amd64.deb ...\n","Unpacking cuda-cudart-dev-11-4 (11.4.108-1) ...\n","Selecting previously unselected package cuda-nvcc-11-4.\n","Preparing to unpack .../21-cuda-nvcc-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-nvcc-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-nvprune-11-4.\n","Preparing to unpack .../22-cuda-nvprune-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-nvprune-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-compiler-11-4.\n","Preparing to unpack .../23-cuda-compiler-11-4_11.4.2-1_amd64.deb ...\n","Unpacking cuda-compiler-11-4 (11.4.2-1) ...\n","Selecting previously unselected package cuda-nvrtc-dev-11-4.\n","Preparing to unpack .../24-cuda-nvrtc-dev-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-nvrtc-dev-11-4 (11.4.120-1) ...\n","Selecting previously unselected package libcublas-dev-11-4.\n","Preparing to unpack .../25-libcublas-dev-11-4_11.6.1.51-1_amd64.deb ...\n","Unpacking libcublas-dev-11-4 (11.6.1.51-1) ...\n","Selecting previously unselected package libcufft-dev-11-4.\n","Preparing to unpack .../26-libcufft-dev-11-4_10.5.2.100-1_amd64.deb ...\n","Unpacking libcufft-dev-11-4 (10.5.2.100-1) ...\n","Selecting previously unselected package libcufile-dev-11-4.\n","Preparing to unpack .../27-libcufile-dev-11-4_1.0.2.10-1_amd64.deb ...\n","Unpacking libcufile-dev-11-4 (1.0.2.10-1) ...\n","Selecting previously unselected package libcurand-dev-11-4.\n","Preparing to unpack .../28-libcurand-dev-11-4_10.2.5.120-1_amd64.deb ...\n","Unpacking libcurand-dev-11-4 (10.2.5.120-1) ...\n","Selecting previously unselected package libcusolver-dev-11-4.\n","Preparing to unpack .../29-libcusolver-dev-11-4_11.2.0.120-1_amd64.deb ...\n","Unpacking libcusolver-dev-11-4 (11.2.0.120-1) ...\n","Selecting previously unselected package libcusparse-dev-11-4.\n","Preparing to unpack .../30-libcusparse-dev-11-4_11.6.0.120-1_amd64.deb ...\n","Unpacking libcusparse-dev-11-4 (11.6.0.120-1) ...\n","Selecting previously unselected package libnpp-dev-11-4.\n","Preparing to unpack .../31-libnpp-dev-11-4_11.4.0.110-1_amd64.deb ...\n","Unpacking libnpp-dev-11-4 (11.4.0.110-1) ...\n","Selecting previously unselected package libnvjpeg-dev-11-4.\n","Preparing to unpack .../32-libnvjpeg-dev-11-4_11.5.2.120-1_amd64.deb ...\n","Unpacking libnvjpeg-dev-11-4 (11.5.2.120-1) ...\n","Selecting previously unselected package cuda-libraries-dev-11-4.\n","Preparing to unpack .../33-cuda-libraries-dev-11-4_11.4.2-1_amd64.deb ...\n","Unpacking cuda-libraries-dev-11-4 (11.4.2-1) ...\n","Selecting previously unselected package cuda-cupti-11-4.\n","Preparing to unpack .../34-cuda-cupti-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-cupti-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-cupti-dev-11-4.\n","Preparing to unpack .../35-cuda-cupti-dev-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-cupti-dev-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-nvdisasm-11-4.\n","Preparing to unpack .../36-cuda-nvdisasm-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-nvdisasm-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-gdb-11-4.\n","Preparing to unpack .../37-cuda-gdb-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-gdb-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-memcheck-11-4.\n","Preparing to unpack .../38-cuda-memcheck-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-memcheck-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-nvprof-11-4.\n","Preparing to unpack .../39-cuda-nvprof-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-nvprof-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-nvtx-11-4.\n","Preparing to unpack .../40-cuda-nvtx-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-nvtx-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-sanitizer-11-4.\n","Preparing to unpack .../41-cuda-sanitizer-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-sanitizer-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-command-line-tools-11-4.\n","Preparing to unpack .../42-cuda-command-line-tools-11-4_11.4.2-1_amd64.deb ...\n","Unpacking cuda-command-line-tools-11-4 (11.4.2-1) ...\n","Selecting previously unselected package cuda-nsight-compute-11-4.\n","Preparing to unpack .../43-cuda-nsight-compute-11-4_11.4.2-1_amd64.deb ...\n","Unpacking cuda-nsight-compute-11-4 (11.4.2-1) ...\n","Selecting previously unselected package cuda-nsight-systems-11-4.\n","Preparing to unpack .../44-cuda-nsight-systems-11-4_11.4.2-1_amd64.deb ...\n","Unpacking cuda-nsight-systems-11-4 (11.4.2-1) ...\n","Selecting previously unselected package cuda-nsight-11-4.\n","Preparing to unpack .../45-cuda-nsight-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-nsight-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-nvml-dev-11-4.\n","Preparing to unpack .../46-cuda-nvml-dev-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-nvml-dev-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-nvvp-11-4.\n","Preparing to unpack .../47-cuda-nvvp-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-nvvp-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-visual-tools-11-4.\n","Preparing to unpack .../48-cuda-visual-tools-11-4_11.4.2-1_amd64.deb ...\n","Unpacking cuda-visual-tools-11-4 (11.4.2-1) ...\n","Selecting previously unselected package gds-tools-11-4.\n","Preparing to unpack .../49-gds-tools-11-4_1.0.2.10-1_amd64.deb ...\n","Unpacking gds-tools-11-4 (1.0.2.10-1) ...\n","Selecting previously unselected package cuda-tools-11-4.\n","Preparing to unpack .../50-cuda-tools-11-4_11.4.2-1_amd64.deb ...\n","Unpacking cuda-tools-11-4 (11.4.2-1) ...\n","Selecting previously unselected package cuda-samples-11-4.\n","Preparing to unpack .../51-cuda-samples-11-4_11.4.120-1_amd64.deb ...\n","Unpacking cuda-samples-11-4 (11.4.120-1) ...\n","Selecting previously unselected package cuda-documentation-11-4.\n","Preparing to unpack .../52-cuda-documentation-11-4_11.4.126-1_amd64.deb ...\n","Unpacking cuda-documentation-11-4 (11.4.126-1) ...\n","Selecting previously unselected package cuda-toolkit-11-4.\n","Preparing to unpack .../53-cuda-toolkit-11-4_11.4.2-1_amd64.deb ...\n","Unpacking cuda-toolkit-11-4 (11.4.2-1) ...\n","Selecting previously unselected package cuda-demo-suite-11-4.\n","Preparing to unpack .../54-cuda-demo-suite-11-4_11.4.100-1_amd64.deb ...\n","Unpacking cuda-demo-suite-11-4 (11.4.100-1) ...\n","Selecting previously unselected package cuda-11-4.\n","Preparing to unpack .../55-cuda-11-4_11.4.2-1_amd64.deb ...\n","Unpacking cuda-11-4 (11.4.2-1) ...\n","Selecting previously unselected package cuda.\n","Preparing to unpack .../56-cuda_11.4.2-1_amd64.deb ...\n","Unpacking cuda (11.4.2-1) ...\n","Setting up cuda-cuobjdump-11-4 (11.4.120-1) ...\n","Setting up cuda-nvvp-11-4 (11.4.120-1) ...\n","Setting up cuda-toolkit-config-common (11.4.108-1) ...\n","Setting up cuda-nvml-dev-11-4 (11.4.120-1) ...\n","Setting up cuda-nsight-systems-11-4 (11.4.2-1) ...\n","Setting up cuda-memcheck-11-4 (11.4.120-1) ...\n","Setting up cuda-nvprune-11-4 (11.4.120-1) ...\n","Setting up cuda-nsight-compute-11-4 (11.4.2-1) ...\n","Setting up cuda-cuxxfilt-11-4 (11.4.120-1) ...\n","Setting up gds-tools-11-4 (1.0.2.10-1) ...\n","Setting up cuda-toolkit-11-config-common (11.4.108-1) ...\n","Setting up cuda-sanitizer-11-4 (11.4.120-1) ...\n","Setting up liburcu6:amd64 (0.10.1-1ubuntu1) ...\n","Setting up cuda-cccl-11-4 (11.4.122-1) ...\n","Setting up cuda-nsight-11-4 (11.4.120-1) ...\n","Setting up cuda-toolkit-11-4-config-common (11.4.108-1) ...\n","Setting alternatives\n","update-alternatives: using /usr/local/cuda-11.4 to provide /usr/local/cuda (cuda) in auto mode\n","update-alternatives: using /usr/local/cuda-11.4 to provide /usr/local/cuda-11 (cuda-11) in auto mode\n","Setting up cuda-nvdisasm-11-4 (11.4.120-1) ...\n","Setting up cuda-nvrtc-11-4 (11.4.120-1) ...\n","Setting up cuda-driver-dev-11-4 (11.4.108-1) ...\n","Setting up cuda-nvprof-11-4 (11.4.120-1) ...\n","Setting up cuda-nvtx-11-4 (11.4.120-1) ...\n","Setting up libnpp-11-4 (11.4.0.110-1) ...\n","Setting up cuda-gdb-11-4 (11.4.120-1) ...\n","Setting up libcurand-11-4 (10.2.5.120-1) ...\n","Setting up libcurand-dev-11-4 (10.2.5.120-1) ...\n","Setting up libnvjpeg-11-4 (11.5.2.120-1) ...\n","Setting up cuda-cudart-11-4 (11.4.108-1) ...\n","Setting up cuda-cudart-dev-11-4 (11.4.108-1) ...\n","Setting up libcufft-11-4 (10.5.2.100-1) ...\n","Setting up cuda-nvrtc-dev-11-4 (11.4.120-1) ...\n","Setting up libcusparse-11-4 (11.6.0.120-1) ...\n","Setting up libcublas-11-4 (11.6.1.51-1) ...\n","Setting up libcufile-11-4 (1.0.2.10-1) ...\n","Setting up libcusolver-11-4 (11.2.0.120-1) ...\n","Setting up cuda-nvcc-11-4 (11.4.120-1) ...\n","Setting up libcusolver-dev-11-4 (11.2.0.120-1) ...\n","Setting up cuda-compiler-11-4 (11.4.2-1) ...\n","Setting up libcufile-dev-11-4 (1.0.2.10-1) ...\n","Setting up libnpp-dev-11-4 (11.4.0.110-1) ...\n","Setting up libnvjpeg-dev-11-4 (11.5.2.120-1) ...\n","Setting up libcublas-dev-11-4 (11.6.1.51-1) ...\n","Setting up cuda-cupti-11-4 (11.4.120-1) ...\n","Setting up libcufft-dev-11-4 (10.5.2.100-1) ...\n","Setting up libcusparse-dev-11-4 (11.6.0.120-1) ...\n","Setting up cuda-libraries-11-4 (11.4.2-1) ...\n","Setting up cuda-libraries-dev-11-4 (11.4.2-1) ...\n","Setting up cuda-runtime-11-4 (11.4.2-1) ...\n","Setting up cuda-visual-tools-11-4 (11.4.2-1) ...\n","Setting up cuda-cupti-dev-11-4 (11.4.120-1) ...\n","Setting up cuda-demo-suite-11-4 (11.4.100-1) ...\n","Setting up cuda-samples-11-4 (11.4.120-1) ...\n","Setting up cuda-command-line-tools-11-4 (11.4.2-1) ...\n","Setting up cuda-tools-11-4 (11.4.2-1) ...\n","Setting up cuda-documentation-11-4 (11.4.126-1) ...\n","Setting up cuda-toolkit-11-4 (11.4.2-1) ...\n","Setting alternatives\n","Setting up cuda-11-4 (11.4.2-1) ...\n","Setting up cuda (11.4.2-1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Cloning into 'joeynmt'...\n","remote: Enumerating objects: 3412, done.\u001b[K\n","remote: Counting objects: 100% (461/461), done.\u001b[K\n","remote: Compressing objects: 100% (219/219), done.\u001b[K\n","remote: Total 3412 (delta 283), reused 367 (delta 242), pack-reused 2951\u001b[K\n","Receiving objects: 100% (3412/3412), 12.55 MiB | 24.10 MiB/s, done.\n","Resolving deltas: 100% (2312/2312), done.\n","Processing /content/joeynmt\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (0.16.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (7.1.2)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (1.19.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (57.4.0)\n","Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (1.9.0+cu102)\n","Requirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (2.6.0)\n","Requirement already satisfied: torchtext>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (0.10.0)\n","Collecting sacrebleu>=2.0.0\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 4.9 MB/s \n","\u001b[?25hCollecting subword-nmt\n","  Downloading subword_nmt-0.3.7-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (3.2.2)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (0.11.2)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 71.1 MB/s \n","\u001b[?25hCollecting pylint>=2.9.6\n","  Downloading pylint-2.11.1-py3-none-any.whl (392 kB)\n","\u001b[K     |████████████████████████████████| 392 kB 87.0 MB/s \n","\u001b[?25hCollecting six==1.12\n","  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n","Collecting wrapt==1.11.1\n","  Downloading wrapt-1.11.1.tar.gz (27 kB)\n","Collecting isort<6,>=4.2.5\n","  Downloading isort-5.9.3-py3-none-any.whl (106 kB)\n","\u001b[K     |████████████████████████████████| 106 kB 68.0 MB/s \n","\u001b[?25hCollecting typing-extensions>=3.10.0\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: toml>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pylint>=2.9.6->joeynmt==1.3) (0.10.2)\n","Collecting platformdirs>=2.2.0\n","  Downloading platformdirs-2.3.0-py3-none-any.whl (13 kB)\n","Collecting astroid<2.9,>=2.8.0\n","  Downloading astroid-2.8.0-py3-none-any.whl (242 kB)\n","\u001b[K     |████████████████████████████████| 242 kB 78.1 MB/s \n","\u001b[?25hCollecting mccabe<0.7,>=0.6\n","  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n","Collecting typed-ast<1.5,>=1.4.0\n","  Downloading typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n","\u001b[K     |████████████████████████████████| 743 kB 62.2 MB/s \n","\u001b[?25hCollecting lazy-object-proxy>=1.4.0\n","  Downloading lazy_object_proxy-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 4.9 MB/s \n","\u001b[?25hCollecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=2.0.0->joeynmt==1.3) (2019.12.20)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=2.0.0->joeynmt==1.3) (0.8.9)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (1.8.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (0.6.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (0.4.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (1.40.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (3.3.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (2.23.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (0.12.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (0.37.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (3.17.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.3) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.3) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.3) (4.2.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->joeynmt==1.3) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.15->joeynmt==1.3) (4.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.3) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.3) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.3) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.3) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.3) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->joeynmt==1.3) (3.1.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext>=0.10.0->joeynmt==1.3) (4.62.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=1.15->joeynmt==1.3) (3.5.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt==1.3) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt==1.3) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt==1.3) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt==1.3) (1.3.2)\n","Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn->joeynmt==1.3) (1.1.5)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn->joeynmt==1.3) (1.4.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn->joeynmt==1.3) (2018.9)\n","Building wheels for collected packages: joeynmt, wrapt\n","  Building wheel for joeynmt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for joeynmt: filename=joeynmt-1.3-py3-none-any.whl size=86029 sha256=e3dad1b452969c6929e87588a48aab996339688765ead5504af5e5a5be3c60ad\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-2z_jxb08/wheels/0a/f4/bf/6c9d3b8efbfece6cd209f865be37382b02e7c3584df2e28ca4\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.11.1-cp37-cp37m-linux_x86_64.whl size=68435 sha256=aaa34df85f827e3e3c8a41c0eb0afec3e1f7c84f74f8820a7c9542c217fbdc00\n","  Stored in directory: /root/.cache/pip/wheels/4e/58/9d/da8bad4545585ca52311498ff677647c95c7b690b3040171f8\n","Successfully built joeynmt wrapt\n","Installing collected packages: typing-extensions, six, wrapt, typed-ast, lazy-object-proxy, portalocker, platformdirs, mccabe, isort, colorama, astroid, subword-nmt, sacrebleu, pyyaml, pylint, joeynmt\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 3.7.4.3\n","    Uninstalling typing-extensions-3.7.4.3:\n","      Successfully uninstalled typing-extensions-3.7.4.3\n","  Attempting uninstall: six\n","    Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.12.1\n","    Uninstalling wrapt-1.12.1:\n","      Successfully uninstalled wrapt-1.12.1\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.12.0 which is incompatible.\n","tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\n","tensorflow 2.6.0 requires wrapt~=1.12.1, but you have wrapt 1.11.1 which is incompatible.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.12.0 which is incompatible.\n","google-api-python-client 1.12.8 requires six<2dev,>=1.13.0, but you have six 1.12.0 which is incompatible.\n","google-api-core 1.26.3 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed astroid-2.8.0 colorama-0.4.4 isort-5.9.3 joeynmt-1.3 lazy-object-proxy-1.6.0 mccabe-0.6.1 platformdirs-2.3.0 portalocker-2.3.2 pylint-2.11.1 pyyaml-5.4.1 sacrebleu-2.0.0 six-1.12.0 subword-nmt-0.3.7 typed-ast-1.4.3 typing-extensions-3.10.0.2 wrapt-1.11.1\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.9.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n","\u001b[K     |█████████████                   | 834.1 MB 1.3 MB/s eta 0:15:53tcmalloc: large alloc 1147494400 bytes == 0x55854ea66000 @  0x7f99db35d615 0x5585160144cc 0x5585160f447a 0x5585160172ed 0x558516108e1d 0x55851608ae99 0x5585160859ee 0x558516018bda 0x55851608ad00 0x5585160859ee 0x558516018bda 0x558516087737 0x558516109c66 0x558516086daf 0x558516109c66 0x558516086daf 0x558516109c66 0x558516086daf 0x558516019039 0x55851605c409 0x558516017c52 0x55851608ac25 0x5585160859ee 0x558516018bda 0x558516087737 0x5585160859ee 0x558516018bda 0x558516086915 0x558516018afa 0x558516086c0d 0x5585160859ee\n","\u001b[K     |████████████████▌               | 1055.7 MB 1.3 MB/s eta 0:12:41tcmalloc: large alloc 1434370048 bytes == 0x5585930bc000 @  0x7f99db35d615 0x5585160144cc 0x5585160f447a 0x5585160172ed 0x558516108e1d 0x55851608ae99 0x5585160859ee 0x558516018bda 0x55851608ad00 0x5585160859ee 0x558516018bda 0x558516087737 0x558516109c66 0x558516086daf 0x558516109c66 0x558516086daf 0x558516109c66 0x558516086daf 0x558516019039 0x55851605c409 0x558516017c52 0x55851608ac25 0x5585160859ee 0x558516018bda 0x558516087737 0x5585160859ee 0x558516018bda 0x558516086915 0x558516018afa 0x558516086c0d 0x5585160859ee\n","\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:09:27tcmalloc: large alloc 1792966656 bytes == 0x558517eee000 @  0x7f99db35d615 0x5585160144cc 0x5585160f447a 0x5585160172ed 0x558516108e1d 0x55851608ae99 0x5585160859ee 0x558516018bda 0x55851608ad00 0x5585160859ee 0x558516018bda 0x558516087737 0x558516109c66 0x558516086daf 0x558516109c66 0x558516086daf 0x558516109c66 0x558516086daf 0x558516019039 0x55851605c409 0x558516017c52 0x55851608ac25 0x5585160859ee 0x558516018bda 0x558516087737 0x5585160859ee 0x558516018bda 0x558516086915 0x558516018afa 0x558516086c0d 0x5585160859ee\n","\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.2 MB/s eta 0:04:54tcmalloc: large alloc 2241208320 bytes == 0x558582cd6000 @  0x7f99db35d615 0x5585160144cc 0x5585160f447a 0x5585160172ed 0x558516108e1d 0x55851608ae99 0x5585160859ee 0x558516018bda 0x55851608ad00 0x5585160859ee 0x558516018bda 0x558516087737 0x558516109c66 0x558516086daf 0x558516109c66 0x558516086daf 0x558516109c66 0x558516086daf 0x558516019039 0x55851605c409 0x558516017c52 0x55851608ac25 0x5585160859ee 0x558516018bda 0x558516087737 0x5585160859ee 0x558516018bda 0x558516086915 0x558516018afa 0x558516086c0d 0x5585160859ee\n","\u001b[K     |████████████████████████████████| 2041.3 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0x558608638000 @  0x7f99db35c1e7 0x55851604a067 0x5585160144cc 0x5585160f447a 0x5585160172ed 0x558516108e1d 0x55851608ae99 0x5585160859ee 0x558516018bda 0x558516086c0d 0x5585160859ee 0x558516018bda 0x558516086c0d 0x5585160859ee 0x558516018bda 0x558516086c0d 0x5585160859ee 0x558516018bda 0x558516086c0d 0x5585160859ee 0x558516018bda 0x558516086c0d 0x558516018afa 0x558516086c0d 0x5585160859ee 0x558516018bda 0x558516087737 0x5585160859ee 0x558516018bda 0x558516087737 0x5585160859ee\n","tcmalloc: large alloc 2551685120 bytes == 0x558682100000 @  0x7f99db35d615 0x5585160144cc 0x5585160f447a 0x5585160172ed 0x558516108e1d 0x55851608ae99 0x5585160859ee 0x558516018bda 0x558516086c0d 0x5585160859ee 0x558516018bda 0x558516086c0d 0x5585160859ee 0x558516018bda 0x558516086c0d 0x5585160859ee 0x558516018bda 0x558516086c0d 0x5585160859ee 0x558516018bda 0x558516086c0d 0x558516018afa 0x558516086c0d 0x5585160859ee 0x558516018bda 0x558516087737 0x5585160859ee 0x558516018bda 0x558516087737 0x5585160859ee 0x558516019271\n","\u001b[K     |████████████████████████████████| 2041.3 MB 5.3 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 1.3 MB/s \n","\u001b[?25hCollecting torchaudio==0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (3.10.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.19.5)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.10.0+cu102\n","    Uninstalling torchvision-0.10.0+cu102:\n","      Successfully uninstalled torchvision-0.10.0+cu102\n","Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"]}]},{"cell_type":"code","metadata":{"id":"cvD5XwNo29a6","executionInfo":{"status":"ok","timestamp":1632138166382,"user_tz":-60,"elapsed":565,"user":{"displayName":"prathyusha emilya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5IYFecnx3cxca5vOVpF0DuHxaxAztIW-WIhNSRA=s64","userId":"01406194847381075901"}}},"source":["import os\n","from os import path\n","tag = \"pmi_nhs_backtranslate\"\n","tokenized_data = \"/content/drive/MyDrive/DA/updated_data_tok_files\"\n","src_lang = \"hi\"\n","tgt_lang = \"en\"\n","bpe_operations = 5000\n","bpe_file = \"len_full.bpe.codes.\" + str(bpe_operations)\n","bpe_folder = src_lang + \"_\" + tgt_lang + \"_\" + tag + \"_\" + str(bpe_operations)\n","bpe_data = \"/content/drive/MyDrive/DA/backtranslation\" + bpe_folder\n","\n","os.environ[\"src_lang\"] = src_lang\n","os.environ[\"tgt_lang\"] = tgt_lang\n","os.environ[\"tokenized_data\"] = tokenized_data\n","os.environ[\"bpe_file\"] = bpe_file\n","os.environ[\"bpe_operations\"] = str(bpe_operations)\n","os.environ[\"jnmt_data_path\"] = path.join(\"joeynmt\", \"data\", src_lang + tgt_lang)\n","\n","! mkdir -p $jnmt_data_path\n","! mkdir -p $bpe_data"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"IaRiP-EYr8Qb","executionInfo":{"status":"ok","timestamp":1632137597194,"user_tz":-60,"elapsed":27608,"user":{"displayName":"prathyusha emilya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5IYFecnx3cxca5vOVpF0DuHxaxAztIW-WIhNSRA=s64","userId":"01406194847381075901"}}},"source":["### Learn BPEs on training data\n","from os import path\n","\n","os.environ[\"jnmt_data_path\"] = path.join(\"joeynmt\", \"data\", src_lang + tgt_lang)  \n","! subword-nmt learn-joint-bpe-and-vocab --input $tokenized_data/train_tok.$src_lang $tokenized_data/train_tok.$tgt_lang -s $bpe_operations -o $bpe_file --write-vocabulary vocab.$src_lang vocab.$tgt_lang\n","\n","# Apply BPE splits to the development and test data.\n","! subword-nmt apply-bpe -c $bpe_file --vocabulary vocab.$src_lang < $tokenized_data/train_tok.$src_lang > train.bpe.$src_lang\n","! subword-nmt apply-bpe -c $bpe_file --vocabulary vocab.$tgt_lang < $tokenized_data/train_tok.$tgt_lang > train.bpe.$tgt_lang\n","\n","! subword-nmt apply-bpe -c $bpe_file --vocabulary vocab.$src_lang < $tokenized_data/dev_tok.$src_lang > dev.bpe.$src_lang\n","! subword-nmt apply-bpe -c $bpe_file --vocabulary vocab.$tgt_lang < $tokenized_data/dev_tok.$tgt_lang > dev.bpe.$tgt_lang\n","\n","\n","! subword-nmt apply-bpe -c $bpe_file --vocabulary vocab.$src_lang < $tokenized_data/test_tok.$src_lang > test.bpe.$src_lang\n","! subword-nmt apply-bpe -c $bpe_file --vocabulary vocab.$tgt_lang < $tokenized_data/test_tok.$tgt_lang > test.bpe.$tgt_lang\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"zGFCjAabuKUW","executionInfo":{"status":"ok","timestamp":1632138170723,"user_tz":-60,"elapsed":600,"user":{"displayName":"prathyusha emilya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5IYFecnx3cxca5vOVpF0DuHxaxAztIW-WIhNSRA=s64","userId":"01406194847381075901"}}},"source":["!cp *.bpe.* $jnmt_data_path\n","\n","!cp *.bpe.* $bpe_data"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"uwXc3J_QjOJC","executionInfo":{"status":"ok","timestamp":1632138174991,"user_tz":-60,"elapsed":588,"user":{"displayName":"prathyusha emilya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5IYFecnx3cxca5vOVpF0DuHxaxAztIW-WIhNSRA=s64","userId":"01406194847381075901"}}},"source":["!mkdir -p $bpe_data/model_data\n","!cp /content/joeynmt/data/hien/* $bpe_data/model_data\n","!cp *vocab* $bpe_data/model_data"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"LMbak6lC6B8x","executionInfo":{"status":"ok","timestamp":1632137626990,"user_tz":-60,"elapsed":1539,"user":{"displayName":"prathyusha emilya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5IYFecnx3cxca5vOVpF0DuHxaxAztIW-WIhNSRA=s64","userId":"01406194847381075901"}}},"source":["# # Create that vocab using build_vocab\n","! sudo chmod 777 joeynmt/scripts/build_vocab.py\n","! joeynmt/scripts/build_vocab.py $jnmt_data_path/train.bpe.$src_lang $jnmt_data_path/train.bpe.$tgt_lang --output_path $jnmt_data_path/vocab.txt"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wXA4TKeL_Dfw","executionInfo":{"status":"ok","timestamp":1632138185813,"user_tz":-60,"elapsed":564,"user":{"displayName":"prathyusha emilya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5IYFecnx3cxca5vOVpF0DuHxaxAztIW-WIhNSRA=s64","userId":"01406194847381075901"}},"outputId":"b5ad2edb-0850-4a7e-d4b6-adbf3f59a116"},"source":["!cp $jnmt_data_path/vocab.txt  $bpe_data/model_data\n","!ls $bpe_data/model_data"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["dev.bpe.en  len_full.bpe.codes.5000  test.bpe.hi   train.bpe.hi  vocab.hi\n","dev.bpe.hi  test.bpe.en\t\t     train.bpe.en  vocab.en\t vocab.txt\n"]}]},{"cell_type":"code","metadata":{"id":"p7mNVQRJ6X4z"},"source":["model_type = \"bpe\"\n","use_cuda = True\n","\n","# Create the Joey NMT config file\n","\n","config = \"\"\"\n","name: \"{name}_transformer\"\n","\n","data:\n","    src: \"{src_lang}\"\n","    trg: \"{tgt_lang}\"\n","    train: \"data/{name}/train.{model_type}\"\n","    dev:   \"data/{name}/dev.{model_type}\"\n","    test:   \"data/{name}/test.{model_type}\"\n","    level: \"{model_type}\"\n","    lowercase: False\n","    max_sent_length: 60\n","    src_vocab: \"data/{name}/vocab.txt\"\n","    trg_vocab: \"data/{name}/vocab.txt\"\n","\n","testing:\n","    beam_size: 5\n","    alpha: 1.0\n","\n","training:\n","    random_seed: 42\n","    optimizer: \"adam\"\n","    normalization: \"tokens\"\n","    adam_betas: [0.9, 0.999] \n","    scheduling: \"plateau\"           # TODO: try switching from plateau to Noam scheduling\n","    patience: 5                     # For plateau: decrease learning rate by decrease_factor if validation score has not improved for this many validation rounds.\n","    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n","    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n","    decrease_factor: 0.7\n","    loss: \"crossentropy\"\n","    learning_rate: 0.0003\n","    learning_rate_min: 0.00000001\n","    weight_decay: 0.0\n","    label_smoothing: 0.1\n","    batch_size: 4096\n","    batch_type: \"token\"\n","    eval_batch_size: 3600\n","    eval_batch_type: \"token\"\n","    batch_multiplier: 1\n","    early_stopping_metric: \"ppl\"\n","    epochs: 100                     # TODO: Decrease for when playing around and checking of working. Around 30 is sufficient to check if its working at all\n","    validation_freq: 1000          # TODO: Set to at least once per epoch.\n","    logging_freq: 100\n","    eval_metric: \"bleu\"\n","    model_dir: \"models/{name}_transformer_{tag}\"\n","    overwrite: True               # TODO: Set to True if you want to overwrite possibly existing models. \n","    shuffle: True\n","    use_cuda: {use_cuda}\n","    max_output_length: 130\n","    print_valid_sents: [0, 1, 2, 3]\n","    keep_best_ckpts: 3\n","    \n","model:\n","    initializer: \"xavier\"\n","    bias_initializer: \"zeros\"\n","    init_gain: 1.0\n","    embed_initializer: \"xavier\"\n","    embed_init_gain: 1.0\n","    tied_embeddings: True\n","    tied_softmax: True\n","    encoder:\n","        type: \"transformer\"\n","        num_layers: 6\n","        num_heads: 4             # TODO: Increase to 8 for larger data.\n","        embeddings:\n","            embedding_dim: 256   # TODO: Increase to 512 for larger data.\n","            scale: True\n","            dropout: 0.2\n","        # typically ff_size = 4 x hidden_size\n","        hidden_size: 256         # TODO: Increase to 512 for larger data.\n","        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n","        dropout: 0.3\n","    decoder:\n","        type: \"transformer\"\n","        num_layers: 6\n","        num_heads: 4              # TODO: Increase to 8 for larger data.\n","        embeddings:\n","            embedding_dim: 256    # TODO: Increase to 512 for larger data.\n","            scale: True\n","            dropout: 0.2\n","        # typically ff_size = 4 x hidden_size\n","        hidden_size: 256         # TODO: Increase to 512 for larger data.\n","        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n","        dropout: 0.3\n","\"\"\".format(name = src_lang + tgt_lang, src_lang = src_lang, tgt_lang = tgt_lang, model_type = model_type,  use_cuda = use_cuda, tag = tag)\n","with open(\"joeynmt/configs/transformer_{name}.yaml\".format(name = src_lang+tgt_lang), 'w') as f:\n","    f.write(config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VBBPS77FAzaP","executionInfo":{"status":"ok","timestamp":1632123550251,"user_tz":-60,"elapsed":3484,"user":{"displayName":"prathyusha emilya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5IYFecnx3cxca5vOVpF0DuHxaxAztIW-WIhNSRA=s64","userId":"01406194847381075901"}},"outputId":"34e10040-9499-42f0-86ea-bef677c650f4"},"source":["! pip install --upgrade sacrebleu==2.0.0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sacrebleu==2.0.0 in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu==2.0.0) (0.4.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu==2.0.0) (1.19.5)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu==2.0.0) (0.8.9)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu==2.0.0) (2.3.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu==2.0.0) (2019.12.20)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZqfGFNI6h62","executionInfo":{"status":"ok","timestamp":1632134210131,"user_tz":-60,"elapsed":10659886,"user":{"displayName":"prathyusha emilya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5IYFecnx3cxca5vOVpF0DuHxaxAztIW-WIhNSRA=s64","userId":"01406194847381075901"}},"outputId":"f561f13b-c19b-450e-cc0f-017a88f4efb9"},"source":["# Train the model\n","!cd joeynmt; python3 -m joeynmt train configs/transformer_$src_lang$tgt_lang.yaml"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-09-20 07:39:11,798 - INFO - root - Hello! This is Joey-NMT (version 1.3).\n","2021-09-20 07:39:11,856 - INFO - joeynmt.data - Loading training data...\n","2021-09-20 07:39:12,964 - INFO - joeynmt.data - Building vocabulary...\n","2021-09-20 07:39:13,419 - INFO - joeynmt.data - Loading dev data...\n","2021-09-20 07:39:13,428 - INFO - joeynmt.data - Loading test data...\n","2021-09-20 07:39:13,435 - INFO - joeynmt.data - Data loaded.\n","2021-09-20 07:39:13,435 - INFO - joeynmt.model - Building an encoder-decoder model...\n","2021-09-20 07:39:13,671 - INFO - joeynmt.model - Enc-dec model built.\n","2021-09-20 07:39:16,133 - INFO - joeynmt.training - Total params: 12422400\n","2021-09-20 07:39:21,358 - INFO - joeynmt.helpers - cfg.name                           : hien_transformer\n","2021-09-20 07:39:21,358 - INFO - joeynmt.helpers - cfg.data.src                       : hi\n","2021-09-20 07:39:21,358 - INFO - joeynmt.helpers - cfg.data.trg                       : en\n","2021-09-20 07:39:21,358 - INFO - joeynmt.helpers - cfg.data.train                     : data/hien/train.bpe\n","2021-09-20 07:39:21,359 - INFO - joeynmt.helpers - cfg.data.dev                       : data/hien/dev.bpe\n","2021-09-20 07:39:21,359 - INFO - joeynmt.helpers - cfg.data.test                      : data/hien/test.bpe\n","2021-09-20 07:39:21,359 - INFO - joeynmt.helpers - cfg.data.level                     : bpe\n","2021-09-20 07:39:21,359 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False\n","2021-09-20 07:39:21,359 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 60\n","2021-09-20 07:39:21,360 - INFO - joeynmt.helpers - cfg.data.src_vocab                 : data/hien/vocab.txt\n","2021-09-20 07:39:21,360 - INFO - joeynmt.helpers - cfg.data.trg_vocab                 : data/hien/vocab.txt\n","2021-09-20 07:39:21,360 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5\n","2021-09-20 07:39:21,360 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0\n","2021-09-20 07:39:21,360 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42\n","2021-09-20 07:39:21,360 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam\n","2021-09-20 07:39:21,360 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens\n","2021-09-20 07:39:21,361 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]\n","2021-09-20 07:39:21,361 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau\n","2021-09-20 07:39:21,361 - INFO - joeynmt.helpers - cfg.training.patience              : 5\n","2021-09-20 07:39:21,361 - INFO - joeynmt.helpers - cfg.training.learning_rate_factor  : 0.5\n","2021-09-20 07:39:21,361 - INFO - joeynmt.helpers - cfg.training.learning_rate_warmup  : 1000\n","2021-09-20 07:39:21,361 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7\n","2021-09-20 07:39:21,361 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy\n","2021-09-20 07:39:21,361 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0003\n","2021-09-20 07:39:21,362 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08\n","2021-09-20 07:39:21,362 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0\n","2021-09-20 07:39:21,362 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.1\n","2021-09-20 07:39:21,362 - INFO - joeynmt.helpers - cfg.training.batch_size            : 4096\n","2021-09-20 07:39:21,362 - INFO - joeynmt.helpers - cfg.training.batch_type            : token\n","2021-09-20 07:39:21,362 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 3600\n","2021-09-20 07:39:21,362 - INFO - joeynmt.helpers - cfg.training.eval_batch_type       : token\n","2021-09-20 07:39:21,362 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1\n","2021-09-20 07:39:21,363 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl\n","2021-09-20 07:39:21,363 - INFO - joeynmt.helpers - cfg.training.epochs                : 100\n","2021-09-20 07:39:21,363 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 1000\n","2021-09-20 07:39:21,363 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 100\n","2021-09-20 07:39:21,363 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu\n","2021-09-20 07:39:21,363 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/hien_transformer_pmi_nhs_backtranslate\n","2021-09-20 07:39:21,363 - INFO - joeynmt.helpers - cfg.training.overwrite             : True\n","2021-09-20 07:39:21,364 - INFO - joeynmt.helpers - cfg.training.shuffle               : True\n","2021-09-20 07:39:21,364 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True\n","2021-09-20 07:39:21,364 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 130\n","2021-09-20 07:39:21,364 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3]\n","2021-09-20 07:39:21,364 - INFO - joeynmt.helpers - cfg.training.keep_best_ckpts       : 3\n","2021-09-20 07:39:21,364 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier\n","2021-09-20 07:39:21,364 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros\n","2021-09-20 07:39:21,365 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0\n","2021-09-20 07:39:21,365 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier\n","2021-09-20 07:39:21,365 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0\n","2021-09-20 07:39:21,365 - INFO - joeynmt.helpers - cfg.model.tied_embeddings          : True\n","2021-09-20 07:39:21,365 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True\n","2021-09-20 07:39:21,365 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer\n","2021-09-20 07:39:21,365 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6\n","2021-09-20 07:39:21,365 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 4\n","2021-09-20 07:39:21,366 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256\n","2021-09-20 07:39:21,366 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True\n","2021-09-20 07:39:21,366 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.2\n","2021-09-20 07:39:21,366 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 256\n","2021-09-20 07:39:21,366 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 1024\n","2021-09-20 07:39:21,366 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.3\n","2021-09-20 07:39:21,366 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer\n","2021-09-20 07:39:21,366 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6\n","2021-09-20 07:39:21,366 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 4\n","2021-09-20 07:39:21,366 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256\n","2021-09-20 07:39:21,366 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True\n","2021-09-20 07:39:21,366 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.2\n","2021-09-20 07:39:21,367 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 256\n","2021-09-20 07:39:21,367 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 1024\n","2021-09-20 07:39:21,367 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.3\n","2021-09-20 07:39:21,367 - INFO - joeynmt.helpers - Data set sizes: \n","\ttrain 50186,\n","\tvalid 502,\n","\ttest 597\n","2021-09-20 07:39:21,367 - INFO - joeynmt.helpers - First training example:\n","\t[SRC] उन्होंने गं@@ भी@@ र भारत - फ्रांस रक्षा तथा सुरक्षा सहयोग के प्रति अपनी प्रतिबद्धता व्यक्त की और इस वर्ष फ्रांस में प्रधानमंत्री की अग@@ व@@ ानी करने की आशा व्यक्त की ।\n","\t[TRG] He under@@ lin@@ ed his commitment to deep@@ en India-@@ France defence and security cooperation and loo@@ ked forward to recei@@ ving Prime Minister in France this year .\n","2021-09-20 07:39:21,367 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) the (6) के (7) . (8) । (9) of\n","2021-09-20 07:39:21,367 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) the (6) के (7) . (8) । (9) of\n","2021-09-20 07:39:21,367 - INFO - joeynmt.helpers - Number of Src words (types): 5321\n","2021-09-20 07:39:21,368 - INFO - joeynmt.helpers - Number of Trg words (types): 5321\n","2021-09-20 07:39:21,368 - INFO - joeynmt.training - Model(\n","\tencoder=TransformerEncoder(num_layers=6, num_heads=4),\n","\tdecoder=TransformerDecoder(num_layers=6, num_heads=4),\n","\tsrc_embed=Embeddings(embedding_dim=256, vocab_size=5321),\n","\ttrg_embed=Embeddings(embedding_dim=256, vocab_size=5321))\n","2021-09-20 07:39:21,375 - INFO - joeynmt.training - Train stats:\n","\tdevice: cuda\n","\tn_gpu: 1\n","\t16-bits training: False\n","\tgradient accumulation: 1\n","\tbatch size per device: 4096\n","\ttotal batch size (w. parallel & accumulation): 4096\n","2021-09-20 07:39:21,375 - INFO - joeynmt.training - EPOCH 1\n","2021-09-20 07:39:34,944 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     5.587875, Tokens per Sec:    14529, Lr: 0.000300\n","2021-09-20 07:39:48,202 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     5.397071, Tokens per Sec:    15033, Lr: 0.000300\n","2021-09-20 07:40:01,586 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     5.064082, Tokens per Sec:    14652, Lr: 0.000300\n","2021-09-20 07:40:14,931 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     4.868088, Tokens per Sec:    14803, Lr: 0.000300\n","2021-09-20 07:40:28,346 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     4.859990, Tokens per Sec:    14873, Lr: 0.000300\n","2021-09-20 07:40:41,709 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     4.630922, Tokens per Sec:    14700, Lr: 0.000300\n","2021-09-20 07:40:55,182 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     4.608978, Tokens per Sec:    14668, Lr: 0.000300\n","2021-09-20 07:40:59,078 - INFO - joeynmt.training - Epoch   1: total training loss 3715.55\n","2021-09-20 07:40:59,078 - INFO - joeynmt.training - EPOCH 2\n","2021-09-20 07:41:08,502 - INFO - joeynmt.training - Epoch   2, Step:      800, Batch Loss:     4.426448, Tokens per Sec:    14740, Lr: 0.000300\n","2021-09-20 07:41:21,870 - INFO - joeynmt.training - Epoch   2, Step:      900, Batch Loss:     4.287018, Tokens per Sec:    14685, Lr: 0.000300\n","2021-09-20 07:41:35,349 - INFO - joeynmt.training - Epoch   2, Step:     1000, Batch Loss:     4.188725, Tokens per Sec:    14639, Lr: 0.000300\n","2021-09-20 07:42:00,553 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 07:42:00,553 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 07:42:00,554 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 07:42:00,558 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 07:42:00,902 - INFO - joeynmt.training - Example #0\n","2021-09-20 07:42:00,904 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 07:42:00,904 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 07:42:00,904 - INFO - joeynmt.training - \tHypothesis: The MoU will be a new years of the Government of the Government of the Government of the Government of the Government of the Government of the Government of the Government of the Government .\n","2021-09-20 07:42:00,904 - INFO - joeynmt.training - Example #1\n","2021-09-20 07:42:00,905 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 07:42:00,905 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 07:42:00,905 - INFO - joeynmt.training - \tHypothesis: We have not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not\n","2021-09-20 07:42:00,905 - INFO - joeynmt.training - Example #2\n","2021-09-20 07:42:00,905 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 07:42:00,905 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 07:42:00,905 - INFO - joeynmt.training - \tHypothesis: The MoU will be a cooperation in the field of the field of the field of the field of the field of the field of the field of the field of the field of the field of the field of the field .\n","2021-09-20 07:42:00,905 - INFO - joeynmt.training - Example #3\n","2021-09-20 07:42:00,906 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 07:42:00,906 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 07:42:00,906 - INFO - joeynmt.training - \tHypothesis: I am am to the people of the world of the world .\n","2021-09-20 07:42:00,906 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     1000: bleu:   2.80, loss: 64276.7656, ppl:  68.9561, duration: 25.5568s\n","2021-09-20 07:42:14,280 - INFO - joeynmt.training - Epoch   2, Step:     1100, Batch Loss:     4.188271, Tokens per Sec:    14700, Lr: 0.000300\n","2021-09-20 07:42:27,693 - INFO - joeynmt.training - Epoch   2, Step:     1200, Batch Loss:     4.200116, Tokens per Sec:    14683, Lr: 0.000300\n","2021-09-20 07:42:41,236 - INFO - joeynmt.training - Epoch   2, Step:     1300, Batch Loss:     4.153698, Tokens per Sec:    14663, Lr: 0.000300\n","2021-09-20 07:42:54,787 - INFO - joeynmt.training - Epoch   2, Step:     1400, Batch Loss:     3.894840, Tokens per Sec:    14696, Lr: 0.000300\n","2021-09-20 07:43:02,789 - INFO - joeynmt.training - Epoch   2: total training loss 3080.50\n","2021-09-20 07:43:02,790 - INFO - joeynmt.training - EPOCH 3\n","2021-09-20 07:43:08,186 - INFO - joeynmt.training - Epoch   3, Step:     1500, Batch Loss:     4.093223, Tokens per Sec:    14756, Lr: 0.000300\n","2021-09-20 07:43:21,528 - INFO - joeynmt.training - Epoch   3, Step:     1600, Batch Loss:     3.866679, Tokens per Sec:    14889, Lr: 0.000300\n","2021-09-20 07:43:34,917 - INFO - joeynmt.training - Epoch   3, Step:     1700, Batch Loss:     3.919911, Tokens per Sec:    14753, Lr: 0.000300\n","2021-09-20 07:43:48,209 - INFO - joeynmt.training - Epoch   3, Step:     1800, Batch Loss:     3.858889, Tokens per Sec:    14811, Lr: 0.000300\n","2021-09-20 07:44:01,752 - INFO - joeynmt.training - Epoch   3, Step:     1900, Batch Loss:     3.586905, Tokens per Sec:    14508, Lr: 0.000300\n","2021-09-20 07:44:15,250 - INFO - joeynmt.training - Epoch   3, Step:     2000, Batch Loss:     3.666542, Tokens per Sec:    14680, Lr: 0.000300\n","2021-09-20 07:44:40,159 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 07:44:40,159 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 07:44:40,159 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 07:44:40,163 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 07:44:40,490 - INFO - joeynmt.training - Example #0\n","2021-09-20 07:44:40,490 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 07:44:40,490 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 07:44:40,490 - INFO - joeynmt.training - \tHypothesis: • The total of the last years of the last years of the last years of the last years of the last years .\n","2021-09-20 07:44:40,490 - INFO - joeynmt.training - Example #1\n","2021-09-20 07:44:40,491 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 07:44:40,491 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 07:44:40,491 - INFO - joeynmt.training - \tHypothesis: It is not not not not not not not not not not not not not not not only to our society , but not not not not not not not not not not not not only .\n","2021-09-20 07:44:40,491 - INFO - joeynmt.training - Example #2\n","2021-09-20 07:44:40,491 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 07:44:40,491 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 07:44:40,491 - INFO - joeynmt.training - \tHypothesis: • The cooperation between the field of the field of cooperation in the field of the field of cooperation .\n","2021-09-20 07:44:40,491 - INFO - joeynmt.training - Example #3\n","2021-09-20 07:44:40,491 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 07:44:40,491 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 07:44:40,492 - INFO - joeynmt.training - \tHypothesis: I am happy to see our commitment to our relationship .\n","2021-09-20 07:44:40,492 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     2000: bleu:   3.91, loss: 55564.6797, ppl:  38.8483, duration: 25.2408s\n","2021-09-20 07:44:54,054 - INFO - joeynmt.training - Epoch   3, Step:     2100, Batch Loss:     3.673752, Tokens per Sec:    14523, Lr: 0.000300\n","2021-09-20 07:45:06,131 - INFO - joeynmt.training - Epoch   3: total training loss 2779.13\n","2021-09-20 07:45:06,131 - INFO - joeynmt.training - EPOCH 4\n","2021-09-20 07:45:07,566 - INFO - joeynmt.training - Epoch   4, Step:     2200, Batch Loss:     3.685321, Tokens per Sec:    13876, Lr: 0.000300\n","2021-09-20 07:45:21,181 - INFO - joeynmt.training - Epoch   4, Step:     2300, Batch Loss:     3.587348, Tokens per Sec:    14479, Lr: 0.000300\n","2021-09-20 07:45:34,419 - INFO - joeynmt.training - Epoch   4, Step:     2400, Batch Loss:     3.598382, Tokens per Sec:    14912, Lr: 0.000300\n","2021-09-20 07:45:47,862 - INFO - joeynmt.training - Epoch   4, Step:     2500, Batch Loss:     3.617894, Tokens per Sec:    14733, Lr: 0.000300\n","2021-09-20 07:46:01,217 - INFO - joeynmt.training - Epoch   4, Step:     2600, Batch Loss:     3.583740, Tokens per Sec:    14760, Lr: 0.000300\n","2021-09-20 07:46:14,679 - INFO - joeynmt.training - Epoch   4, Step:     2700, Batch Loss:     3.434261, Tokens per Sec:    14635, Lr: 0.000300\n","2021-09-20 07:46:27,986 - INFO - joeynmt.training - Epoch   4, Step:     2800, Batch Loss:     3.487546, Tokens per Sec:    14858, Lr: 0.000300\n","2021-09-20 07:46:41,565 - INFO - joeynmt.training - Epoch   4, Step:     2900, Batch Loss:     3.211305, Tokens per Sec:    14479, Lr: 0.000300\n","2021-09-20 07:46:44,349 - INFO - joeynmt.training - Epoch   4: total training loss 2569.16\n","2021-09-20 07:46:44,350 - INFO - joeynmt.training - EPOCH 5\n","2021-09-20 07:46:54,928 - INFO - joeynmt.training - Epoch   5, Step:     3000, Batch Loss:     3.268065, Tokens per Sec:    14818, Lr: 0.000300\n","2021-09-20 07:47:11,158 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 07:47:11,159 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 07:47:11,159 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 07:47:11,162 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 07:47:11,513 - INFO - joeynmt.training - Example #0\n","2021-09-20 07:47:11,514 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 07:47:11,514 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 07:47:11,514 - INFO - joeynmt.training - \tHypothesis: The total of Rs. 45 crore will be given to be given to Rs. 25.0...........\n","2021-09-20 07:47:11,514 - INFO - joeynmt.training - Example #1\n","2021-09-20 07:47:11,514 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 07:47:11,514 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 07:47:11,514 - INFO - joeynmt.training - \tHypothesis: We are not only only only only only only only only the same , but we have to be a way that the biggest biggest back of our backage .\n","2021-09-20 07:47:11,515 - INFO - joeynmt.training - Example #2\n","2021-09-20 07:47:11,515 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 07:47:11,515 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 07:47:11,515 - INFO - joeynmt.training - \tHypothesis: . The exchange of cooperation in the field of technology\n","2021-09-20 07:47:11,515 - INFO - joeynmt.training - Example #3\n","2021-09-20 07:47:11,515 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 07:47:11,515 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 07:47:11,516 - INFO - joeynmt.training - \tHypothesis: I also also also congratulate the importance of our cultural heritage .\n","2021-09-20 07:47:11,516 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step     3000: bleu:   6.70, loss: 49832.8008, ppl:  26.6328, duration: 16.5869s\n","2021-09-20 07:47:25,115 - INFO - joeynmt.training - Epoch   5, Step:     3100, Batch Loss:     3.255131, Tokens per Sec:    14521, Lr: 0.000300\n","2021-09-20 07:47:38,501 - INFO - joeynmt.training - Epoch   5, Step:     3200, Batch Loss:     3.314039, Tokens per Sec:    14758, Lr: 0.000300\n","2021-09-20 07:47:51,938 - INFO - joeynmt.training - Epoch   5, Step:     3300, Batch Loss:     3.305472, Tokens per Sec:    14724, Lr: 0.000300\n","2021-09-20 07:48:05,640 - INFO - joeynmt.training - Epoch   5, Step:     3400, Batch Loss:     3.431413, Tokens per Sec:    14407, Lr: 0.000300\n","2021-09-20 07:48:19,103 - INFO - joeynmt.training - Epoch   5, Step:     3500, Batch Loss:     3.314341, Tokens per Sec:    14759, Lr: 0.000300\n","2021-09-20 07:48:32,550 - INFO - joeynmt.training - Epoch   5, Step:     3600, Batch Loss:     3.152880, Tokens per Sec:    14662, Lr: 0.000300\n","2021-09-20 07:48:39,285 - INFO - joeynmt.training - Epoch   5: total training loss 2408.74\n","2021-09-20 07:48:39,285 - INFO - joeynmt.training - EPOCH 6\n","2021-09-20 07:48:45,993 - INFO - joeynmt.training - Epoch   6, Step:     3700, Batch Loss:     3.238301, Tokens per Sec:    14351, Lr: 0.000300\n","2021-09-20 07:48:59,442 - INFO - joeynmt.training - Epoch   6, Step:     3800, Batch Loss:     3.034274, Tokens per Sec:    14599, Lr: 0.000300\n","2021-09-20 07:49:13,033 - INFO - joeynmt.training - Epoch   6, Step:     3900, Batch Loss:     3.184274, Tokens per Sec:    14584, Lr: 0.000300\n","2021-09-20 07:49:26,579 - INFO - joeynmt.training - Epoch   6, Step:     4000, Batch Loss:     3.348243, Tokens per Sec:    14638, Lr: 0.000300\n","2021-09-20 07:49:40,761 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 07:49:40,761 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 07:49:40,762 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 07:49:40,767 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 07:49:41,143 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/1000.ckpt\n","2021-09-20 07:49:41,162 - INFO - joeynmt.training - Example #0\n","2021-09-20 07:49:41,162 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 07:49:41,162 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 07:49:41,163 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 5.0.............\n","2021-09-20 07:49:41,163 - INFO - joeynmt.training - Example #1\n","2021-09-20 07:49:41,163 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 07:49:41,163 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 07:49:41,163 - INFO - joeynmt.training - \tHypothesis: These are not only , we are not only that we are not only in the same way , we are not able to do not only our own own , but we can be able .\n","2021-09-20 07:49:41,163 - INFO - joeynmt.training - Example #2\n","2021-09-20 07:49:41,163 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 07:49:41,164 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 07:49:41,164 - INFO - joeynmt.training - \tHypothesis: 3 . To exchange of cooperation in the field of human resources\n","2021-09-20 07:49:41,164 - INFO - joeynmt.training - Example #3\n","2021-09-20 07:49:41,164 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 07:49:41,164 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 07:49:41,164 - INFO - joeynmt.training - \tHypothesis: I also wish to see our cultural heritage .\n","2021-09-20 07:49:41,164 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step     4000: bleu:   9.26, loss: 46200.2070, ppl:  20.9658, duration: 14.5847s\n","2021-09-20 07:49:54,639 - INFO - joeynmt.training - Epoch   6, Step:     4100, Batch Loss:     3.147795, Tokens per Sec:    14630, Lr: 0.000300\n","2021-09-20 07:50:08,233 - INFO - joeynmt.training - Epoch   6, Step:     4200, Batch Loss:     3.118960, Tokens per Sec:    14537, Lr: 0.000300\n","2021-09-20 07:50:21,782 - INFO - joeynmt.training - Epoch   6, Step:     4300, Batch Loss:     3.138094, Tokens per Sec:    14618, Lr: 0.000300\n","2021-09-20 07:50:32,589 - INFO - joeynmt.training - Epoch   6: total training loss 2291.07\n","2021-09-20 07:50:32,589 - INFO - joeynmt.training - EPOCH 7\n","2021-09-20 07:50:35,040 - INFO - joeynmt.training - Epoch   7, Step:     4400, Batch Loss:     2.940732, Tokens per Sec:    14479, Lr: 0.000300\n","2021-09-20 07:50:48,480 - INFO - joeynmt.training - Epoch   7, Step:     4500, Batch Loss:     3.152671, Tokens per Sec:    14755, Lr: 0.000300\n","2021-09-20 07:51:01,911 - INFO - joeynmt.training - Epoch   7, Step:     4600, Batch Loss:     2.934900, Tokens per Sec:    14606, Lr: 0.000300\n","2021-09-20 07:51:15,410 - INFO - joeynmt.training - Epoch   7, Step:     4700, Batch Loss:     2.921465, Tokens per Sec:    14574, Lr: 0.000300\n","2021-09-20 07:51:29,009 - INFO - joeynmt.training - Epoch   7, Step:     4800, Batch Loss:     2.926976, Tokens per Sec:    14591, Lr: 0.000300\n","2021-09-20 07:51:42,460 - INFO - joeynmt.training - Epoch   7, Step:     4900, Batch Loss:     2.873188, Tokens per Sec:    14676, Lr: 0.000300\n","2021-09-20 07:51:56,136 - INFO - joeynmt.training - Epoch   7, Step:     5000, Batch Loss:     2.758172, Tokens per Sec:    14482, Lr: 0.000300\n","2021-09-20 07:52:06,900 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 07:52:06,900 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 07:52:06,900 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 07:52:06,904 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 07:52:07,250 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/2000.ckpt\n","2021-09-20 07:52:07,270 - INFO - joeynmt.training - Example #0\n","2021-09-20 07:52:07,270 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 07:52:07,270 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 07:52:07,270 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 330.0.0.0.0.0.0.0.0.0.0.0.0.4 crore .\n","2021-09-20 07:52:07,271 - INFO - joeynmt.training - Example #1\n","2021-09-20 07:52:07,271 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 07:52:07,271 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 07:52:07,271 - INFO - joeynmt.training - \tHypothesis: These are not only , we are not only that we are not only the same , but we are not just a fundred , but we are not just a lot of our own .\n","2021-09-20 07:52:07,271 - INFO - joeynmt.training - Example #2\n","2021-09-20 07:52:07,271 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 07:52:07,271 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 07:52:07,271 - INFO - joeynmt.training - \tHypothesis: . To exchange information on cooperation in the field of human resources .\n","2021-09-20 07:52:07,272 - INFO - joeynmt.training - Example #3\n","2021-09-20 07:52:07,272 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 07:52:07,272 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 07:52:07,272 - INFO - joeynmt.training - \tHypothesis: I also congratulate them to share our cultural heritage .\n","2021-09-20 07:52:07,272 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step     5000: bleu:  10.83, loss: 43347.4922, ppl:  17.3745, duration: 11.1352s\n","2021-09-20 07:52:20,610 - INFO - joeynmt.training - Epoch   7, Step:     5100, Batch Loss:     2.945323, Tokens per Sec:    14823, Lr: 0.000300\n","2021-09-20 07:52:22,300 - INFO - joeynmt.training - Epoch   7: total training loss 2193.54\n","2021-09-20 07:52:22,300 - INFO - joeynmt.training - EPOCH 8\n","2021-09-20 07:52:34,164 - INFO - joeynmt.training - Epoch   8, Step:     5200, Batch Loss:     2.989443, Tokens per Sec:    14538, Lr: 0.000300\n","2021-09-20 07:52:47,480 - INFO - joeynmt.training - Epoch   8, Step:     5300, Batch Loss:     2.958881, Tokens per Sec:    14875, Lr: 0.000300\n","2021-09-20 07:53:00,986 - INFO - joeynmt.training - Epoch   8, Step:     5400, Batch Loss:     2.785395, Tokens per Sec:    14687, Lr: 0.000300\n","2021-09-20 07:53:14,492 - INFO - joeynmt.training - Epoch   8, Step:     5500, Batch Loss:     2.842623, Tokens per Sec:    14683, Lr: 0.000300\n","2021-09-20 07:53:27,928 - INFO - joeynmt.training - Epoch   8, Step:     5600, Batch Loss:     3.020808, Tokens per Sec:    14722, Lr: 0.000300\n","2021-09-20 07:53:41,478 - INFO - joeynmt.training - Epoch   8, Step:     5700, Batch Loss:     2.680646, Tokens per Sec:    14551, Lr: 0.000300\n","2021-09-20 07:53:54,951 - INFO - joeynmt.training - Epoch   8, Step:     5800, Batch Loss:     2.914314, Tokens per Sec:    14622, Lr: 0.000300\n","2021-09-20 07:54:00,742 - INFO - joeynmt.training - Epoch   8: total training loss 2107.10\n","2021-09-20 07:54:00,743 - INFO - joeynmt.training - EPOCH 9\n","2021-09-20 07:54:08,512 - INFO - joeynmt.training - Epoch   9, Step:     5900, Batch Loss:     2.803072, Tokens per Sec:    14505, Lr: 0.000300\n","2021-09-20 07:54:22,023 - INFO - joeynmt.training - Epoch   9, Step:     6000, Batch Loss:     2.835527, Tokens per Sec:    14591, Lr: 0.000300\n","2021-09-20 07:54:32,158 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 07:54:32,158 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 07:54:32,159 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 07:54:32,163 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 07:54:32,493 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/3000.ckpt\n","2021-09-20 07:54:32,510 - INFO - joeynmt.training - Example #0\n","2021-09-20 07:54:32,511 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 07:54:32,511 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 07:54:32,511 - INFO - joeynmt.training - \tHypothesis: The need for Rs. 4.0.4 crore for the period of 2015-18 will be required for the period of 2015-2018 .\n","2021-09-20 07:54:32,511 - INFO - joeynmt.training - Example #1\n","2021-09-20 07:54:32,511 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 07:54:32,511 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 07:54:32,511 - INFO - joeynmt.training - \tHypothesis: These are not only because we are not just the right that we are not just to move aheb , but we are not just the right of our country .\n","2021-09-20 07:54:32,511 - INFO - joeynmt.training - Example #2\n","2021-09-20 07:54:32,512 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 07:54:32,512 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 07:54:32,512 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange of information on cooperation in human resources .\n","2021-09-20 07:54:32,512 - INFO - joeynmt.training - Example #3\n","2021-09-20 07:54:32,512 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 07:54:32,512 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 07:54:32,512 - INFO - joeynmt.training - \tHypothesis: I also thank them for the legacy of our heritage .\n","2021-09-20 07:54:32,512 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step     6000: bleu:  11.53, loss: 41301.5117, ppl:  15.1841, duration: 10.4886s\n","2021-09-20 07:54:45,885 - INFO - joeynmt.training - Epoch   9, Step:     6100, Batch Loss:     2.871230, Tokens per Sec:    14844, Lr: 0.000300\n","2021-09-20 07:54:59,234 - INFO - joeynmt.training - Epoch   9, Step:     6200, Batch Loss:     2.667373, Tokens per Sec:    14713, Lr: 0.000300\n","2021-09-20 07:55:12,797 - INFO - joeynmt.training - Epoch   9, Step:     6300, Batch Loss:     2.868091, Tokens per Sec:    14486, Lr: 0.000300\n","2021-09-20 07:55:26,259 - INFO - joeynmt.training - Epoch   9, Step:     6400, Batch Loss:     2.737302, Tokens per Sec:    14640, Lr: 0.000300\n","2021-09-20 07:55:39,496 - INFO - joeynmt.training - Epoch   9, Step:     6500, Batch Loss:     2.687238, Tokens per Sec:    14988, Lr: 0.000300\n","2021-09-20 07:55:49,395 - INFO - joeynmt.training - Epoch   9: total training loss 2043.06\n","2021-09-20 07:55:49,396 - INFO - joeynmt.training - EPOCH 10\n","2021-09-20 07:55:52,827 - INFO - joeynmt.training - Epoch  10, Step:     6600, Batch Loss:     2.716697, Tokens per Sec:    14266, Lr: 0.000300\n","2021-09-20 07:56:06,115 - INFO - joeynmt.training - Epoch  10, Step:     6700, Batch Loss:     2.682383, Tokens per Sec:    14821, Lr: 0.000300\n","2021-09-20 07:56:19,404 - INFO - joeynmt.training - Epoch  10, Step:     6800, Batch Loss:     2.689150, Tokens per Sec:    14909, Lr: 0.000300\n","2021-09-20 07:56:32,657 - INFO - joeynmt.training - Epoch  10, Step:     6900, Batch Loss:     2.665698, Tokens per Sec:    14914, Lr: 0.000300\n","2021-09-20 07:56:46,075 - INFO - joeynmt.training - Epoch  10, Step:     7000, Batch Loss:     2.647223, Tokens per Sec:    14524, Lr: 0.000300\n","2021-09-20 07:56:53,176 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 07:56:53,177 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 07:56:53,177 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 07:56:53,181 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 07:56:53,519 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/4000.ckpt\n","2021-09-20 07:56:53,539 - INFO - joeynmt.training - Example #0\n","2021-09-20 07:56:53,539 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 07:56:53,539 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 07:56:53,539 - INFO - joeynmt.training - \tHypothesis: The need for a period of 2016-17 , 2016-17 will be required for a period of 2016-17 .\n","2021-09-20 07:56:53,539 - INFO - joeynmt.training - Example #1\n","2021-09-20 07:56:53,539 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 07:56:53,540 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 07:56:53,540 - INFO - joeynmt.training - \tHypothesis: This is not only because we are not only because we are not only to be able to do that our country is not just a fast trust .\n","2021-09-20 07:56:53,540 - INFO - joeynmt.training - Example #2\n","2021-09-20 07:56:53,540 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 07:56:53,540 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 07:56:53,540 - INFO - joeynmt.training - \tHypothesis: 4 . Exchange of cooperation in human resources\n","2021-09-20 07:56:53,540 - INFO - joeynmt.training - Example #3\n","2021-09-20 07:56:53,540 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 07:56:53,540 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 07:56:53,540 - INFO - joeynmt.training - \tHypothesis: I also thank them for the legacy of our heritage .\n","2021-09-20 07:56:53,541 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step     7000: bleu:  13.73, loss: 39700.0078, ppl:  13.6640, duration: 7.4655s\n","2021-09-20 07:57:07,080 - INFO - joeynmt.training - Epoch  10, Step:     7100, Batch Loss:     2.666381, Tokens per Sec:    14683, Lr: 0.000300\n","2021-09-20 07:57:20,522 - INFO - joeynmt.training - Epoch  10, Step:     7200, Batch Loss:     2.660220, Tokens per Sec:    14813, Lr: 0.000300\n","2021-09-20 07:57:34,010 - INFO - joeynmt.training - Epoch  10, Step:     7300, Batch Loss:     2.798085, Tokens per Sec:    14676, Lr: 0.000300\n","2021-09-20 07:57:34,724 - INFO - joeynmt.training - Epoch  10: total training loss 1977.15\n","2021-09-20 07:57:34,725 - INFO - joeynmt.training - EPOCH 11\n","2021-09-20 07:57:47,383 - INFO - joeynmt.training - Epoch  11, Step:     7400, Batch Loss:     2.704338, Tokens per Sec:    14792, Lr: 0.000300\n","2021-09-20 07:58:00,745 - INFO - joeynmt.training - Epoch  11, Step:     7500, Batch Loss:     2.696319, Tokens per Sec:    14605, Lr: 0.000300\n","2021-09-20 07:58:14,044 - INFO - joeynmt.training - Epoch  11, Step:     7600, Batch Loss:     2.651042, Tokens per Sec:    14777, Lr: 0.000300\n","2021-09-20 07:58:27,648 - INFO - joeynmt.training - Epoch  11, Step:     7700, Batch Loss:     2.704464, Tokens per Sec:    14579, Lr: 0.000300\n","2021-09-20 07:58:41,166 - INFO - joeynmt.training - Epoch  11, Step:     7800, Batch Loss:     2.699588, Tokens per Sec:    14603, Lr: 0.000300\n","2021-09-20 07:58:54,555 - INFO - joeynmt.training - Epoch  11, Step:     7900, Batch Loss:     2.820803, Tokens per Sec:    14848, Lr: 0.000300\n","2021-09-20 07:59:07,914 - INFO - joeynmt.training - Epoch  11, Step:     8000, Batch Loss:     2.621217, Tokens per Sec:    14725, Lr: 0.000300\n","2021-09-20 07:59:17,024 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 07:59:17,025 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 07:59:17,025 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 07:59:17,029 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 07:59:17,390 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/5000.ckpt\n","2021-09-20 07:59:17,411 - INFO - joeynmt.training - Example #0\n","2021-09-20 07:59:17,412 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 07:59:17,412 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 07:59:17,412 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 44.0.0.0.4 crore for 2016-19 will be required for a period of 2016-19 .\n","2021-09-20 07:59:17,412 - INFO - joeynmt.training - Example #1\n","2021-09-20 07:59:17,412 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 07:59:17,412 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 07:59:17,413 - INFO - joeynmt.training - \tHypothesis: This is not a right that we are being done , we are not only to be done , but we have to move ahead of our businesses .\n","2021-09-20 07:59:17,413 - INFO - joeynmt.training - Example #2\n","2021-09-20 07:59:17,413 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 07:59:17,413 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 07:59:17,413 - INFO - joeynmt.training - \tHypothesis: . To exchange programmes for cooperation in human resources .\n","2021-09-20 07:59:17,413 - INFO - joeynmt.training - Example #3\n","2021-09-20 07:59:17,414 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 07:59:17,414 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 07:59:17,414 - INFO - joeynmt.training - \tHypothesis: I also thank him for the shared heritage of our heritage .\n","2021-09-20 07:59:17,414 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step     8000: bleu:  14.03, loss: 37927.9180, ppl:  12.1588, duration: 9.4996s\n","2021-09-20 07:59:22,323 - INFO - joeynmt.training - Epoch  11: total training loss 1919.93\n","2021-09-20 07:59:22,323 - INFO - joeynmt.training - EPOCH 12\n","2021-09-20 07:59:30,980 - INFO - joeynmt.training - Epoch  12, Step:     8100, Batch Loss:     2.580088, Tokens per Sec:    14429, Lr: 0.000300\n","2021-09-20 07:59:44,506 - INFO - joeynmt.training - Epoch  12, Step:     8200, Batch Loss:     2.595149, Tokens per Sec:    14705, Lr: 0.000300\n","2021-09-20 07:59:57,862 - INFO - joeynmt.training - Epoch  12, Step:     8300, Batch Loss:     2.498528, Tokens per Sec:    14849, Lr: 0.000300\n","2021-09-20 08:00:11,420 - INFO - joeynmt.training - Epoch  12, Step:     8400, Batch Loss:     2.507143, Tokens per Sec:    14503, Lr: 0.000300\n","2021-09-20 08:00:24,792 - INFO - joeynmt.training - Epoch  12, Step:     8500, Batch Loss:     2.478816, Tokens per Sec:    14658, Lr: 0.000300\n","2021-09-20 08:00:38,349 - INFO - joeynmt.training - Epoch  12, Step:     8600, Batch Loss:     2.450105, Tokens per Sec:    14615, Lr: 0.000300\n","2021-09-20 08:00:51,954 - INFO - joeynmt.training - Epoch  12, Step:     8700, Batch Loss:     2.546687, Tokens per Sec:    14533, Lr: 0.000300\n","2021-09-20 08:01:00,845 - INFO - joeynmt.training - Epoch  12: total training loss 1863.61\n","2021-09-20 08:01:00,845 - INFO - joeynmt.training - EPOCH 13\n","2021-09-20 08:01:05,257 - INFO - joeynmt.training - Epoch  13, Step:     8800, Batch Loss:     2.478890, Tokens per Sec:    14555, Lr: 0.000300\n","2021-09-20 08:01:18,429 - INFO - joeynmt.training - Epoch  13, Step:     8900, Batch Loss:     2.485985, Tokens per Sec:    14947, Lr: 0.000300\n","2021-09-20 08:01:31,787 - INFO - joeynmt.training - Epoch  13, Step:     9000, Batch Loss:     2.568837, Tokens per Sec:    14885, Lr: 0.000300\n","2021-09-20 08:01:40,316 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:01:40,316 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:01:40,316 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:01:40,321 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:01:40,668 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/6000.ckpt\n","2021-09-20 08:01:40,688 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:01:40,689 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:01:40,689 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:01:40,689 - INFO - joeynmt.training - \tHypothesis: The need for a period of 2016-19 will be required for a period of 2016-19 .\n","2021-09-20 08:01:40,689 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:01:40,689 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:01:40,689 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:01:40,689 - INFO - joeynmt.training - \tHypothesis: These are not being done , we are not going to be able to ensure that our mother is not a fast way .\n","2021-09-20 08:01:40,690 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:01:40,690 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:01:40,690 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:01:40,690 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange programmes for cooperation in human resources\n","2021-09-20 08:01:40,690 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:01:40,690 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:01:40,691 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:01:40,691 - INFO - joeynmt.training - \tHypothesis: I also thank him for the most individual of our heritage .\n","2021-09-20 08:01:40,691 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step     9000: bleu:  15.09, loss: 36775.5273, ppl:  11.2701, duration: 8.9028s\n","2021-09-20 08:01:54,007 - INFO - joeynmt.training - Epoch  13, Step:     9100, Batch Loss:     2.447545, Tokens per Sec:    14921, Lr: 0.000300\n","2021-09-20 08:02:07,465 - INFO - joeynmt.training - Epoch  13, Step:     9200, Batch Loss:     2.524757, Tokens per Sec:    14792, Lr: 0.000300\n","2021-09-20 08:02:21,008 - INFO - joeynmt.training - Epoch  13, Step:     9300, Batch Loss:     2.454445, Tokens per Sec:    14613, Lr: 0.000300\n","2021-09-20 08:02:34,429 - INFO - joeynmt.training - Epoch  13, Step:     9400, Batch Loss:     2.461229, Tokens per Sec:    14637, Lr: 0.000300\n","2021-09-20 08:02:47,570 - INFO - joeynmt.training - Epoch  13: total training loss 1818.05\n","2021-09-20 08:02:47,571 - INFO - joeynmt.training - EPOCH 14\n","2021-09-20 08:02:47,901 - INFO - joeynmt.training - Epoch  14, Step:     9500, Batch Loss:     2.467698, Tokens per Sec:    12286, Lr: 0.000300\n","2021-09-20 08:03:01,454 - INFO - joeynmt.training - Epoch  14, Step:     9600, Batch Loss:     2.523693, Tokens per Sec:    14570, Lr: 0.000300\n","2021-09-20 08:03:14,903 - INFO - joeynmt.training - Epoch  14, Step:     9700, Batch Loss:     2.474182, Tokens per Sec:    14612, Lr: 0.000300\n","2021-09-20 08:03:28,378 - INFO - joeynmt.training - Epoch  14, Step:     9800, Batch Loss:     2.369138, Tokens per Sec:    14694, Lr: 0.000300\n","2021-09-20 08:03:41,877 - INFO - joeynmt.training - Epoch  14, Step:     9900, Batch Loss:     2.342157, Tokens per Sec:    14798, Lr: 0.000300\n","2021-09-20 08:03:55,313 - INFO - joeynmt.training - Epoch  14, Step:    10000, Batch Loss:     2.439096, Tokens per Sec:    14632, Lr: 0.000300\n","2021-09-20 08:04:04,704 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:04:04,704 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:04:04,704 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:04:04,709 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:04:05,045 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/7000.ckpt\n","2021-09-20 08:04:05,063 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:04:05,063 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:04:05,063 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:04:05,063 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 6.04 crore will be required for a period of 2014-19 .\n","2021-09-20 08:04:05,064 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:04:05,064 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:04:05,064 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:04:05,064 - INFO - joeynmt.training - \tHypothesis: These are not only because we are going to be doing so that we are going to do that our pace , we are not fast .\n","2021-09-20 08:04:05,064 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:04:05,064 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:04:05,064 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:04:05,064 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange programmes for cooperation in human resources\n","2021-09-20 08:04:05,064 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:04:05,064 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:04:05,064 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:04:05,065 - INFO - joeynmt.training - \tHypothesis: I thank him for the most of our heritage .\n","2021-09-20 08:04:05,065 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    10000: bleu:  16.80, loss: 35372.8711, ppl:  10.2756, duration: 9.7512s\n","2021-09-20 08:04:18,598 - INFO - joeynmt.training - Epoch  14, Step:    10100, Batch Loss:     2.425437, Tokens per Sec:    14545, Lr: 0.000300\n","2021-09-20 08:04:31,958 - INFO - joeynmt.training - Epoch  14, Step:    10200, Batch Loss:     2.348812, Tokens per Sec:    14806, Lr: 0.000300\n","2021-09-20 08:04:35,719 - INFO - joeynmt.training - Epoch  14: total training loss 1776.29\n","2021-09-20 08:04:35,720 - INFO - joeynmt.training - EPOCH 15\n","2021-09-20 08:04:45,511 - INFO - joeynmt.training - Epoch  15, Step:    10300, Batch Loss:     2.323380, Tokens per Sec:    14330, Lr: 0.000300\n","2021-09-20 08:04:58,912 - INFO - joeynmt.training - Epoch  15, Step:    10400, Batch Loss:     2.501966, Tokens per Sec:    14738, Lr: 0.000300\n","2021-09-20 08:05:12,396 - INFO - joeynmt.training - Epoch  15, Step:    10500, Batch Loss:     2.377503, Tokens per Sec:    14716, Lr: 0.000300\n","2021-09-20 08:05:25,765 - INFO - joeynmt.training - Epoch  15, Step:    10600, Batch Loss:     2.363349, Tokens per Sec:    14842, Lr: 0.000300\n","2021-09-20 08:05:39,228 - INFO - joeynmt.training - Epoch  15, Step:    10700, Batch Loss:     2.452868, Tokens per Sec:    14748, Lr: 0.000300\n","2021-09-20 08:05:52,902 - INFO - joeynmt.training - Epoch  15, Step:    10800, Batch Loss:     2.299505, Tokens per Sec:    14412, Lr: 0.000300\n","2021-09-20 08:06:06,465 - INFO - joeynmt.training - Epoch  15, Step:    10900, Batch Loss:     2.463544, Tokens per Sec:    14560, Lr: 0.000300\n","2021-09-20 08:06:14,300 - INFO - joeynmt.training - Epoch  15: total training loss 1735.13\n","2021-09-20 08:06:14,301 - INFO - joeynmt.training - EPOCH 16\n","2021-09-20 08:06:19,962 - INFO - joeynmt.training - Epoch  16, Step:    11000, Batch Loss:     2.283609, Tokens per Sec:    14363, Lr: 0.000300\n","2021-09-20 08:06:27,693 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:06:27,693 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:06:27,694 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:06:27,698 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:06:28,053 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/8000.ckpt\n","2021-09-20 08:06:28,073 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:06:28,074 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:06:28,074 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:06:28,074 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 14.94 crore will be required for a period of 2017-19 .\n","2021-09-20 08:06:28,074 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:06:28,075 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:06:28,075 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:06:28,075 - INFO - joeynmt.training - \tHypothesis: These are not only only if we are going to be able to be done , we are not able to be able to remove that our pace is not just a fast .\n","2021-09-20 08:06:28,075 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:06:28,075 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:06:28,075 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:06:28,075 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange programmes for cooperation in human resources\n","2021-09-20 08:06:28,075 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:06:28,076 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:06:28,076 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:06:28,076 - INFO - joeynmt.training - \tHypothesis: I also thank him for the shared values of our heritage .\n","2021-09-20 08:06:28,076 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    11000: bleu:  17.82, loss: 34592.8203, ppl:   9.7610, duration: 8.1134s\n","2021-09-20 08:06:41,817 - INFO - joeynmt.training - Epoch  16, Step:    11100, Batch Loss:     2.316044, Tokens per Sec:    14361, Lr: 0.000300\n","2021-09-20 08:06:55,381 - INFO - joeynmt.training - Epoch  16, Step:    11200, Batch Loss:     2.190578, Tokens per Sec:    14440, Lr: 0.000300\n","2021-09-20 08:07:08,916 - INFO - joeynmt.training - Epoch  16, Step:    11300, Batch Loss:     2.228946, Tokens per Sec:    14481, Lr: 0.000300\n","2021-09-20 08:07:22,397 - INFO - joeynmt.training - Epoch  16, Step:    11400, Batch Loss:     2.340863, Tokens per Sec:    14548, Lr: 0.000300\n","2021-09-20 08:07:35,911 - INFO - joeynmt.training - Epoch  16, Step:    11500, Batch Loss:     2.212309, Tokens per Sec:    14726, Lr: 0.000300\n","2021-09-20 08:07:49,352 - INFO - joeynmt.training - Epoch  16, Step:    11600, Batch Loss:     2.319175, Tokens per Sec:    14733, Lr: 0.000300\n","2021-09-20 08:08:01,525 - INFO - joeynmt.training - Epoch  16: total training loss 1700.48\n","2021-09-20 08:08:01,525 - INFO - joeynmt.training - EPOCH 17\n","2021-09-20 08:08:02,858 - INFO - joeynmt.training - Epoch  17, Step:    11700, Batch Loss:     2.268619, Tokens per Sec:    13384, Lr: 0.000300\n","2021-09-20 08:08:16,603 - INFO - joeynmt.training - Epoch  17, Step:    11800, Batch Loss:     2.156265, Tokens per Sec:    14440, Lr: 0.000300\n","2021-09-20 08:08:29,941 - INFO - joeynmt.training - Epoch  17, Step:    11900, Batch Loss:     2.217251, Tokens per Sec:    14848, Lr: 0.000300\n","2021-09-20 08:08:43,527 - INFO - joeynmt.training - Epoch  17, Step:    12000, Batch Loss:     2.255769, Tokens per Sec:    14640, Lr: 0.000300\n","2021-09-20 08:08:52,527 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:08:52,527 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:08:52,527 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:08:52,531 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:08:52,876 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/9000.ckpt\n","2021-09-20 08:08:52,897 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:08:52,897 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:08:52,897 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:08:52,897 - INFO - joeynmt.training - \tHypothesis: The cost of Rs. 14.64 crore will be required for a period of 2017-19 .\n","2021-09-20 08:08:52,897 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:08:52,898 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:08:52,898 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:08:52,898 - INFO - joeynmt.training - \tHypothesis: These are not being done , we are not right to ensure that our path is going to be the path of the point of the point of the point .\n","2021-09-20 08:08:52,898 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:08:52,898 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:08:52,898 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:08:52,898 - INFO - joeynmt.training - \tHypothesis: 4 . To establish exchange programmes for cooperation in human resources .\n","2021-09-20 08:08:52,898 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:08:52,898 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:08:52,899 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:08:52,899 - INFO - joeynmt.training - \tHypothesis: I also thank them for their shared values of our heritage .\n","2021-09-20 08:08:52,899 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    12000: bleu:  18.72, loss: 33810.7539, ppl:   9.2709, duration: 9.3713s\n","2021-09-20 08:09:06,593 - INFO - joeynmt.training - Epoch  17, Step:    12100, Batch Loss:     2.495983, Tokens per Sec:    14417, Lr: 0.000300\n","2021-09-20 08:09:20,184 - INFO - joeynmt.training - Epoch  17, Step:    12200, Batch Loss:     2.264587, Tokens per Sec:    14568, Lr: 0.000300\n","2021-09-20 08:09:33,734 - INFO - joeynmt.training - Epoch  17, Step:    12300, Batch Loss:     2.403350, Tokens per Sec:    14597, Lr: 0.000300\n","2021-09-20 08:09:47,453 - INFO - joeynmt.training - Epoch  17, Step:    12400, Batch Loss:     2.359958, Tokens per Sec:    14359, Lr: 0.000300\n","2021-09-20 08:09:50,118 - INFO - joeynmt.training - Epoch  17: total training loss 1659.22\n","2021-09-20 08:09:50,118 - INFO - joeynmt.training - EPOCH 18\n","2021-09-20 08:10:01,151 - INFO - joeynmt.training - Epoch  18, Step:    12500, Batch Loss:     2.321132, Tokens per Sec:    14375, Lr: 0.000300\n","2021-09-20 08:10:14,692 - INFO - joeynmt.training - Epoch  18, Step:    12600, Batch Loss:     2.380738, Tokens per Sec:    14584, Lr: 0.000300\n","2021-09-20 08:10:28,180 - INFO - joeynmt.training - Epoch  18, Step:    12700, Batch Loss:     2.273011, Tokens per Sec:    14698, Lr: 0.000300\n","2021-09-20 08:10:41,555 - INFO - joeynmt.training - Epoch  18, Step:    12800, Batch Loss:     2.404237, Tokens per Sec:    14701, Lr: 0.000300\n","2021-09-20 08:10:54,902 - INFO - joeynmt.training - Epoch  18, Step:    12900, Batch Loss:     2.278205, Tokens per Sec:    14932, Lr: 0.000300\n","2021-09-20 08:11:08,371 - INFO - joeynmt.training - Epoch  18, Step:    13000, Batch Loss:     2.291248, Tokens per Sec:    14648, Lr: 0.000300\n","2021-09-20 08:11:15,662 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:11:15,662 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:11:15,663 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:11:15,665 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:11:16,026 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/10000.ckpt\n","2021-09-20 08:11:16,046 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:11:16,047 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:11:16,047 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:11:16,047 - INFO - joeynmt.training - \tHypothesis: The need for a period of 2018-19 will be Rs. 14.04 crore for a period of 2018-19 .\n","2021-09-20 08:11:16,047 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:11:16,047 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:11:16,047 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:11:16,047 - INFO - joeynmt.training - \tHypothesis: These are not being made that we are not right to be done , but we are not a pace of our pace .\n","2021-09-20 08:11:16,047 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:11:16,047 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:11:16,048 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:11:16,048 - INFO - joeynmt.training - \tHypothesis: 4 . Exchange of programmes for cooperation in human resources\n","2021-09-20 08:11:16,048 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:11:16,048 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:11:16,048 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:11:16,048 - INFO - joeynmt.training - \tHypothesis: I also thank him for thank him for the multilateral value of our heritage .\n","2021-09-20 08:11:16,048 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    13000: bleu:  19.34, loss: 32919.2539, ppl:   8.7422, duration: 7.6768s\n","2021-09-20 08:11:29,398 - INFO - joeynmt.training - Epoch  18, Step:    13100, Batch Loss:     2.311286, Tokens per Sec:    14738, Lr: 0.000300\n","2021-09-20 08:11:36,146 - INFO - joeynmt.training - Epoch  18: total training loss 1631.55\n","2021-09-20 08:11:36,147 - INFO - joeynmt.training - EPOCH 19\n","2021-09-20 08:11:42,944 - INFO - joeynmt.training - Epoch  19, Step:    13200, Batch Loss:     2.135700, Tokens per Sec:    14326, Lr: 0.000300\n","2021-09-20 08:11:56,259 - INFO - joeynmt.training - Epoch  19, Step:    13300, Batch Loss:     2.275086, Tokens per Sec:    14771, Lr: 0.000300\n","2021-09-20 08:12:09,893 - INFO - joeynmt.training - Epoch  19, Step:    13400, Batch Loss:     2.206072, Tokens per Sec:    14530, Lr: 0.000300\n","2021-09-20 08:12:23,273 - INFO - joeynmt.training - Epoch  19, Step:    13500, Batch Loss:     2.197872, Tokens per Sec:    14683, Lr: 0.000300\n","2021-09-20 08:12:36,644 - INFO - joeynmt.training - Epoch  19, Step:    13600, Batch Loss:     2.235980, Tokens per Sec:    15028, Lr: 0.000300\n","2021-09-20 08:12:49,863 - INFO - joeynmt.training - Epoch  19, Step:    13700, Batch Loss:     2.092738, Tokens per Sec:    14794, Lr: 0.000300\n","2021-09-20 08:13:03,480 - INFO - joeynmt.training - Epoch  19, Step:    13800, Batch Loss:     2.182442, Tokens per Sec:    14590, Lr: 0.000300\n","2021-09-20 08:13:14,206 - INFO - joeynmt.training - Epoch  19: total training loss 1598.92\n","2021-09-20 08:13:14,207 - INFO - joeynmt.training - EPOCH 20\n","2021-09-20 08:13:16,837 - INFO - joeynmt.training - Epoch  20, Step:    13900, Batch Loss:     2.096598, Tokens per Sec:    14375, Lr: 0.000300\n","2021-09-20 08:13:30,293 - INFO - joeynmt.training - Epoch  20, Step:    14000, Batch Loss:     2.019339, Tokens per Sec:    14626, Lr: 0.000300\n","2021-09-20 08:13:38,199 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:13:38,199 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:13:38,199 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:13:38,204 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:13:38,547 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/11000.ckpt\n","2021-09-20 08:13:38,565 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:13:38,565 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:13:38,565 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:13:38,565 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 142.64 crore will be required for a period of 2018-19 .\n","2021-09-20 08:13:38,565 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:13:38,566 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:13:38,566 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:13:38,566 - INFO - joeynmt.training - \tHypothesis: These are being made that we are not right to be repared , but we are not able to make it easier .\n","2021-09-20 08:13:38,566 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:13:38,566 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:13:38,566 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:13:38,566 - INFO - joeynmt.training - \tHypothesis: 4 . Exchange of programmes for cooperation in human resources\n","2021-09-20 08:13:38,566 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:13:38,566 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:13:38,566 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:13:38,567 - INFO - joeynmt.training - \tHypothesis: I also thank him for thank him for their shared values of our heritage .\n","2021-09-20 08:13:38,567 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    14000: bleu:  20.13, loss: 32132.4531, ppl:   8.3007, duration: 8.2726s\n","2021-09-20 08:13:52,069 - INFO - joeynmt.training - Epoch  20, Step:    14100, Batch Loss:     2.218789, Tokens per Sec:    14626, Lr: 0.000300\n","2021-09-20 08:14:05,467 - INFO - joeynmt.training - Epoch  20, Step:    14200, Batch Loss:     2.298585, Tokens per Sec:    14884, Lr: 0.000300\n","2021-09-20 08:14:18,902 - INFO - joeynmt.training - Epoch  20, Step:    14300, Batch Loss:     2.227378, Tokens per Sec:    14766, Lr: 0.000300\n","2021-09-20 08:14:32,393 - INFO - joeynmt.training - Epoch  20, Step:    14400, Batch Loss:     2.188289, Tokens per Sec:    14632, Lr: 0.000300\n","2021-09-20 08:14:45,873 - INFO - joeynmt.training - Epoch  20, Step:    14500, Batch Loss:     2.280961, Tokens per Sec:    14506, Lr: 0.000300\n","2021-09-20 08:14:59,396 - INFO - joeynmt.training - Epoch  20, Step:    14600, Batch Loss:     2.144344, Tokens per Sec:    14721, Lr: 0.000300\n","2021-09-20 08:15:00,812 - INFO - joeynmt.training - Epoch  20: total training loss 1571.00\n","2021-09-20 08:15:00,812 - INFO - joeynmt.training - EPOCH 21\n","2021-09-20 08:15:12,995 - INFO - joeynmt.training - Epoch  21, Step:    14700, Batch Loss:     1.999254, Tokens per Sec:    14365, Lr: 0.000300\n","2021-09-20 08:15:26,504 - INFO - joeynmt.training - Epoch  21, Step:    14800, Batch Loss:     2.084896, Tokens per Sec:    14578, Lr: 0.000300\n","2021-09-20 08:15:40,090 - INFO - joeynmt.training - Epoch  21, Step:    14900, Batch Loss:     2.241973, Tokens per Sec:    14570, Lr: 0.000300\n","2021-09-20 08:15:53,591 - INFO - joeynmt.training - Epoch  21, Step:    15000, Batch Loss:     2.239654, Tokens per Sec:    14717, Lr: 0.000300\n","2021-09-20 08:16:01,789 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:16:01,789 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:16:01,789 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:16:01,795 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:16:02,139 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/12000.ckpt\n","2021-09-20 08:16:02,157 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:16:02,158 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:16:02,158 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:16:02,158 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 1464 crore will be required for a period of 2018-19 .\n","2021-09-20 08:16:02,158 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:16:02,158 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:16:02,158 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:16:02,158 - INFO - joeynmt.training - \tHypothesis: This is not only that we are not going to be doing so that our pace is not a pace of pace .\n","2021-09-20 08:16:02,158 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:16:02,159 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:16:02,159 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:16:02,159 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange programmes for cooperation in human resources development\n","2021-09-20 08:16:02,159 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:16:02,159 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:16:02,159 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:16:02,160 - INFO - joeynmt.training - \tHypothesis: I also thank them for their shared values of our heritage .\n","2021-09-20 08:16:02,160 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    15000: bleu:  21.05, loss: 31521.7520, ppl:   7.9735, duration: 8.5686s\n","2021-09-20 08:16:15,748 - INFO - joeynmt.training - Epoch  21, Step:    15100, Batch Loss:     2.222225, Tokens per Sec:    14503, Lr: 0.000300\n","2021-09-20 08:16:29,073 - INFO - joeynmt.training - Epoch  21, Step:    15200, Batch Loss:     2.112074, Tokens per Sec:    14936, Lr: 0.000300\n","2021-09-20 08:16:42,629 - INFO - joeynmt.training - Epoch  21, Step:    15300, Batch Loss:     2.204285, Tokens per Sec:    14597, Lr: 0.000300\n","2021-09-20 08:16:48,081 - INFO - joeynmt.training - Epoch  21: total training loss 1546.11\n","2021-09-20 08:16:48,082 - INFO - joeynmt.training - EPOCH 22\n","2021-09-20 08:16:56,135 - INFO - joeynmt.training - Epoch  22, Step:    15400, Batch Loss:     2.052180, Tokens per Sec:    14365, Lr: 0.000300\n","2021-09-20 08:17:09,810 - INFO - joeynmt.training - Epoch  22, Step:    15500, Batch Loss:     2.000384, Tokens per Sec:    14504, Lr: 0.000300\n","2021-09-20 08:17:23,460 - INFO - joeynmt.training - Epoch  22, Step:    15600, Batch Loss:     2.216409, Tokens per Sec:    14604, Lr: 0.000300\n","2021-09-20 08:17:36,972 - INFO - joeynmt.training - Epoch  22, Step:    15700, Batch Loss:     2.065176, Tokens per Sec:    14591, Lr: 0.000300\n","2021-09-20 08:17:50,669 - INFO - joeynmt.training - Epoch  22, Step:    15800, Batch Loss:     2.083878, Tokens per Sec:    14424, Lr: 0.000300\n","2021-09-20 08:18:04,395 - INFO - joeynmt.training - Epoch  22, Step:    15900, Batch Loss:     1.940439, Tokens per Sec:    14394, Lr: 0.000300\n","2021-09-20 08:18:17,907 - INFO - joeynmt.training - Epoch  22, Step:    16000, Batch Loss:     2.091086, Tokens per Sec:    14619, Lr: 0.000300\n","2021-09-20 08:18:26,352 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:18:26,353 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:18:26,353 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:18:26,355 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:18:26,712 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/13000.ckpt\n","2021-09-20 08:18:26,731 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:18:26,731 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:18:26,731 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:18:26,732 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 146.04 crore will be required for a period of 2018-19 .\n","2021-09-20 08:18:26,732 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:18:26,732 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:18:26,732 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:18:26,732 - INFO - joeynmt.training - \tHypothesis: These are being done , we are not going to ensure that our poetry is not a pace of our poetry .\n","2021-09-20 08:18:26,732 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:18:26,732 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:18:26,732 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:18:26,732 - INFO - joeynmt.training - \tHypothesis: 4 . Exchange of programmes for cooperation in human resources\n","2021-09-20 08:18:26,732 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:18:26,733 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:18:26,733 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:18:26,733 - INFO - joeynmt.training - \tHypothesis: I also thank him for thank him for their shared values of our heritage .\n","2021-09-20 08:18:26,733 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    16000: bleu:  21.38, loss: 30931.3398, ppl:   7.6694, duration: 8.8257s\n","2021-09-20 08:18:36,237 - INFO - joeynmt.training - Epoch  22: total training loss 1519.44\n","2021-09-20 08:18:36,238 - INFO - joeynmt.training - EPOCH 23\n","2021-09-20 08:18:40,176 - INFO - joeynmt.training - Epoch  23, Step:    16100, Batch Loss:     1.874324, Tokens per Sec:    14541, Lr: 0.000300\n","2021-09-20 08:18:53,714 - INFO - joeynmt.training - Epoch  23, Step:    16200, Batch Loss:     2.182605, Tokens per Sec:    14682, Lr: 0.000300\n","2021-09-20 08:19:07,330 - INFO - joeynmt.training - Epoch  23, Step:    16300, Batch Loss:     2.054582, Tokens per Sec:    14403, Lr: 0.000300\n","2021-09-20 08:19:20,775 - INFO - joeynmt.training - Epoch  23, Step:    16400, Batch Loss:     1.925600, Tokens per Sec:    14755, Lr: 0.000300\n","2021-09-20 08:19:34,128 - INFO - joeynmt.training - Epoch  23, Step:    16500, Batch Loss:     2.042875, Tokens per Sec:    14815, Lr: 0.000300\n","2021-09-20 08:19:47,578 - INFO - joeynmt.training - Epoch  23, Step:    16600, Batch Loss:     1.972447, Tokens per Sec:    14640, Lr: 0.000300\n","2021-09-20 08:20:01,073 - INFO - joeynmt.training - Epoch  23, Step:    16700, Batch Loss:     2.064898, Tokens per Sec:    14594, Lr: 0.000300\n","2021-09-20 08:20:14,743 - INFO - joeynmt.training - Epoch  23, Step:    16800, Batch Loss:     2.055313, Tokens per Sec:    14526, Lr: 0.000300\n","2021-09-20 08:20:14,862 - INFO - joeynmt.training - Epoch  23: total training loss 1497.78\n","2021-09-20 08:20:14,862 - INFO - joeynmt.training - EPOCH 24\n","2021-09-20 08:20:28,227 - INFO - joeynmt.training - Epoch  24, Step:    16900, Batch Loss:     2.033128, Tokens per Sec:    14567, Lr: 0.000300\n","2021-09-20 08:20:41,933 - INFO - joeynmt.training - Epoch  24, Step:    17000, Batch Loss:     1.972649, Tokens per Sec:    14346, Lr: 0.000300\n","2021-09-20 08:20:49,580 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:20:49,581 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:20:49,581 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:20:49,587 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:20:49,938 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/14000.ckpt\n","2021-09-20 08:20:49,963 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:20:49,963 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:20:49,963 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:20:49,963 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.64 crore will be required for a period of 2018-19 .\n","2021-09-20 08:20:49,964 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:20:49,964 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:20:49,964 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:20:49,964 - INFO - joeynmt.training - \tHypothesis: They are going to be done that we are not right to do it , the pace of our pace is not a single .\n","2021-09-20 08:20:49,964 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:20:49,964 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:20:49,964 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:20:49,964 - INFO - joeynmt.training - \tHypothesis: 4 . Exchange of programmes for cooperation in human resource development\n","2021-09-20 08:20:49,965 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:20:49,965 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:20:49,965 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:20:49,965 - INFO - joeynmt.training - \tHypothesis: I also thank them for their shared values of our heritage .\n","2021-09-20 08:20:49,965 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    17000: bleu:  21.47, loss: 30741.5508, ppl:   7.5741, duration: 8.0315s\n","2021-09-20 08:21:03,568 - INFO - joeynmt.training - Epoch  24, Step:    17100, Batch Loss:     1.930217, Tokens per Sec:    14490, Lr: 0.000300\n","2021-09-20 08:21:17,067 - INFO - joeynmt.training - Epoch  24, Step:    17200, Batch Loss:     2.049622, Tokens per Sec:    14772, Lr: 0.000300\n","2021-09-20 08:21:30,586 - INFO - joeynmt.training - Epoch  24, Step:    17300, Batch Loss:     2.007311, Tokens per Sec:    14574, Lr: 0.000300\n","2021-09-20 08:21:44,159 - INFO - joeynmt.training - Epoch  24, Step:    17400, Batch Loss:     1.966186, Tokens per Sec:    14565, Lr: 0.000300\n","2021-09-20 08:21:57,673 - INFO - joeynmt.training - Epoch  24, Step:    17500, Batch Loss:     1.880104, Tokens per Sec:    14715, Lr: 0.000300\n","2021-09-20 08:22:01,837 - INFO - joeynmt.training - Epoch  24: total training loss 1475.10\n","2021-09-20 08:22:01,838 - INFO - joeynmt.training - EPOCH 25\n","2021-09-20 08:22:11,241 - INFO - joeynmt.training - Epoch  25, Step:    17600, Batch Loss:     1.879135, Tokens per Sec:    14576, Lr: 0.000300\n","2021-09-20 08:22:24,657 - INFO - joeynmt.training - Epoch  25, Step:    17700, Batch Loss:     1.894686, Tokens per Sec:    14725, Lr: 0.000300\n","2021-09-20 08:22:38,244 - INFO - joeynmt.training - Epoch  25, Step:    17800, Batch Loss:     2.031461, Tokens per Sec:    14500, Lr: 0.000300\n","2021-09-20 08:22:51,875 - INFO - joeynmt.training - Epoch  25, Step:    17900, Batch Loss:     1.992415, Tokens per Sec:    14529, Lr: 0.000300\n","2021-09-20 08:23:05,389 - INFO - joeynmt.training - Epoch  25, Step:    18000, Batch Loss:     2.109582, Tokens per Sec:    14555, Lr: 0.000300\n","2021-09-20 08:23:13,171 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:23:13,172 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:23:13,172 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:23:13,177 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:23:13,545 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/15000.ckpt\n","2021-09-20 08:23:13,566 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:23:13,566 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:23:13,566 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:23:13,566 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 1463.64 crore will be required for a period of 2018-19 .\n","2021-09-20 08:23:13,566 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:23:13,567 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:23:13,567 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:23:13,567 - INFO - joeynmt.training - \tHypothesis: They are trying to be right that we are going to do not be done , but it is not a momentum to the momentum .\n","2021-09-20 08:23:13,567 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:23:13,567 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:23:13,567 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:23:13,567 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange programmes for cooperation in human resources development\n","2021-09-20 08:23:13,567 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:23:13,568 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:23:13,568 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:23:13,568 - INFO - joeynmt.training - \tHypothesis: I also thank him for thank him for the multiple part of our heritage .\n","2021-09-20 08:23:13,568 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    18000: bleu:  21.61, loss: 29987.3945, ppl:   7.2071, duration: 8.1786s\n","2021-09-20 08:23:27,295 - INFO - joeynmt.training - Epoch  25, Step:    18100, Batch Loss:     2.042644, Tokens per Sec:    14355, Lr: 0.000300\n","2021-09-20 08:23:40,747 - INFO - joeynmt.training - Epoch  25, Step:    18200, Batch Loss:     1.772698, Tokens per Sec:    14740, Lr: 0.000300\n","2021-09-20 08:23:49,010 - INFO - joeynmt.training - Epoch  25: total training loss 1454.27\n","2021-09-20 08:23:49,010 - INFO - joeynmt.training - EPOCH 26\n","2021-09-20 08:23:54,400 - INFO - joeynmt.training - Epoch  26, Step:    18300, Batch Loss:     1.956929, Tokens per Sec:    14459, Lr: 0.000300\n","2021-09-20 08:24:07,852 - INFO - joeynmt.training - Epoch  26, Step:    18400, Batch Loss:     2.056724, Tokens per Sec:    14692, Lr: 0.000300\n","2021-09-20 08:24:21,300 - INFO - joeynmt.training - Epoch  26, Step:    18500, Batch Loss:     1.895125, Tokens per Sec:    14507, Lr: 0.000300\n","2021-09-20 08:24:34,827 - INFO - joeynmt.training - Epoch  26, Step:    18600, Batch Loss:     1.961853, Tokens per Sec:    14533, Lr: 0.000300\n","2021-09-20 08:24:48,453 - INFO - joeynmt.training - Epoch  26, Step:    18700, Batch Loss:     1.940007, Tokens per Sec:    14469, Lr: 0.000300\n","2021-09-20 08:25:01,997 - INFO - joeynmt.training - Epoch  26, Step:    18800, Batch Loss:     2.126843, Tokens per Sec:    14666, Lr: 0.000300\n","2021-09-20 08:25:15,754 - INFO - joeynmt.training - Epoch  26, Step:    18900, Batch Loss:     1.939260, Tokens per Sec:    14360, Lr: 0.000300\n","2021-09-20 08:25:28,251 - INFO - joeynmt.training - Epoch  26: total training loss 1435.04\n","2021-09-20 08:25:28,251 - INFO - joeynmt.training - EPOCH 27\n","2021-09-20 08:25:29,528 - INFO - joeynmt.training - Epoch  27, Step:    19000, Batch Loss:     1.885517, Tokens per Sec:    13995, Lr: 0.000300\n","2021-09-20 08:25:37,420 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:25:37,420 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:25:37,420 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:25:37,426 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:25:37,812 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/16000.ckpt\n","2021-09-20 08:25:37,833 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:25:37,833 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:25:37,833 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:25:37,833 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.64 crore will be required for a period of 2018-19 .\n","2021-09-20 08:25:37,833 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:25:37,834 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:25:37,834 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:25:37,834 - INFO - joeynmt.training - \tHypothesis: They are trying to be done , that we are not going to do that our pace is not a pace of pace , whether it is not a silot .\n","2021-09-20 08:25:37,834 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:25:37,834 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:25:37,835 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:25:37,835 - INFO - joeynmt.training - \tHypothesis: 4 . To establish exchange programmes for cooperation in human resources development .\n","2021-09-20 08:25:37,835 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:25:37,835 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:25:37,835 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:25:37,835 - INFO - joeynmt.training - \tHypothesis: I also thank them for their shared values of our heritage .\n","2021-09-20 08:25:37,836 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    19000: bleu:  22.73, loss: 29567.7578, ppl:   7.0106, duration: 8.3072s\n","2021-09-20 08:25:51,418 - INFO - joeynmt.training - Epoch  27, Step:    19100, Batch Loss:     1.941727, Tokens per Sec:    14496, Lr: 0.000300\n","2021-09-20 08:26:05,079 - INFO - joeynmt.training - Epoch  27, Step:    19200, Batch Loss:     1.970344, Tokens per Sec:    14441, Lr: 0.000300\n","2021-09-20 08:26:18,734 - INFO - joeynmt.training - Epoch  27, Step:    19300, Batch Loss:     1.979367, Tokens per Sec:    14357, Lr: 0.000300\n","2021-09-20 08:26:32,358 - INFO - joeynmt.training - Epoch  27, Step:    19400, Batch Loss:     1.886879, Tokens per Sec:    14446, Lr: 0.000300\n","2021-09-20 08:26:46,059 - INFO - joeynmt.training - Epoch  27, Step:    19500, Batch Loss:     1.850217, Tokens per Sec:    14473, Lr: 0.000300\n","2021-09-20 08:26:59,747 - INFO - joeynmt.training - Epoch  27, Step:    19600, Batch Loss:     1.912680, Tokens per Sec:    14442, Lr: 0.000300\n","2021-09-20 08:27:13,389 - INFO - joeynmt.training - Epoch  27, Step:    19700, Batch Loss:     1.818452, Tokens per Sec:    14530, Lr: 0.000300\n","2021-09-20 08:27:16,388 - INFO - joeynmt.training - Epoch  27: total training loss 1418.90\n","2021-09-20 08:27:16,388 - INFO - joeynmt.training - EPOCH 28\n","2021-09-20 08:27:27,079 - INFO - joeynmt.training - Epoch  28, Step:    19800, Batch Loss:     1.886379, Tokens per Sec:    14358, Lr: 0.000300\n","2021-09-20 08:27:40,969 - INFO - joeynmt.training - Epoch  28, Step:    19900, Batch Loss:     1.960667, Tokens per Sec:    14296, Lr: 0.000300\n","2021-09-20 08:27:54,655 - INFO - joeynmt.training - Epoch  28, Step:    20000, Batch Loss:     1.983778, Tokens per Sec:    14460, Lr: 0.000300\n","2021-09-20 08:28:02,923 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:28:02,923 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:28:02,923 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:28:02,928 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:28:03,293 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/17000.ckpt\n","2021-09-20 08:28:03,312 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:28:03,312 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:28:03,312 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:28:03,312 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 14.64 crore will be required for a period of a year 2018-19 .\n","2021-09-20 08:28:03,313 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:28:03,313 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:28:03,313 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:28:03,313 - INFO - joeynmt.training - \tHypothesis: These are going to be that we are not right to do that our pace is not a pace .\n","2021-09-20 08:28:03,313 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:28:03,313 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:28:03,313 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:28:03,313 - INFO - joeynmt.training - \tHypothesis: 4 . To establish exchange programmes for cooperation in human resources development .\n","2021-09-20 08:28:03,313 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:28:03,314 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:28:03,314 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:28:03,314 - INFO - joeynmt.training - \tHypothesis: I also thank him for the shining part of our heritage .\n","2021-09-20 08:28:03,314 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    20000: bleu:  22.84, loss: 29192.8770, ppl:   6.8396, duration: 8.6586s\n","2021-09-20 08:28:17,054 - INFO - joeynmt.training - Epoch  28, Step:    20100, Batch Loss:     1.805563, Tokens per Sec:    14427, Lr: 0.000300\n","2021-09-20 08:28:30,906 - INFO - joeynmt.training - Epoch  28, Step:    20200, Batch Loss:     2.140299, Tokens per Sec:    14331, Lr: 0.000300\n","2021-09-20 08:28:44,436 - INFO - joeynmt.training - Epoch  28, Step:    20300, Batch Loss:     1.898220, Tokens per Sec:    14519, Lr: 0.000300\n","2021-09-20 08:28:58,366 - INFO - joeynmt.training - Epoch  28, Step:    20400, Batch Loss:     1.999423, Tokens per Sec:    14325, Lr: 0.000300\n","2021-09-20 08:29:05,295 - INFO - joeynmt.training - Epoch  28: total training loss 1397.89\n","2021-09-20 08:29:05,295 - INFO - joeynmt.training - EPOCH 29\n","2021-09-20 08:29:12,069 - INFO - joeynmt.training - Epoch  29, Step:    20500, Batch Loss:     1.945985, Tokens per Sec:    14326, Lr: 0.000300\n","2021-09-20 08:29:25,453 - INFO - joeynmt.training - Epoch  29, Step:    20600, Batch Loss:     1.907310, Tokens per Sec:    14603, Lr: 0.000300\n","2021-09-20 08:29:39,197 - INFO - joeynmt.training - Epoch  29, Step:    20700, Batch Loss:     1.935381, Tokens per Sec:    14448, Lr: 0.000300\n","2021-09-20 08:29:52,731 - INFO - joeynmt.training - Epoch  29, Step:    20800, Batch Loss:     1.826518, Tokens per Sec:    14564, Lr: 0.000300\n","2021-09-20 08:30:06,332 - INFO - joeynmt.training - Epoch  29, Step:    20900, Batch Loss:     2.098638, Tokens per Sec:    14585, Lr: 0.000300\n","2021-09-20 08:30:19,940 - INFO - joeynmt.training - Epoch  29, Step:    21000, Batch Loss:     2.016467, Tokens per Sec:    14558, Lr: 0.000300\n","2021-09-20 08:30:28,082 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:30:28,082 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:30:28,082 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:30:28,086 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:30:28,445 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/18000.ckpt\n","2021-09-20 08:30:28,465 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:30:28,465 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:30:28,465 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:30:28,466 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.6.64 crore will be required for a period of 2018-19 .\n","2021-09-20 08:30:28,466 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:30:28,466 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:30:28,466 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:30:28,466 - INFO - joeynmt.training - \tHypothesis: These are going to be right , we are going to do that it is not a single pace , that is not a single week .\n","2021-09-20 08:30:28,466 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:30:28,466 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:30:28,467 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:30:28,467 - INFO - joeynmt.training - \tHypothesis: 4 . To establish exchange programmes for cooperation in human resources development .\n","2021-09-20 08:30:28,467 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:30:28,467 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:30:28,467 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:30:28,467 - INFO - joeynmt.training - \tHypothesis: I also thank them for the multiple part of our heritage .\n","2021-09-20 08:30:28,467 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    21000: bleu:  23.04, loss: 28989.1055, ppl:   6.7485, duration: 8.5273s\n","2021-09-20 08:30:42,074 - INFO - joeynmt.training - Epoch  29, Step:    21100, Batch Loss:     1.856191, Tokens per Sec:    14464, Lr: 0.000300\n","2021-09-20 08:30:53,198 - INFO - joeynmt.training - Epoch  29: total training loss 1385.50\n","2021-09-20 08:30:53,199 - INFO - joeynmt.training - EPOCH 30\n","2021-09-20 08:30:55,680 - INFO - joeynmt.training - Epoch  30, Step:    21200, Batch Loss:     1.714822, Tokens per Sec:    14086, Lr: 0.000300\n","2021-09-20 08:31:09,268 - INFO - joeynmt.training - Epoch  30, Step:    21300, Batch Loss:     1.887410, Tokens per Sec:    14546, Lr: 0.000300\n","2021-09-20 08:31:22,596 - INFO - joeynmt.training - Epoch  30, Step:    21400, Batch Loss:     1.722250, Tokens per Sec:    14702, Lr: 0.000300\n","2021-09-20 08:31:36,394 - INFO - joeynmt.training - Epoch  30, Step:    21500, Batch Loss:     1.810518, Tokens per Sec:    14433, Lr: 0.000300\n","2021-09-20 08:31:50,069 - INFO - joeynmt.training - Epoch  30, Step:    21600, Batch Loss:     1.766482, Tokens per Sec:    14546, Lr: 0.000300\n","2021-09-20 08:32:03,642 - INFO - joeynmt.training - Epoch  30, Step:    21700, Batch Loss:     1.991486, Tokens per Sec:    14448, Lr: 0.000300\n","2021-09-20 08:32:17,213 - INFO - joeynmt.training - Epoch  30, Step:    21800, Batch Loss:     1.973578, Tokens per Sec:    14547, Lr: 0.000300\n","2021-09-20 08:32:30,819 - INFO - joeynmt.training - Epoch  30, Step:    21900, Batch Loss:     1.805777, Tokens per Sec:    14599, Lr: 0.000300\n","2021-09-20 08:32:32,514 - INFO - joeynmt.training - Epoch  30: total training loss 1368.30\n","2021-09-20 08:32:32,515 - INFO - joeynmt.training - EPOCH 31\n","2021-09-20 08:32:44,587 - INFO - joeynmt.training - Epoch  31, Step:    22000, Batch Loss:     1.721277, Tokens per Sec:    14533, Lr: 0.000300\n","2021-09-20 08:32:52,317 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:32:52,317 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:32:52,317 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:32:52,321 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:32:52,684 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/19000.ckpt\n","2021-09-20 08:32:52,705 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:32:52,706 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:32:52,706 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:32:52,706 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 141.64 crore will be required for a period of 2018-19 .\n","2021-09-20 08:32:52,706 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:32:52,706 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:32:52,706 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:32:52,707 - INFO - joeynmt.training - \tHypothesis: These are going to be that we are going to do that we do not have to be able to do it .\n","2021-09-20 08:32:52,707 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:32:52,707 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:32:52,707 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:32:52,707 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange programmes for cooperation in human resources development\n","2021-09-20 08:32:52,707 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:32:52,708 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:32:52,708 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:32:52,708 - INFO - joeynmt.training - \tHypothesis: I also thank him for the landmark part of our heritage .\n","2021-09-20 08:32:52,708 - INFO - joeynmt.training - Validation result (greedy) at epoch  31, step    22000: bleu:  23.60, loss: 28722.6719, ppl:   6.6311, duration: 8.1207s\n","2021-09-20 08:33:06,294 - INFO - joeynmt.training - Epoch  31, Step:    22100, Batch Loss:     1.820198, Tokens per Sec:    14615, Lr: 0.000300\n","2021-09-20 08:33:20,077 - INFO - joeynmt.training - Epoch  31, Step:    22200, Batch Loss:     1.896547, Tokens per Sec:    14251, Lr: 0.000300\n","2021-09-20 08:33:33,897 - INFO - joeynmt.training - Epoch  31, Step:    22300, Batch Loss:     1.825509, Tokens per Sec:    14356, Lr: 0.000300\n","2021-09-20 08:33:47,516 - INFO - joeynmt.training - Epoch  31, Step:    22400, Batch Loss:     1.790871, Tokens per Sec:    14538, Lr: 0.000300\n","2021-09-20 08:34:01,166 - INFO - joeynmt.training - Epoch  31, Step:    22500, Batch Loss:     1.814929, Tokens per Sec:    14453, Lr: 0.000300\n","2021-09-20 08:34:14,596 - INFO - joeynmt.training - Epoch  31, Step:    22600, Batch Loss:     1.873790, Tokens per Sec:    14599, Lr: 0.000300\n","2021-09-20 08:34:20,346 - INFO - joeynmt.training - Epoch  31: total training loss 1352.83\n","2021-09-20 08:34:20,346 - INFO - joeynmt.training - EPOCH 32\n","2021-09-20 08:34:28,259 - INFO - joeynmt.training - Epoch  32, Step:    22700, Batch Loss:     1.883217, Tokens per Sec:    14462, Lr: 0.000300\n","2021-09-20 08:34:41,927 - INFO - joeynmt.training - Epoch  32, Step:    22800, Batch Loss:     1.962841, Tokens per Sec:    14474, Lr: 0.000300\n","2021-09-20 08:34:55,501 - INFO - joeynmt.training - Epoch  32, Step:    22900, Batch Loss:     1.925244, Tokens per Sec:    14599, Lr: 0.000300\n","2021-09-20 08:35:09,332 - INFO - joeynmt.training - Epoch  32, Step:    23000, Batch Loss:     1.805037, Tokens per Sec:    14174, Lr: 0.000300\n","2021-09-20 08:35:17,341 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:35:17,341 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:35:17,341 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:35:17,347 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:35:17,733 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/20000.ckpt\n","2021-09-20 08:35:17,753 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:35:17,753 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:35:17,753 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:35:17,753 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.603.64 crore will be required for a period of one year 2018-19 .\n","2021-09-20 08:35:17,753 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:35:17,754 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:35:17,754 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:35:17,754 - INFO - joeynmt.training - \tHypothesis: These are going to be that we are not going to be done , our pace is not just a single pace .\n","2021-09-20 08:35:17,754 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:35:17,754 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:35:17,754 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:35:17,754 - INFO - joeynmt.training - \tHypothesis: 4 . To establish exchange programmes for cooperation in human resource development .\n","2021-09-20 08:35:17,754 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:35:17,755 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:35:17,755 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:35:17,755 - INFO - joeynmt.training - \tHypothesis: I also thank him for the shining part of our heritage .\n","2021-09-20 08:35:17,755 - INFO - joeynmt.training - Validation result (greedy) at epoch  32, step    23000: bleu:  23.85, loss: 28387.7773, ppl:   6.4864, duration: 8.4223s\n","2021-09-20 08:35:31,418 - INFO - joeynmt.training - Epoch  32, Step:    23100, Batch Loss:     1.854122, Tokens per Sec:    14467, Lr: 0.000300\n","2021-09-20 08:35:45,079 - INFO - joeynmt.training - Epoch  32, Step:    23200, Batch Loss:     1.772413, Tokens per Sec:    14553, Lr: 0.000300\n","2021-09-20 08:35:58,588 - INFO - joeynmt.training - Epoch  32, Step:    23300, Batch Loss:     1.730951, Tokens per Sec:    14727, Lr: 0.000300\n","2021-09-20 08:36:08,330 - INFO - joeynmt.training - Epoch  32: total training loss 1337.16\n","2021-09-20 08:36:08,331 - INFO - joeynmt.training - EPOCH 33\n","2021-09-20 08:36:12,382 - INFO - joeynmt.training - Epoch  33, Step:    23400, Batch Loss:     1.805093, Tokens per Sec:    13962, Lr: 0.000300\n","2021-09-20 08:36:25,896 - INFO - joeynmt.training - Epoch  33, Step:    23500, Batch Loss:     1.745245, Tokens per Sec:    14637, Lr: 0.000300\n","2021-09-20 08:36:39,523 - INFO - joeynmt.training - Epoch  33, Step:    23600, Batch Loss:     1.944392, Tokens per Sec:    14415, Lr: 0.000300\n","2021-09-20 08:36:53,321 - INFO - joeynmt.training - Epoch  33, Step:    23700, Batch Loss:     1.552465, Tokens per Sec:    14294, Lr: 0.000300\n","2021-09-20 08:37:06,970 - INFO - joeynmt.training - Epoch  33, Step:    23800, Batch Loss:     1.818977, Tokens per Sec:    14614, Lr: 0.000300\n","2021-09-20 08:37:20,628 - INFO - joeynmt.training - Epoch  33, Step:    23900, Batch Loss:     1.844753, Tokens per Sec:    14595, Lr: 0.000300\n","2021-09-20 08:37:34,292 - INFO - joeynmt.training - Epoch  33, Step:    24000, Batch Loss:     1.887712, Tokens per Sec:    14348, Lr: 0.000300\n","2021-09-20 08:37:42,242 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:37:42,242 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:37:42,242 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:37:42,247 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:37:42,617 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/21000.ckpt\n","2021-09-20 08:37:42,636 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:37:42,637 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:37:42,637 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:37:42,637 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 08:37:42,637 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:37:42,637 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:37:42,637 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:37:42,638 - INFO - joeynmt.training - \tHypothesis: These are going to be that we are not right to do that they are not a siloth , our pace is not a siloth .\n","2021-09-20 08:37:42,638 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:37:42,638 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:37:42,638 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:37:42,638 - INFO - joeynmt.training - \tHypothesis: 4 . To establish exchange programmes for cooperation in human resource development .\n","2021-09-20 08:37:42,638 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:37:42,638 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:37:42,638 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:37:42,639 - INFO - joeynmt.training - \tHypothesis: I also thank them for the part of our heritage .\n","2021-09-20 08:37:42,639 - INFO - joeynmt.training - Validation result (greedy) at epoch  33, step    24000: bleu:  24.39, loss: 28137.9023, ppl:   6.3805, duration: 8.3466s\n","2021-09-20 08:37:56,266 - INFO - joeynmt.training - Epoch  33, Step:    24100, Batch Loss:     1.851460, Tokens per Sec:    14416, Lr: 0.000300\n","2021-09-20 08:37:56,494 - INFO - joeynmt.training - Epoch  33: total training loss 1327.99\n","2021-09-20 08:37:56,494 - INFO - joeynmt.training - EPOCH 34\n","2021-09-20 08:38:09,875 - INFO - joeynmt.training - Epoch  34, Step:    24200, Batch Loss:     1.801981, Tokens per Sec:    14316, Lr: 0.000300\n","2021-09-20 08:38:23,686 - INFO - joeynmt.training - Epoch  34, Step:    24300, Batch Loss:     1.892200, Tokens per Sec:    14255, Lr: 0.000300\n","2021-09-20 08:38:37,179 - INFO - joeynmt.training - Epoch  34, Step:    24400, Batch Loss:     1.836413, Tokens per Sec:    14691, Lr: 0.000300\n","2021-09-20 08:38:50,870 - INFO - joeynmt.training - Epoch  34, Step:    24500, Batch Loss:     1.828121, Tokens per Sec:    14396, Lr: 0.000300\n","2021-09-20 08:39:04,537 - INFO - joeynmt.training - Epoch  34, Step:    24600, Batch Loss:     1.712863, Tokens per Sec:    14674, Lr: 0.000300\n","2021-09-20 08:39:18,177 - INFO - joeynmt.training - Epoch  34, Step:    24700, Batch Loss:     1.722120, Tokens per Sec:    14514, Lr: 0.000300\n","2021-09-20 08:39:31,784 - INFO - joeynmt.training - Epoch  34, Step:    24800, Batch Loss:     1.722937, Tokens per Sec:    14518, Lr: 0.000300\n","2021-09-20 08:39:36,294 - INFO - joeynmt.training - Epoch  34: total training loss 1314.63\n","2021-09-20 08:39:36,294 - INFO - joeynmt.training - EPOCH 35\n","2021-09-20 08:39:45,575 - INFO - joeynmt.training - Epoch  35, Step:    24900, Batch Loss:     1.770021, Tokens per Sec:    14303, Lr: 0.000300\n","2021-09-20 08:39:59,311 - INFO - joeynmt.training - Epoch  35, Step:    25000, Batch Loss:     1.846925, Tokens per Sec:    14435, Lr: 0.000300\n","2021-09-20 08:40:07,663 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:40:07,663 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:40:07,663 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:40:07,669 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:40:08,049 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/22000.ckpt\n","2021-09-20 08:40:08,070 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:40:08,070 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:40:08,071 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:40:08,071 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.6.04 crore will be required for a period of a year 2018-19 .\n","2021-09-20 08:40:08,071 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:40:08,071 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:40:08,071 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:40:08,071 - INFO - joeynmt.training - \tHypothesis: These are going to be that we are going to do that it is not going to be done , but our pace is not a single pace .\n","2021-09-20 08:40:08,071 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:40:08,071 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:40:08,072 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:40:08,072 - INFO - joeynmt.training - \tHypothesis: 4 . To establish exchange programmes for cooperation in human resource development .\n","2021-09-20 08:40:08,072 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:40:08,072 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:40:08,072 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:40:08,072 - INFO - joeynmt.training - \tHypothesis: I also thank him for the desire of our heritage .\n","2021-09-20 08:40:08,072 - INFO - joeynmt.training - Validation result (greedy) at epoch  35, step    25000: bleu:  24.12, loss: 27878.5723, ppl:   6.2725, duration: 8.7610s\n","2021-09-20 08:40:21,664 - INFO - joeynmt.training - Epoch  35, Step:    25100, Batch Loss:     1.728452, Tokens per Sec:    14551, Lr: 0.000300\n","2021-09-20 08:40:35,447 - INFO - joeynmt.training - Epoch  35, Step:    25200, Batch Loss:     1.750001, Tokens per Sec:    14440, Lr: 0.000300\n","2021-09-20 08:40:49,073 - INFO - joeynmt.training - Epoch  35, Step:    25300, Batch Loss:     1.838938, Tokens per Sec:    14543, Lr: 0.000300\n","2021-09-20 08:41:02,815 - INFO - joeynmt.training - Epoch  35, Step:    25400, Batch Loss:     1.814500, Tokens per Sec:    14347, Lr: 0.000300\n","2021-09-20 08:41:16,631 - INFO - joeynmt.training - Epoch  35, Step:    25500, Batch Loss:     1.856308, Tokens per Sec:    14297, Lr: 0.000300\n","2021-09-20 08:41:25,043 - INFO - joeynmt.training - Epoch  35: total training loss 1300.87\n","2021-09-20 08:41:25,044 - INFO - joeynmt.training - EPOCH 36\n","2021-09-20 08:41:30,358 - INFO - joeynmt.training - Epoch  36, Step:    25600, Batch Loss:     1.705952, Tokens per Sec:    14413, Lr: 0.000300\n","2021-09-20 08:41:43,976 - INFO - joeynmt.training - Epoch  36, Step:    25700, Batch Loss:     1.727533, Tokens per Sec:    14563, Lr: 0.000300\n","2021-09-20 08:41:57,519 - INFO - joeynmt.training - Epoch  36, Step:    25800, Batch Loss:     1.681748, Tokens per Sec:    14654, Lr: 0.000300\n","2021-09-20 08:42:11,013 - INFO - joeynmt.training - Epoch  36, Step:    25900, Batch Loss:     1.815771, Tokens per Sec:    14636, Lr: 0.000300\n","2021-09-20 08:42:24,554 - INFO - joeynmt.training - Epoch  36, Step:    26000, Batch Loss:     1.686166, Tokens per Sec:    14535, Lr: 0.000300\n","2021-09-20 08:42:32,983 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:42:32,983 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:42:32,984 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:42:32,987 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:42:33,338 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/23000.ckpt\n","2021-09-20 08:42:33,360 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:42:33,360 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:42:33,360 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:42:33,360 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 08:42:33,361 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:42:33,361 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:42:33,361 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:42:33,361 - INFO - joeynmt.training - \tHypothesis: These tragers are trying to be conducive that we are not going to do that it is not a single pace , but it is not a single week .\n","2021-09-20 08:42:33,361 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:42:33,361 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:42:33,361 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:42:33,361 - INFO - joeynmt.training - \tHypothesis: 4 . To establish exchange programmes for cooperation in human resources development .\n","2021-09-20 08:42:33,361 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:42:33,362 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:42:33,362 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:42:33,362 - INFO - joeynmt.training - \tHypothesis: I also thank them for their own part of our heritage .\n","2021-09-20 08:42:33,362 - INFO - joeynmt.training - Validation result (greedy) at epoch  36, step    26000: bleu:  24.57, loss: 27803.8906, ppl:   6.2417, duration: 8.8070s\n","2021-09-20 08:42:47,009 - INFO - joeynmt.training - Epoch  36, Step:    26100, Batch Loss:     1.812213, Tokens per Sec:    14431, Lr: 0.000300\n","2021-09-20 08:43:00,741 - INFO - joeynmt.training - Epoch  36, Step:    26200, Batch Loss:     1.663510, Tokens per Sec:    14404, Lr: 0.000300\n","2021-09-20 08:43:13,283 - INFO - joeynmt.training - Epoch  36: total training loss 1289.44\n","2021-09-20 08:43:13,284 - INFO - joeynmt.training - EPOCH 37\n","2021-09-20 08:43:14,443 - INFO - joeynmt.training - Epoch  37, Step:    26300, Batch Loss:     1.696591, Tokens per Sec:    13935, Lr: 0.000300\n","2021-09-20 08:43:27,986 - INFO - joeynmt.training - Epoch  37, Step:    26400, Batch Loss:     1.925827, Tokens per Sec:    14534, Lr: 0.000300\n","2021-09-20 08:43:41,562 - INFO - joeynmt.training - Epoch  37, Step:    26500, Batch Loss:     1.729779, Tokens per Sec:    14543, Lr: 0.000300\n","2021-09-20 08:43:55,102 - INFO - joeynmt.training - Epoch  37, Step:    26600, Batch Loss:     1.804900, Tokens per Sec:    14605, Lr: 0.000300\n","2021-09-20 08:44:08,701 - INFO - joeynmt.training - Epoch  37, Step:    26700, Batch Loss:     1.768809, Tokens per Sec:    14635, Lr: 0.000300\n","2021-09-20 08:44:22,474 - INFO - joeynmt.training - Epoch  37, Step:    26800, Batch Loss:     1.877658, Tokens per Sec:    14340, Lr: 0.000300\n","2021-09-20 08:44:36,007 - INFO - joeynmt.training - Epoch  37, Step:    26900, Batch Loss:     1.882082, Tokens per Sec:    14609, Lr: 0.000300\n","2021-09-20 08:44:49,648 - INFO - joeynmt.training - Epoch  37, Step:    27000, Batch Loss:     1.730588, Tokens per Sec:    14408, Lr: 0.000300\n","2021-09-20 08:44:58,054 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:44:58,054 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:44:58,054 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:44:58,060 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:44:58,432 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/24000.ckpt\n","2021-09-20 08:44:58,453 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:44:58,453 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:44:58,453 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:44:58,453 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.64 crore will be required for a period of a year 2018-19 .\n","2021-09-20 08:44:58,453 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:44:58,454 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:44:58,454 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:44:58,454 - INFO - joeynmt.training - \tHypothesis: These are trying to be done , we are trying to do that they are not going to be done , but they are not a pace of pace .\n","2021-09-20 08:44:58,454 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:44:58,454 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:44:58,454 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:44:58,454 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange programmes for cooperation in human resources development .\n","2021-09-20 08:44:58,454 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:44:58,455 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:44:58,455 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:44:58,455 - INFO - joeynmt.training - \tHypothesis: I also thank him for the pioneering part of our legacy .\n","2021-09-20 08:44:58,455 - INFO - joeynmt.training - Validation result (greedy) at epoch  37, step    27000: bleu:  25.01, loss: 27398.6914, ppl:   6.0773, duration: 8.8062s\n","2021-09-20 08:45:01,516 - INFO - joeynmt.training - Epoch  37: total training loss 1280.59\n","2021-09-20 08:45:01,517 - INFO - joeynmt.training - EPOCH 38\n","2021-09-20 08:45:12,167 - INFO - joeynmt.training - Epoch  38, Step:    27100, Batch Loss:     1.871019, Tokens per Sec:    14407, Lr: 0.000300\n","2021-09-20 08:45:25,842 - INFO - joeynmt.training - Epoch  38, Step:    27200, Batch Loss:     1.834357, Tokens per Sec:    14385, Lr: 0.000300\n","2021-09-20 08:45:39,584 - INFO - joeynmt.training - Epoch  38, Step:    27300, Batch Loss:     1.721928, Tokens per Sec:    14440, Lr: 0.000300\n","2021-09-20 08:45:53,287 - INFO - joeynmt.training - Epoch  38, Step:    27400, Batch Loss:     1.799913, Tokens per Sec:    14433, Lr: 0.000300\n","2021-09-20 08:46:06,938 - INFO - joeynmt.training - Epoch  38, Step:    27500, Batch Loss:     1.817035, Tokens per Sec:    14461, Lr: 0.000300\n","2021-09-20 08:46:20,509 - INFO - joeynmt.training - Epoch  38, Step:    27600, Batch Loss:     1.726781, Tokens per Sec:    14528, Lr: 0.000300\n","2021-09-20 08:46:34,187 - INFO - joeynmt.training - Epoch  38, Step:    27700, Batch Loss:     1.735952, Tokens per Sec:    14459, Lr: 0.000300\n","2021-09-20 08:46:41,350 - INFO - joeynmt.training - Epoch  38: total training loss 1268.16\n","2021-09-20 08:46:41,350 - INFO - joeynmt.training - EPOCH 39\n","2021-09-20 08:46:47,899 - INFO - joeynmt.training - Epoch  39, Step:    27800, Batch Loss:     1.705290, Tokens per Sec:    14075, Lr: 0.000300\n","2021-09-20 08:47:01,578 - INFO - joeynmt.training - Epoch  39, Step:    27900, Batch Loss:     1.677477, Tokens per Sec:    14441, Lr: 0.000300\n","2021-09-20 08:47:15,222 - INFO - joeynmt.training - Epoch  39, Step:    28000, Batch Loss:     1.610689, Tokens per Sec:    14541, Lr: 0.000300\n","2021-09-20 08:47:22,929 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:47:22,930 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:47:22,930 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:47:22,933 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:47:23,297 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/25000.ckpt\n","2021-09-20 08:47:23,316 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:47:23,317 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:47:23,317 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:47:23,317 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of 2018-19 .\n","2021-09-20 08:47:23,317 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:47:23,317 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:47:23,317 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:47:23,317 - INFO - joeynmt.training - \tHypothesis: These conditions are being made right to ensure that they are not being being being done , our speed is not a single .\n","2021-09-20 08:47:23,317 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:47:23,318 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:47:23,318 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:47:23,318 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in human resources development .\n","2021-09-20 08:47:23,318 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:47:23,318 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:47:23,318 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:47:23,318 - INFO - joeynmt.training - \tHypothesis: I also thank him for taking part of our legacy .\n","2021-09-20 08:47:23,318 - INFO - joeynmt.training - Validation result (greedy) at epoch  39, step    28000: bleu:  25.24, loss: 27371.8047, ppl:   6.0666, duration: 8.0959s\n","2021-09-20 08:47:37,104 - INFO - joeynmt.training - Epoch  39, Step:    28100, Batch Loss:     1.717461, Tokens per Sec:    14293, Lr: 0.000300\n","2021-09-20 08:47:50,880 - INFO - joeynmt.training - Epoch  39, Step:    28200, Batch Loss:     1.760403, Tokens per Sec:    14434, Lr: 0.000300\n","2021-09-20 08:48:04,497 - INFO - joeynmt.training - Epoch  39, Step:    28300, Batch Loss:     1.681321, Tokens per Sec:    14445, Lr: 0.000300\n","2021-09-20 08:48:18,075 - INFO - joeynmt.training - Epoch  39, Step:    28400, Batch Loss:     1.772473, Tokens per Sec:    14633, Lr: 0.000300\n","2021-09-20 08:48:29,329 - INFO - joeynmt.training - Epoch  39: total training loss 1257.88\n","2021-09-20 08:48:29,330 - INFO - joeynmt.training - EPOCH 40\n","2021-09-20 08:48:31,703 - INFO - joeynmt.training - Epoch  40, Step:    28500, Batch Loss:     1.554320, Tokens per Sec:    14285, Lr: 0.000300\n","2021-09-20 08:48:45,539 - INFO - joeynmt.training - Epoch  40, Step:    28600, Batch Loss:     1.671142, Tokens per Sec:    14155, Lr: 0.000300\n","2021-09-20 08:48:59,109 - INFO - joeynmt.training - Epoch  40, Step:    28700, Batch Loss:     1.742807, Tokens per Sec:    14579, Lr: 0.000300\n","2021-09-20 08:49:12,724 - INFO - joeynmt.training - Epoch  40, Step:    28800, Batch Loss:     1.771768, Tokens per Sec:    14534, Lr: 0.000300\n","2021-09-20 08:49:26,437 - INFO - joeynmt.training - Epoch  40, Step:    28900, Batch Loss:     1.694464, Tokens per Sec:    14350, Lr: 0.000300\n","2021-09-20 08:49:40,126 - INFO - joeynmt.training - Epoch  40, Step:    29000, Batch Loss:     1.519437, Tokens per Sec:    14457, Lr: 0.000300\n","2021-09-20 08:49:48,106 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:49:48,106 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:49:48,106 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:49:48,111 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:49:48,476 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/26000.ckpt\n","2021-09-20 08:49:48,497 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:49:48,497 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:49:48,497 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:49:48,497 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of one year during 2018-19 .\n","2021-09-20 08:49:48,497 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:49:48,498 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:49:48,498 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:49:48,498 - INFO - joeynmt.training - \tHypothesis: These events are trying to be right , we are trying to have the pace of their pace , not because of their state-of-the-art .\n","2021-09-20 08:49:48,498 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:49:48,498 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:49:48,498 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:49:48,498 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in human resource development .\n","2021-09-20 08:49:48,498 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:49:48,499 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:49:48,499 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:49:48,499 - INFO - joeynmt.training - \tHypothesis: I also thank them for their rich part of our heritage .\n","2021-09-20 08:49:48,499 - INFO - joeynmt.training - Validation result (greedy) at epoch  40, step    29000: bleu:  25.61, loss: 27071.5293, ppl:   5.9478, duration: 8.3722s\n","2021-09-20 08:50:02,258 - INFO - joeynmt.training - Epoch  40, Step:    29100, Batch Loss:     1.725747, Tokens per Sec:    14333, Lr: 0.000300\n","2021-09-20 08:50:15,839 - INFO - joeynmt.training - Epoch  40, Step:    29200, Batch Loss:     1.814285, Tokens per Sec:    14492, Lr: 0.000300\n","2021-09-20 08:50:17,837 - INFO - joeynmt.training - Epoch  40: total training loss 1251.08\n","2021-09-20 08:50:17,838 - INFO - joeynmt.training - EPOCH 41\n","2021-09-20 08:50:29,501 - INFO - joeynmt.training - Epoch  41, Step:    29300, Batch Loss:     1.478272, Tokens per Sec:    14496, Lr: 0.000300\n","2021-09-20 08:50:43,144 - INFO - joeynmt.training - Epoch  41, Step:    29400, Batch Loss:     1.692793, Tokens per Sec:    14347, Lr: 0.000300\n","2021-09-20 08:50:56,844 - INFO - joeynmt.training - Epoch  41, Step:    29500, Batch Loss:     1.681195, Tokens per Sec:    14417, Lr: 0.000300\n","2021-09-20 08:51:10,555 - INFO - joeynmt.training - Epoch  41, Step:    29600, Batch Loss:     1.742110, Tokens per Sec:    14366, Lr: 0.000300\n","2021-09-20 08:51:24,410 - INFO - joeynmt.training - Epoch  41, Step:    29700, Batch Loss:     1.831482, Tokens per Sec:    14427, Lr: 0.000300\n","2021-09-20 08:51:37,908 - INFO - joeynmt.training - Epoch  41, Step:    29800, Batch Loss:     1.606828, Tokens per Sec:    14673, Lr: 0.000300\n","2021-09-20 08:51:51,600 - INFO - joeynmt.training - Epoch  41, Step:    29900, Batch Loss:     1.720767, Tokens per Sec:    14488, Lr: 0.000300\n","2021-09-20 08:51:57,749 - INFO - joeynmt.training - Epoch  41: total training loss 1238.50\n","2021-09-20 08:51:57,749 - INFO - joeynmt.training - EPOCH 42\n","2021-09-20 08:52:05,332 - INFO - joeynmt.training - Epoch  42, Step:    30000, Batch Loss:     1.530819, Tokens per Sec:    14475, Lr: 0.000300\n","2021-09-20 08:52:13,714 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:52:13,714 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:52:13,714 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:52:14,075 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/27000.ckpt\n","2021-09-20 08:52:14,096 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:52:14,097 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:52:14,097 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:52:14,097 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 08:52:14,097 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:52:14,097 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:52:14,097 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:52:14,097 - INFO - joeynmt.training - \tHypothesis: These conventions are being made that we are not right , that they are not going to do it , our momentum is not a single .\n","2021-09-20 08:52:14,098 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:52:14,098 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:52:14,098 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:52:14,098 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange programmes for cooperation in human resource development .\n","2021-09-20 08:52:14,098 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:52:14,098 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:52:14,098 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:52:14,098 - INFO - joeynmt.training - \tHypothesis: I also thank him for his determination to show the multiple part of our heritage .\n","2021-09-20 08:52:14,099 - INFO - joeynmt.training - Validation result (greedy) at epoch  42, step    30000: bleu:  24.96, loss: 27100.8730, ppl:   5.9593, duration: 8.7661s\n","2021-09-20 08:52:27,746 - INFO - joeynmt.training - Epoch  42, Step:    30100, Batch Loss:     1.623243, Tokens per Sec:    14520, Lr: 0.000300\n","2021-09-20 08:52:41,557 - INFO - joeynmt.training - Epoch  42, Step:    30200, Batch Loss:     1.793784, Tokens per Sec:    14242, Lr: 0.000300\n","2021-09-20 08:52:55,401 - INFO - joeynmt.training - Epoch  42, Step:    30300, Batch Loss:     1.561514, Tokens per Sec:    14138, Lr: 0.000300\n","2021-09-20 08:53:09,120 - INFO - joeynmt.training - Epoch  42, Step:    30400, Batch Loss:     1.742479, Tokens per Sec:    14512, Lr: 0.000300\n","2021-09-20 08:53:22,694 - INFO - joeynmt.training - Epoch  42, Step:    30500, Batch Loss:     1.657815, Tokens per Sec:    14597, Lr: 0.000300\n","2021-09-20 08:53:36,508 - INFO - joeynmt.training - Epoch  42, Step:    30600, Batch Loss:     1.621434, Tokens per Sec:    14258, Lr: 0.000300\n","2021-09-20 08:53:46,866 - INFO - joeynmt.training - Epoch  42: total training loss 1230.45\n","2021-09-20 08:53:46,867 - INFO - joeynmt.training - EPOCH 43\n","2021-09-20 08:53:50,385 - INFO - joeynmt.training - Epoch  43, Step:    30700, Batch Loss:     1.666377, Tokens per Sec:    13876, Lr: 0.000300\n","2021-09-20 08:54:03,883 - INFO - joeynmt.training - Epoch  43, Step:    30800, Batch Loss:     1.734794, Tokens per Sec:    14584, Lr: 0.000300\n","2021-09-20 08:54:17,414 - INFO - joeynmt.training - Epoch  43, Step:    30900, Batch Loss:     1.765517, Tokens per Sec:    14559, Lr: 0.000300\n","2021-09-20 08:54:31,085 - INFO - joeynmt.training - Epoch  43, Step:    31000, Batch Loss:     1.670839, Tokens per Sec:    14558, Lr: 0.000300\n","2021-09-20 08:54:39,117 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:54:39,117 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:54:39,117 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:54:39,123 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:54:39,505 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/28000.ckpt\n","2021-09-20 08:54:39,528 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:54:39,528 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:54:39,528 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:54:39,528 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 08:54:39,528 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:54:39,528 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:54:39,528 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:54:39,529 - INFO - joeynmt.training - \tHypothesis: These conditions are being made that we are not right , we are not pace to do it , but they are not a pace of our pace .\n","2021-09-20 08:54:39,529 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:54:39,529 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:54:39,529 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:54:39,529 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in human resource development .\n","2021-09-20 08:54:39,529 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:54:39,529 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:54:39,529 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:54:39,529 - INFO - joeynmt.training - \tHypothesis: I also thank him for taking part of our heritage .\n","2021-09-20 08:54:39,529 - INFO - joeynmt.training - Validation result (greedy) at epoch  43, step    31000: bleu:  25.54, loss: 26678.3750, ppl:   5.7957, duration: 8.4438s\n","2021-09-20 08:54:53,300 - INFO - joeynmt.training - Epoch  43, Step:    31100, Batch Loss:     1.718512, Tokens per Sec:    14407, Lr: 0.000300\n","2021-09-20 08:55:07,113 - INFO - joeynmt.training - Epoch  43, Step:    31200, Batch Loss:     1.707483, Tokens per Sec:    14217, Lr: 0.000300\n","2021-09-20 08:55:20,827 - INFO - joeynmt.training - Epoch  43, Step:    31300, Batch Loss:     1.581776, Tokens per Sec:    14366, Lr: 0.000300\n","2021-09-20 08:55:34,560 - INFO - joeynmt.training - Epoch  43, Step:    31400, Batch Loss:     1.691406, Tokens per Sec:    14440, Lr: 0.000300\n","2021-09-20 08:55:35,335 - INFO - joeynmt.training - Epoch  43: total training loss 1222.49\n","2021-09-20 08:55:35,336 - INFO - joeynmt.training - EPOCH 44\n","2021-09-20 08:55:48,264 - INFO - joeynmt.training - Epoch  44, Step:    31500, Batch Loss:     1.648857, Tokens per Sec:    14300, Lr: 0.000300\n","2021-09-20 08:56:01,786 - INFO - joeynmt.training - Epoch  44, Step:    31600, Batch Loss:     1.627025, Tokens per Sec:    14559, Lr: 0.000300\n","2021-09-20 08:56:15,581 - INFO - joeynmt.training - Epoch  44, Step:    31700, Batch Loss:     1.475257, Tokens per Sec:    14369, Lr: 0.000300\n","2021-09-20 08:56:29,261 - INFO - joeynmt.training - Epoch  44, Step:    31800, Batch Loss:     1.775586, Tokens per Sec:    14430, Lr: 0.000300\n","2021-09-20 08:56:42,950 - INFO - joeynmt.training - Epoch  44, Step:    31900, Batch Loss:     1.677000, Tokens per Sec:    14416, Lr: 0.000300\n","2021-09-20 08:56:56,620 - INFO - joeynmt.training - Epoch  44, Step:    32000, Batch Loss:     1.719940, Tokens per Sec:    14406, Lr: 0.000300\n","2021-09-20 08:57:04,562 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:57:04,562 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:57:04,562 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:57:04,567 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:57:04,918 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/30000.ckpt\n","2021-09-20 08:57:04,937 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:57:04,938 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:57:04,938 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:57:04,938 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of one year during 2018-19 .\n","2021-09-20 08:57:04,938 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:57:04,938 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:57:04,938 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:57:04,938 - INFO - joeynmt.training - \tHypothesis: These tests are going to ensure that they are not going to do that it is not a sleep pace , but our momentum is not a smooth .\n","2021-09-20 08:57:04,938 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:57:04,939 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:57:04,939 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:57:04,939 - INFO - joeynmt.training - \tHypothesis: 4 . To establish exchange programmes for cooperation in human resources development .\n","2021-09-20 08:57:04,939 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:57:04,939 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:57:04,939 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:57:04,939 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing the multiple part of our heritage .\n","2021-09-20 08:57:04,939 - INFO - joeynmt.training - Validation result (greedy) at epoch  44, step    32000: bleu:  26.02, loss: 26651.7285, ppl:   5.7856, duration: 8.3185s\n","2021-09-20 08:57:18,400 - INFO - joeynmt.training - Epoch  44, Step:    32100, Batch Loss:     1.637596, Tokens per Sec:    14691, Lr: 0.000300\n","2021-09-20 08:57:23,339 - INFO - joeynmt.training - Epoch  44: total training loss 1214.30\n","2021-09-20 08:57:23,339 - INFO - joeynmt.training - EPOCH 45\n","2021-09-20 08:57:31,947 - INFO - joeynmt.training - Epoch  45, Step:    32200, Batch Loss:     1.634594, Tokens per Sec:    14553, Lr: 0.000300\n","2021-09-20 08:57:45,593 - INFO - joeynmt.training - Epoch  45, Step:    32300, Batch Loss:     1.716015, Tokens per Sec:    14558, Lr: 0.000300\n","2021-09-20 08:57:59,273 - INFO - joeynmt.training - Epoch  45, Step:    32400, Batch Loss:     1.688568, Tokens per Sec:    14554, Lr: 0.000300\n","2021-09-20 08:58:12,843 - INFO - joeynmt.training - Epoch  45, Step:    32500, Batch Loss:     1.574925, Tokens per Sec:    14522, Lr: 0.000300\n","2021-09-20 08:58:26,679 - INFO - joeynmt.training - Epoch  45, Step:    32600, Batch Loss:     1.621017, Tokens per Sec:    14215, Lr: 0.000300\n","2021-09-20 08:58:40,233 - INFO - joeynmt.training - Epoch  45, Step:    32700, Batch Loss:     1.773033, Tokens per Sec:    14572, Lr: 0.000300\n","2021-09-20 08:58:53,888 - INFO - joeynmt.training - Epoch  45, Step:    32800, Batch Loss:     1.629556, Tokens per Sec:    14431, Lr: 0.000300\n","2021-09-20 08:59:02,841 - INFO - joeynmt.training - Epoch  45: total training loss 1205.49\n","2021-09-20 08:59:02,842 - INFO - joeynmt.training - EPOCH 46\n","2021-09-20 08:59:07,393 - INFO - joeynmt.training - Epoch  46, Step:    32900, Batch Loss:     1.673209, Tokens per Sec:    14509, Lr: 0.000300\n","2021-09-20 08:59:21,096 - INFO - joeynmt.training - Epoch  46, Step:    33000, Batch Loss:     1.451615, Tokens per Sec:    14497, Lr: 0.000300\n","2021-09-20 08:59:28,827 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 08:59:28,827 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 08:59:28,827 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 08:59:28,833 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 08:59:29,194 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/29000.ckpt\n","2021-09-20 08:59:29,217 - INFO - joeynmt.training - Example #0\n","2021-09-20 08:59:29,217 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 08:59:29,218 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 08:59:29,218 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 08:59:29,218 - INFO - joeynmt.training - Example #1\n","2021-09-20 08:59:29,218 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 08:59:29,218 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 08:59:29,218 - INFO - joeynmt.training - \tHypothesis: These tragers are trying to be realized that we are not going to do that our pace , not just because of it is a single .\n","2021-09-20 08:59:29,218 - INFO - joeynmt.training - Example #2\n","2021-09-20 08:59:29,219 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 08:59:29,219 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 08:59:29,219 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in human resource development .\n","2021-09-20 08:59:29,219 - INFO - joeynmt.training - Example #3\n","2021-09-20 08:59:29,219 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 08:59:29,219 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 08:59:29,219 - INFO - joeynmt.training - \tHypothesis: I also thank him for his desire to show the multiple part of our heritage .\n","2021-09-20 08:59:29,219 - INFO - joeynmt.training - Validation result (greedy) at epoch  46, step    33000: bleu:  26.06, loss: 26613.2383, ppl:   5.7709, duration: 8.1234s\n","2021-09-20 08:59:42,844 - INFO - joeynmt.training - Epoch  46, Step:    33100, Batch Loss:     1.651048, Tokens per Sec:    14591, Lr: 0.000300\n","2021-09-20 08:59:56,481 - INFO - joeynmt.training - Epoch  46, Step:    33200, Batch Loss:     1.761781, Tokens per Sec:    14394, Lr: 0.000300\n","2021-09-20 09:00:10,167 - INFO - joeynmt.training - Epoch  46, Step:    33300, Batch Loss:     1.511676, Tokens per Sec:    14354, Lr: 0.000300\n","2021-09-20 09:00:23,732 - INFO - joeynmt.training - Epoch  46, Step:    33400, Batch Loss:     1.593199, Tokens per Sec:    14546, Lr: 0.000300\n","2021-09-20 09:00:37,392 - INFO - joeynmt.training - Epoch  46, Step:    33500, Batch Loss:     1.722216, Tokens per Sec:    14354, Lr: 0.000300\n","2021-09-20 09:00:50,822 - INFO - joeynmt.training - Epoch  46: total training loss 1198.56\n","2021-09-20 09:00:50,823 - INFO - joeynmt.training - EPOCH 47\n","2021-09-20 09:00:51,173 - INFO - joeynmt.training - Epoch  47, Step:    33600, Batch Loss:     1.704420, Tokens per Sec:    11369, Lr: 0.000300\n","2021-09-20 09:01:04,879 - INFO - joeynmt.training - Epoch  47, Step:    33700, Batch Loss:     1.570697, Tokens per Sec:    14383, Lr: 0.000300\n","2021-09-20 09:01:18,489 - INFO - joeynmt.training - Epoch  47, Step:    33800, Batch Loss:     1.613876, Tokens per Sec:    14493, Lr: 0.000300\n","2021-09-20 09:01:32,198 - INFO - joeynmt.training - Epoch  47, Step:    33900, Batch Loss:     1.688612, Tokens per Sec:    14367, Lr: 0.000300\n","2021-09-20 09:01:45,760 - INFO - joeynmt.training - Epoch  47, Step:    34000, Batch Loss:     1.670913, Tokens per Sec:    14515, Lr: 0.000300\n","2021-09-20 09:01:53,695 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:01:53,695 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:01:53,695 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:01:53,699 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:01:54,091 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/31000.ckpt\n","2021-09-20 09:01:54,113 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:01:54,113 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:01:54,113 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:01:54,114 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 09:01:54,114 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:01:54,114 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:01:54,114 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:01:54,114 - INFO - joeynmt.training - \tHypothesis: These are trying to be right , we are trying to have a pace of pace , but our momentum is not just a sleep instalment .\n","2021-09-20 09:01:54,114 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:01:54,114 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:01:54,115 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:01:54,115 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in human resources development .\n","2021-09-20 09:01:54,115 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:01:54,115 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:01:54,115 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:01:54,115 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing the multiple part of our heritage .\n","2021-09-20 09:01:54,115 - INFO - joeynmt.training - Validation result (greedy) at epoch  47, step    34000: bleu:  25.93, loss: 26382.2168, ppl:   5.6838, duration: 8.3549s\n","2021-09-20 09:02:07,760 - INFO - joeynmt.training - Epoch  47, Step:    34100, Batch Loss:     1.528494, Tokens per Sec:    14503, Lr: 0.000300\n","2021-09-20 09:02:21,569 - INFO - joeynmt.training - Epoch  47, Step:    34200, Batch Loss:     1.696293, Tokens per Sec:    14357, Lr: 0.000300\n","2021-09-20 09:02:35,280 - INFO - joeynmt.training - Epoch  47, Step:    34300, Batch Loss:     1.681576, Tokens per Sec:    14291, Lr: 0.000300\n","2021-09-20 09:02:39,308 - INFO - joeynmt.training - Epoch  47: total training loss 1191.97\n","2021-09-20 09:02:39,309 - INFO - joeynmt.training - EPOCH 48\n","2021-09-20 09:02:49,198 - INFO - joeynmt.training - Epoch  48, Step:    34400, Batch Loss:     1.623823, Tokens per Sec:    14089, Lr: 0.000300\n","2021-09-20 09:03:02,882 - INFO - joeynmt.training - Epoch  48, Step:    34500, Batch Loss:     1.521938, Tokens per Sec:    14499, Lr: 0.000300\n","2021-09-20 09:03:16,430 - INFO - joeynmt.training - Epoch  48, Step:    34600, Batch Loss:     1.624376, Tokens per Sec:    14611, Lr: 0.000300\n","2021-09-20 09:03:29,972 - INFO - joeynmt.training - Epoch  48, Step:    34700, Batch Loss:     1.564890, Tokens per Sec:    14562, Lr: 0.000300\n","2021-09-20 09:03:43,514 - INFO - joeynmt.training - Epoch  48, Step:    34800, Batch Loss:     1.721328, Tokens per Sec:    14662, Lr: 0.000300\n","2021-09-20 09:03:57,336 - INFO - joeynmt.training - Epoch  48, Step:    34900, Batch Loss:     1.477175, Tokens per Sec:    14242, Lr: 0.000300\n","2021-09-20 09:04:11,150 - INFO - joeynmt.training - Epoch  48, Step:    35000, Batch Loss:     1.693751, Tokens per Sec:    14351, Lr: 0.000300\n","2021-09-20 09:04:19,036 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:04:19,036 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:04:19,036 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:04:19,042 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:04:19,403 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/32000.ckpt\n","2021-09-20 09:04:19,423 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:04:19,424 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:04:19,424 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:04:19,424 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 09:04:19,424 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:04:19,424 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:04:19,424 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:04:19,424 - INFO - joeynmt.training - \tHypothesis: These are trying , we are trying to ensure that our pace is not going to be done , but is our pace .\n","2021-09-20 09:04:19,425 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:04:19,425 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:04:19,425 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:04:19,425 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in human resources development .\n","2021-09-20 09:04:19,425 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:04:19,425 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:04:19,425 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:04:19,425 - INFO - joeynmt.training - \tHypothesis: I also thank him for the desire of our heritage .\n","2021-09-20 09:04:19,426 - INFO - joeynmt.training - Validation result (greedy) at epoch  48, step    35000: bleu:  26.22, loss: 26256.5176, ppl:   5.6369, duration: 8.2747s\n","2021-09-20 09:04:27,459 - INFO - joeynmt.training - Epoch  48: total training loss 1182.88\n","2021-09-20 09:04:27,460 - INFO - joeynmt.training - EPOCH 49\n","2021-09-20 09:04:33,092 - INFO - joeynmt.training - Epoch  49, Step:    35100, Batch Loss:     1.622918, Tokens per Sec:    14453, Lr: 0.000300\n","2021-09-20 09:04:46,788 - INFO - joeynmt.training - Epoch  49, Step:    35200, Batch Loss:     1.666947, Tokens per Sec:    14487, Lr: 0.000300\n","2021-09-20 09:05:00,330 - INFO - joeynmt.training - Epoch  49, Step:    35300, Batch Loss:     1.528233, Tokens per Sec:    14647, Lr: 0.000300\n","2021-09-20 09:05:13,934 - INFO - joeynmt.training - Epoch  49, Step:    35400, Batch Loss:     1.505898, Tokens per Sec:    14459, Lr: 0.000300\n","2021-09-20 09:05:27,666 - INFO - joeynmt.training - Epoch  49, Step:    35500, Batch Loss:     1.530617, Tokens per Sec:    14386, Lr: 0.000300\n","2021-09-20 09:05:41,401 - INFO - joeynmt.training - Epoch  49, Step:    35600, Batch Loss:     1.648440, Tokens per Sec:    14292, Lr: 0.000300\n","2021-09-20 09:05:55,036 - INFO - joeynmt.training - Epoch  49, Step:    35700, Batch Loss:     1.670009, Tokens per Sec:    14622, Lr: 0.000300\n","2021-09-20 09:06:07,178 - INFO - joeynmt.training - Epoch  49: total training loss 1174.99\n","2021-09-20 09:06:07,178 - INFO - joeynmt.training - EPOCH 50\n","2021-09-20 09:06:08,719 - INFO - joeynmt.training - Epoch  50, Step:    35800, Batch Loss:     1.575882, Tokens per Sec:    14178, Lr: 0.000300\n","2021-09-20 09:06:22,210 - INFO - joeynmt.training - Epoch  50, Step:    35900, Batch Loss:     1.627921, Tokens per Sec:    14608, Lr: 0.000300\n","2021-09-20 09:06:35,722 - INFO - joeynmt.training - Epoch  50, Step:    36000, Batch Loss:     1.521804, Tokens per Sec:    14470, Lr: 0.000300\n","2021-09-20 09:06:43,816 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:06:43,816 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:06:43,816 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:06:43,822 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:06:44,176 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/33000.ckpt\n","2021-09-20 09:06:44,197 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:06:44,198 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:06:44,198 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:06:44,198 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year period 2018-19 .\n","2021-09-20 09:06:44,198 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:06:44,198 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:06:44,198 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:06:44,198 - INFO - joeynmt.training - \tHypothesis: These conventions are going to be that we are not going to do that our pace is not going to be realized .\n","2021-09-20 09:06:44,199 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:06:44,199 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:06:44,199 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:06:44,199 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in Human Resource Development .\n","2021-09-20 09:06:44,199 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:06:44,199 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:06:44,200 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:06:44,200 - INFO - joeynmt.training - \tHypothesis: I also thank him for the part of our heritage .\n","2021-09-20 09:06:44,200 - INFO - joeynmt.training - Validation result (greedy) at epoch  50, step    36000: bleu:  26.00, loss: 26121.7871, ppl:   5.5871, duration: 8.4775s\n","2021-09-20 09:06:57,771 - INFO - joeynmt.training - Epoch  50, Step:    36100, Batch Loss:     1.622373, Tokens per Sec:    14579, Lr: 0.000300\n","2021-09-20 09:07:11,455 - INFO - joeynmt.training - Epoch  50, Step:    36200, Batch Loss:     1.593874, Tokens per Sec:    14478, Lr: 0.000300\n","2021-09-20 09:07:25,245 - INFO - joeynmt.training - Epoch  50, Step:    36300, Batch Loss:     1.531570, Tokens per Sec:    14354, Lr: 0.000300\n","2021-09-20 09:07:38,839 - INFO - joeynmt.training - Epoch  50, Step:    36400, Batch Loss:     1.700566, Tokens per Sec:    14649, Lr: 0.000300\n","2021-09-20 09:07:52,367 - INFO - joeynmt.training - Epoch  50, Step:    36500, Batch Loss:     1.725637, Tokens per Sec:    14639, Lr: 0.000300\n","2021-09-20 09:07:54,890 - INFO - joeynmt.training - Epoch  50: total training loss 1169.10\n","2021-09-20 09:07:54,890 - INFO - joeynmt.training - EPOCH 51\n","2021-09-20 09:08:05,894 - INFO - joeynmt.training - Epoch  51, Step:    36600, Batch Loss:     1.511575, Tokens per Sec:    14470, Lr: 0.000300\n","2021-09-20 09:08:19,691 - INFO - joeynmt.training - Epoch  51, Step:    36700, Batch Loss:     1.675955, Tokens per Sec:    14297, Lr: 0.000300\n","2021-09-20 09:08:33,481 - INFO - joeynmt.training - Epoch  51, Step:    36800, Batch Loss:     1.669537, Tokens per Sec:    14281, Lr: 0.000300\n","2021-09-20 09:08:47,201 - INFO - joeynmt.training - Epoch  51, Step:    36900, Batch Loss:     1.530266, Tokens per Sec:    14412, Lr: 0.000300\n","2021-09-20 09:09:00,798 - INFO - joeynmt.training - Epoch  51, Step:    37000, Batch Loss:     1.411993, Tokens per Sec:    14624, Lr: 0.000300\n","2021-09-20 09:09:08,669 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:09:08,669 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:09:08,669 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:09:08,675 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:09:09,029 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/34000.ckpt\n","2021-09-20 09:09:09,049 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:09:09,050 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:09:09,050 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:09:09,050 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 09:09:09,050 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:09:09,050 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:09:09,050 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:09:09,051 - INFO - joeynmt.training - \tHypothesis: These tragers are trying to be realized that they are not going to be realized , our momentum is not a single story .\n","2021-09-20 09:09:09,051 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:09:09,051 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:09:09,051 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:09:09,051 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in human resource development .\n","2021-09-20 09:09:09,051 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:09:09,051 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:09:09,052 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:09:09,052 - INFO - joeynmt.training - \tHypothesis: I also thank him for taking part of our heritage .\n","2021-09-20 09:09:09,052 - INFO - joeynmt.training - Validation result (greedy) at epoch  51, step    37000: bleu:  26.62, loss: 26016.4961, ppl:   5.5485, duration: 8.2532s\n","2021-09-20 09:09:22,638 - INFO - joeynmt.training - Epoch  51, Step:    37100, Batch Loss:     1.674383, Tokens per Sec:    14489, Lr: 0.000300\n","2021-09-20 09:09:36,236 - INFO - joeynmt.training - Epoch  51, Step:    37200, Batch Loss:     1.546677, Tokens per Sec:    14454, Lr: 0.000300\n","2021-09-20 09:09:43,063 - INFO - joeynmt.training - Epoch  51: total training loss 1163.86\n","2021-09-20 09:09:43,063 - INFO - joeynmt.training - EPOCH 52\n","2021-09-20 09:09:49,951 - INFO - joeynmt.training - Epoch  52, Step:    37300, Batch Loss:     1.518319, Tokens per Sec:    14261, Lr: 0.000300\n","2021-09-20 09:10:03,486 - INFO - joeynmt.training - Epoch  52, Step:    37400, Batch Loss:     1.607893, Tokens per Sec:    14732, Lr: 0.000300\n","2021-09-20 09:10:16,924 - INFO - joeynmt.training - Epoch  52, Step:    37500, Batch Loss:     1.550393, Tokens per Sec:    14768, Lr: 0.000300\n","2021-09-20 09:10:30,567 - INFO - joeynmt.training - Epoch  52, Step:    37600, Batch Loss:     1.628150, Tokens per Sec:    14493, Lr: 0.000300\n","2021-09-20 09:10:44,282 - INFO - joeynmt.training - Epoch  52, Step:    37700, Batch Loss:     1.563866, Tokens per Sec:    14496, Lr: 0.000300\n","2021-09-20 09:10:58,017 - INFO - joeynmt.training - Epoch  52, Step:    37800, Batch Loss:     1.457744, Tokens per Sec:    14329, Lr: 0.000300\n","2021-09-20 09:11:11,762 - INFO - joeynmt.training - Epoch  52, Step:    37900, Batch Loss:     1.689098, Tokens per Sec:    14240, Lr: 0.000300\n","2021-09-20 09:11:22,811 - INFO - joeynmt.training - Epoch  52: total training loss 1157.44\n","2021-09-20 09:11:22,811 - INFO - joeynmt.training - EPOCH 53\n","2021-09-20 09:11:25,481 - INFO - joeynmt.training - Epoch  53, Step:    38000, Batch Loss:     1.501710, Tokens per Sec:    14139, Lr: 0.000300\n","2021-09-20 09:11:33,274 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:11:33,274 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:11:33,275 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:11:33,279 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:11:33,654 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/35000.ckpt\n","2021-09-20 09:11:33,674 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:11:33,675 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:11:33,675 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:11:33,675 - INFO - joeynmt.training - \tHypothesis: The requirement of Rs. 143.64 crore for a period of a year period in 2018-19 will be required .\n","2021-09-20 09:11:33,675 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:11:33,675 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:11:33,675 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:11:33,675 - INFO - joeynmt.training - \tHypothesis: These exams are trying to be right , we are pace to do not only because of it is that it is not just a silos .\n","2021-09-20 09:11:33,675 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:11:33,676 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:11:33,676 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:11:33,676 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in Human Resource Development\n","2021-09-20 09:11:33,676 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:11:33,676 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:11:33,676 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:11:33,676 - INFO - joeynmt.training - \tHypothesis: I also thank him for showing the multi-value of our heritage .\n","2021-09-20 09:11:33,676 - INFO - joeynmt.training - Validation result (greedy) at epoch  53, step    38000: bleu:  26.74, loss: 25928.6562, ppl:   5.5165, duration: 8.1947s\n","2021-09-20 09:11:47,398 - INFO - joeynmt.training - Epoch  53, Step:    38100, Batch Loss:     1.700213, Tokens per Sec:    14333, Lr: 0.000300\n","2021-09-20 09:12:01,169 - INFO - joeynmt.training - Epoch  53, Step:    38200, Batch Loss:     1.768408, Tokens per Sec:    14422, Lr: 0.000300\n","2021-09-20 09:12:14,872 - INFO - joeynmt.training - Epoch  53, Step:    38300, Batch Loss:     1.547834, Tokens per Sec:    14476, Lr: 0.000300\n","2021-09-20 09:12:28,375 - INFO - joeynmt.training - Epoch  53, Step:    38400, Batch Loss:     1.690840, Tokens per Sec:    14590, Lr: 0.000300\n","2021-09-20 09:12:41,825 - INFO - joeynmt.training - Epoch  53, Step:    38500, Batch Loss:     1.700179, Tokens per Sec:    14612, Lr: 0.000300\n","2021-09-20 09:12:55,439 - INFO - joeynmt.training - Epoch  53, Step:    38600, Batch Loss:     1.543796, Tokens per Sec:    14409, Lr: 0.000300\n","2021-09-20 09:13:09,115 - INFO - joeynmt.training - Epoch  53, Step:    38700, Batch Loss:     1.635171, Tokens per Sec:    14540, Lr: 0.000300\n","2021-09-20 09:13:10,761 - INFO - joeynmt.training - Epoch  53: total training loss 1151.78\n","2021-09-20 09:13:10,762 - INFO - joeynmt.training - EPOCH 54\n","2021-09-20 09:13:23,009 - INFO - joeynmt.training - Epoch  54, Step:    38800, Batch Loss:     1.588784, Tokens per Sec:    14209, Lr: 0.000300\n","2021-09-20 09:13:36,772 - INFO - joeynmt.training - Epoch  54, Step:    38900, Batch Loss:     1.498394, Tokens per Sec:    14413, Lr: 0.000300\n","2021-09-20 09:13:50,377 - INFO - joeynmt.training - Epoch  54, Step:    39000, Batch Loss:     1.683776, Tokens per Sec:    14582, Lr: 0.000300\n","2021-09-20 09:13:58,183 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:13:58,183 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:13:58,183 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:13:58,554 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/36000.ckpt\n","2021-09-20 09:13:58,575 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:13:58,575 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:13:58,575 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:13:58,575 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of one year during 2018-19 .\n","2021-09-20 09:13:58,575 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:13:58,575 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:13:58,576 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:13:58,576 - INFO - joeynmt.training - \tHypothesis: These tests are trying that we are not right to do that it is our pace , and our pace is not just a swer .\n","2021-09-20 09:13:58,576 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:13:58,576 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:13:58,576 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:13:58,576 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in human resource development .\n","2021-09-20 09:13:58,576 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:13:58,576 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:13:58,576 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:13:58,576 - INFO - joeynmt.training - \tHypothesis: I also thank him for showing the multiple part of our heritage .\n","2021-09-20 09:13:58,577 - INFO - joeynmt.training - Validation result (greedy) at epoch  54, step    39000: bleu:  26.66, loss: 25955.6055, ppl:   5.5263, duration: 8.1988s\n","2021-09-20 09:14:12,232 - INFO - joeynmt.training - Epoch  54, Step:    39100, Batch Loss:     1.686682, Tokens per Sec:    14481, Lr: 0.000300\n","2021-09-20 09:14:25,937 - INFO - joeynmt.training - Epoch  54, Step:    39200, Batch Loss:     1.677752, Tokens per Sec:    14358, Lr: 0.000300\n","2021-09-20 09:14:39,452 - INFO - joeynmt.training - Epoch  54, Step:    39300, Batch Loss:     1.634677, Tokens per Sec:    14562, Lr: 0.000300\n","2021-09-20 09:14:53,221 - INFO - joeynmt.training - Epoch  54, Step:    39400, Batch Loss:     1.563963, Tokens per Sec:    14323, Lr: 0.000300\n","2021-09-20 09:14:58,960 - INFO - joeynmt.training - Epoch  54: total training loss 1143.62\n","2021-09-20 09:14:58,960 - INFO - joeynmt.training - EPOCH 55\n","2021-09-20 09:15:07,004 - INFO - joeynmt.training - Epoch  55, Step:    39500, Batch Loss:     1.408085, Tokens per Sec:    14167, Lr: 0.000300\n","2021-09-20 09:15:20,768 - INFO - joeynmt.training - Epoch  55, Step:    39600, Batch Loss:     1.589101, Tokens per Sec:    14311, Lr: 0.000300\n","2021-09-20 09:15:34,371 - INFO - joeynmt.training - Epoch  55, Step:    39700, Batch Loss:     1.487652, Tokens per Sec:    14564, Lr: 0.000300\n","2021-09-20 09:15:48,105 - INFO - joeynmt.training - Epoch  55, Step:    39800, Batch Loss:     1.625663, Tokens per Sec:    14362, Lr: 0.000300\n","2021-09-20 09:16:01,828 - INFO - joeynmt.training - Epoch  55, Step:    39900, Batch Loss:     1.597910, Tokens per Sec:    14401, Lr: 0.000300\n","2021-09-20 09:16:15,723 - INFO - joeynmt.training - Epoch  55, Step:    40000, Batch Loss:     1.473513, Tokens per Sec:    14231, Lr: 0.000300\n","2021-09-20 09:16:23,391 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:16:23,391 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:16:23,391 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:16:23,398 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:16:23,772 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/37000.ckpt\n","2021-09-20 09:16:23,793 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:16:23,793 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:16:23,794 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:16:23,794 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 09:16:23,794 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:16:23,794 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:16:23,794 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:16:23,794 - INFO - joeynmt.training - \tHypothesis: These are trying that we are trying to be realized that it is not just a single pace , but it is not a single instalment .\n","2021-09-20 09:16:23,795 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:16:23,795 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:16:23,795 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:16:23,795 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in human resource development .\n","2021-09-20 09:16:23,795 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:16:23,796 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:16:23,796 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:16:23,796 - INFO - joeynmt.training - \tHypothesis: I also thank him for showing the multiple part of our heritage .\n","2021-09-20 09:16:23,796 - INFO - joeynmt.training - Validation result (greedy) at epoch  55, step    40000: bleu:  27.20, loss: 25849.6992, ppl:   5.4879, duration: 8.0723s\n","2021-09-20 09:16:37,458 - INFO - joeynmt.training - Epoch  55, Step:    40100, Batch Loss:     1.601498, Tokens per Sec:    14531, Lr: 0.000300\n","2021-09-20 09:16:47,423 - INFO - joeynmt.training - Epoch  55: total training loss 1139.82\n","2021-09-20 09:16:47,423 - INFO - joeynmt.training - EPOCH 56\n","2021-09-20 09:16:51,246 - INFO - joeynmt.training - Epoch  56, Step:    40200, Batch Loss:     1.554242, Tokens per Sec:    14223, Lr: 0.000300\n","2021-09-20 09:17:04,903 - INFO - joeynmt.training - Epoch  56, Step:    40300, Batch Loss:     1.365161, Tokens per Sec:    14494, Lr: 0.000300\n","2021-09-20 09:17:18,675 - INFO - joeynmt.training - Epoch  56, Step:    40400, Batch Loss:     1.690461, Tokens per Sec:    14457, Lr: 0.000300\n","2021-09-20 09:17:32,279 - INFO - joeynmt.training - Epoch  56, Step:    40500, Batch Loss:     1.492712, Tokens per Sec:    14493, Lr: 0.000300\n","2021-09-20 09:17:45,994 - INFO - joeynmt.training - Epoch  56, Step:    40600, Batch Loss:     1.629853, Tokens per Sec:    14352, Lr: 0.000300\n","2021-09-20 09:17:59,523 - INFO - joeynmt.training - Epoch  56, Step:    40700, Batch Loss:     1.730073, Tokens per Sec:    14545, Lr: 0.000300\n","2021-09-20 09:18:13,331 - INFO - joeynmt.training - Epoch  56, Step:    40800, Batch Loss:     1.539512, Tokens per Sec:    14338, Lr: 0.000300\n","2021-09-20 09:18:27,010 - INFO - joeynmt.training - Epoch  56, Step:    40900, Batch Loss:     1.655217, Tokens per Sec:    14325, Lr: 0.000300\n","2021-09-20 09:18:27,508 - INFO - joeynmt.training - Epoch  56: total training loss 1134.60\n","2021-09-20 09:18:27,509 - INFO - joeynmt.training - EPOCH 57\n","2021-09-20 09:18:40,821 - INFO - joeynmt.training - Epoch  57, Step:    41000, Batch Loss:     1.481488, Tokens per Sec:    14278, Lr: 0.000300\n","2021-09-20 09:18:48,794 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:18:48,794 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:18:48,794 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:18:49,151 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/39000.ckpt\n","2021-09-20 09:18:49,172 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:18:49,172 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:18:49,172 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:18:49,173 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 09:18:49,173 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:18:49,173 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:18:49,173 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:18:49,173 - INFO - joeynmt.training - \tHypothesis: These exams are being true to that they are not going to be realized , our momentum is not just that it is not just a single pace .\n","2021-09-20 09:18:49,173 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:18:49,173 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:18:49,173 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:18:49,173 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange programmes for cooperation in human resources development .\n","2021-09-20 09:18:49,173 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:18:49,174 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:18:49,174 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:18:49,174 - INFO - joeynmt.training - \tHypothesis: I also thank him for showing the valuable part of our heritage .\n","2021-09-20 09:18:49,174 - INFO - joeynmt.training - Validation result (greedy) at epoch  57, step    41000: bleu:  27.06, loss: 25907.0234, ppl:   5.5086, duration: 8.3528s\n","2021-09-20 09:19:02,929 - INFO - joeynmt.training - Epoch  57, Step:    41100, Batch Loss:     1.518807, Tokens per Sec:    14394, Lr: 0.000300\n","2021-09-20 09:19:16,697 - INFO - joeynmt.training - Epoch  57, Step:    41200, Batch Loss:     1.674119, Tokens per Sec:    14440, Lr: 0.000300\n","2021-09-20 09:19:30,281 - INFO - joeynmt.training - Epoch  57, Step:    41300, Batch Loss:     1.613195, Tokens per Sec:    14533, Lr: 0.000300\n","2021-09-20 09:19:43,913 - INFO - joeynmt.training - Epoch  57, Step:    41400, Batch Loss:     1.549824, Tokens per Sec:    14464, Lr: 0.000300\n","2021-09-20 09:19:57,665 - INFO - joeynmt.training - Epoch  57, Step:    41500, Batch Loss:     1.547682, Tokens per Sec:    14281, Lr: 0.000300\n","2021-09-20 09:20:11,429 - INFO - joeynmt.training - Epoch  57, Step:    41600, Batch Loss:     1.573560, Tokens per Sec:    14258, Lr: 0.000300\n","2021-09-20 09:20:16,110 - INFO - joeynmt.training - Epoch  57: total training loss 1128.49\n","2021-09-20 09:20:16,111 - INFO - joeynmt.training - EPOCH 58\n","2021-09-20 09:20:24,977 - INFO - joeynmt.training - Epoch  58, Step:    41700, Batch Loss:     1.313161, Tokens per Sec:    14424, Lr: 0.000300\n","2021-09-20 09:20:38,700 - INFO - joeynmt.training - Epoch  58, Step:    41800, Batch Loss:     1.517259, Tokens per Sec:    14387, Lr: 0.000300\n","2021-09-20 09:20:52,510 - INFO - joeynmt.training - Epoch  58, Step:    41900, Batch Loss:     1.498333, Tokens per Sec:    14338, Lr: 0.000300\n","2021-09-20 09:21:06,325 - INFO - joeynmt.training - Epoch  58, Step:    42000, Batch Loss:     1.553856, Tokens per Sec:    14322, Lr: 0.000300\n","2021-09-20 09:21:15,600 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:21:15,600 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:21:15,601 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:21:15,607 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:21:15,993 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/38000.ckpt\n","2021-09-20 09:21:16,014 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:21:16,014 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:21:16,015 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:21:16,015 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 09:21:16,015 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:21:16,015 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:21:16,015 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:21:16,016 - INFO - joeynmt.training - \tHypothesis: These exams are going to be done that we are not going to do that our pace is not going to be done .\n","2021-09-20 09:21:16,016 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:21:16,016 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:21:16,016 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:21:16,016 - INFO - joeynmt.training - \tHypothesis: 4 . To establish exchange programmes for cooperation in Human Resource Development .\n","2021-09-20 09:21:16,016 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:21:16,016 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:21:16,016 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:21:16,016 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing their valuable part of our heritage .\n","2021-09-20 09:21:16,017 - INFO - joeynmt.training - Validation result (greedy) at epoch  58, step    42000: bleu:  26.69, loss: 25734.4375, ppl:   5.4464, duration: 9.6906s\n","2021-09-20 09:21:29,711 - INFO - joeynmt.training - Epoch  58, Step:    42100, Batch Loss:     1.599917, Tokens per Sec:    14378, Lr: 0.000300\n","2021-09-20 09:21:43,391 - INFO - joeynmt.training - Epoch  58, Step:    42200, Batch Loss:     1.416236, Tokens per Sec:    14420, Lr: 0.000300\n","2021-09-20 09:21:57,340 - INFO - joeynmt.training - Epoch  58, Step:    42300, Batch Loss:     1.409333, Tokens per Sec:    14256, Lr: 0.000300\n","2021-09-20 09:22:06,072 - INFO - joeynmt.training - Epoch  58: total training loss 1121.78\n","2021-09-20 09:22:06,072 - INFO - joeynmt.training - EPOCH 59\n","2021-09-20 09:22:10,889 - INFO - joeynmt.training - Epoch  59, Step:    42400, Batch Loss:     1.439310, Tokens per Sec:    14540, Lr: 0.000300\n","2021-09-20 09:22:24,629 - INFO - joeynmt.training - Epoch  59, Step:    42500, Batch Loss:     1.505245, Tokens per Sec:    14373, Lr: 0.000300\n","2021-09-20 09:22:38,228 - INFO - joeynmt.training - Epoch  59, Step:    42600, Batch Loss:     1.477341, Tokens per Sec:    14516, Lr: 0.000300\n","2021-09-20 09:22:51,940 - INFO - joeynmt.training - Epoch  59, Step:    42700, Batch Loss:     1.541974, Tokens per Sec:    14377, Lr: 0.000300\n","2021-09-20 09:23:05,610 - INFO - joeynmt.training - Epoch  59, Step:    42800, Batch Loss:     1.576224, Tokens per Sec:    14448, Lr: 0.000300\n","2021-09-20 09:23:19,285 - INFO - joeynmt.training - Epoch  59, Step:    42900, Batch Loss:     1.551069, Tokens per Sec:    14379, Lr: 0.000300\n","2021-09-20 09:23:32,943 - INFO - joeynmt.training - Epoch  59, Step:    43000, Batch Loss:     1.536801, Tokens per Sec:    14445, Lr: 0.000300\n","2021-09-20 09:23:41,551 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:23:41,551 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:23:41,551 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:23:41,557 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:23:41,909 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/41000.ckpt\n","2021-09-20 09:23:41,930 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:23:41,930 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:23:41,930 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:23:41,930 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of one year 2018-19 .\n","2021-09-20 09:23:41,930 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:23:41,931 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:23:41,931 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:23:41,931 - INFO - joeynmt.training - \tHypothesis: These exams are being trying that we are not going to be realized that our pace is not just a single way , our pace is not just that they are .\n","2021-09-20 09:23:41,931 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:23:41,931 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:23:41,931 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:23:41,931 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in human resources development .\n","2021-09-20 09:23:41,931 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:23:41,931 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:23:41,931 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:23:41,932 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing their valuable part of our heritage .\n","2021-09-20 09:23:41,932 - INFO - joeynmt.training - Validation result (greedy) at epoch  59, step    43000: bleu:  27.85, loss: 25518.4355, ppl:   5.3694, duration: 8.9883s\n","2021-09-20 09:23:55,132 - INFO - joeynmt.training - Epoch  59: total training loss 1118.36\n","2021-09-20 09:23:55,132 - INFO - joeynmt.training - EPOCH 60\n","2021-09-20 09:23:55,738 - INFO - joeynmt.training - Epoch  60, Step:    43100, Batch Loss:     1.509753, Tokens per Sec:    13305, Lr: 0.000300\n","2021-09-20 09:24:09,362 - INFO - joeynmt.training - Epoch  60, Step:    43200, Batch Loss:     1.435679, Tokens per Sec:    14595, Lr: 0.000300\n","2021-09-20 09:24:23,057 - INFO - joeynmt.training - Epoch  60, Step:    43300, Batch Loss:     1.404171, Tokens per Sec:    14315, Lr: 0.000300\n","2021-09-20 09:24:36,767 - INFO - joeynmt.training - Epoch  60, Step:    43400, Batch Loss:     1.435102, Tokens per Sec:    14543, Lr: 0.000300\n","2021-09-20 09:24:50,317 - INFO - joeynmt.training - Epoch  60, Step:    43500, Batch Loss:     1.580610, Tokens per Sec:    14478, Lr: 0.000300\n","2021-09-20 09:25:04,024 - INFO - joeynmt.training - Epoch  60, Step:    43600, Batch Loss:     1.437199, Tokens per Sec:    14363, Lr: 0.000300\n","2021-09-20 09:25:17,752 - INFO - joeynmt.training - Epoch  60, Step:    43700, Batch Loss:     1.619630, Tokens per Sec:    14360, Lr: 0.000300\n","2021-09-20 09:25:31,461 - INFO - joeynmt.training - Epoch  60, Step:    43800, Batch Loss:     1.556484, Tokens per Sec:    14449, Lr: 0.000300\n","2021-09-20 09:25:35,121 - INFO - joeynmt.training - Epoch  60: total training loss 1113.42\n","2021-09-20 09:25:35,121 - INFO - joeynmt.training - EPOCH 61\n","2021-09-20 09:25:45,241 - INFO - joeynmt.training - Epoch  61, Step:    43900, Batch Loss:     1.549737, Tokens per Sec:    14279, Lr: 0.000300\n","2021-09-20 09:25:59,019 - INFO - joeynmt.training - Epoch  61, Step:    44000, Batch Loss:     1.445669, Tokens per Sec:    14303, Lr: 0.000300\n","2021-09-20 09:26:07,133 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:26:07,133 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:26:07,133 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:26:07,508 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/40000.ckpt\n","2021-09-20 09:26:07,528 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:26:07,528 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:26:07,529 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:26:07,529 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore for a period of a year 2018-19 will be required .\n","2021-09-20 09:26:07,529 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:26:07,529 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:26:07,529 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:26:07,529 - INFO - joeynmt.training - \tHypothesis: These exams are being trying , we are trying to ensure that it is not right , our momentum is not our pace .\n","2021-09-20 09:26:07,529 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:26:07,529 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:26:07,530 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:26:07,530 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in Human Resource Development .\n","2021-09-20 09:26:07,530 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:26:07,530 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:26:07,530 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:26:07,530 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing them ’ s multiple part of our heritage .\n","2021-09-20 09:26:07,530 - INFO - joeynmt.training - Validation result (greedy) at epoch  61, step    44000: bleu:  27.42, loss: 25658.5820, ppl:   5.4192, duration: 8.5106s\n","2021-09-20 09:26:21,171 - INFO - joeynmt.training - Epoch  61, Step:    44100, Batch Loss:     1.491901, Tokens per Sec:    14544, Lr: 0.000300\n","2021-09-20 09:26:34,840 - INFO - joeynmt.training - Epoch  61, Step:    44200, Batch Loss:     1.490520, Tokens per Sec:    14420, Lr: 0.000300\n","2021-09-20 09:26:48,616 - INFO - joeynmt.training - Epoch  61, Step:    44300, Batch Loss:     1.583796, Tokens per Sec:    14347, Lr: 0.000300\n","2021-09-20 09:27:02,490 - INFO - joeynmt.training - Epoch  61, Step:    44400, Batch Loss:     1.672488, Tokens per Sec:    14352, Lr: 0.000300\n","2021-09-20 09:27:16,225 - INFO - joeynmt.training - Epoch  61, Step:    44500, Batch Loss:     1.575404, Tokens per Sec:    14337, Lr: 0.000300\n","2021-09-20 09:27:23,958 - INFO - joeynmt.training - Epoch  61: total training loss 1105.60\n","2021-09-20 09:27:23,959 - INFO - joeynmt.training - EPOCH 62\n","2021-09-20 09:27:29,842 - INFO - joeynmt.training - Epoch  62, Step:    44600, Batch Loss:     1.413081, Tokens per Sec:    14645, Lr: 0.000300\n","2021-09-20 09:27:43,519 - INFO - joeynmt.training - Epoch  62, Step:    44700, Batch Loss:     1.549616, Tokens per Sec:    14447, Lr: 0.000300\n","2021-09-20 09:27:57,084 - INFO - joeynmt.training - Epoch  62, Step:    44800, Batch Loss:     1.533920, Tokens per Sec:    14533, Lr: 0.000300\n","2021-09-20 09:28:10,934 - INFO - joeynmt.training - Epoch  62, Step:    44900, Batch Loss:     1.471253, Tokens per Sec:    14215, Lr: 0.000300\n","2021-09-20 09:28:24,499 - INFO - joeynmt.training - Epoch  62, Step:    45000, Batch Loss:     1.340017, Tokens per Sec:    14579, Lr: 0.000300\n","2021-09-20 09:28:32,462 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:28:32,462 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:28:32,462 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:28:32,468 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:28:32,819 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/42000.ckpt\n","2021-09-20 09:28:32,839 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:28:32,839 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:28:32,839 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:28:32,839 - INFO - joeynmt.training - \tHypothesis: The requirement of Rs. 143.604 crore for a period of one year in 2018-19 will be required for a period of one year .\n","2021-09-20 09:28:32,839 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:28:32,840 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:28:32,840 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:28:32,840 - INFO - joeynmt.training - \tHypothesis: These exams are being true that we are not right , our speed is not just that they are doing .\n","2021-09-20 09:28:32,840 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:28:32,840 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:28:32,840 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:28:32,840 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in Human Resource Development .\n","2021-09-20 09:28:32,840 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:28:32,841 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:28:32,841 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:28:32,841 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing their valuable part of our heritage .\n","2021-09-20 09:28:32,841 - INFO - joeynmt.training - Validation result (greedy) at epoch  62, step    45000: bleu:  27.23, loss: 25422.8340, ppl:   5.3357, duration: 8.3416s\n","2021-09-20 09:28:46,637 - INFO - joeynmt.training - Epoch  62, Step:    45100, Batch Loss:     1.658769, Tokens per Sec:    14341, Lr: 0.000300\n","2021-09-20 09:29:00,250 - INFO - joeynmt.training - Epoch  62, Step:    45200, Batch Loss:     1.550170, Tokens per Sec:    14415, Lr: 0.000300\n","2021-09-20 09:29:12,093 - INFO - joeynmt.training - Epoch  62: total training loss 1101.49\n","2021-09-20 09:29:12,094 - INFO - joeynmt.training - EPOCH 63\n","2021-09-20 09:29:13,965 - INFO - joeynmt.training - Epoch  63, Step:    45300, Batch Loss:     1.396966, Tokens per Sec:    13539, Lr: 0.000300\n","2021-09-20 09:29:27,627 - INFO - joeynmt.training - Epoch  63, Step:    45400, Batch Loss:     1.576568, Tokens per Sec:    14501, Lr: 0.000300\n","2021-09-20 09:29:41,239 - INFO - joeynmt.training - Epoch  63, Step:    45500, Batch Loss:     1.659159, Tokens per Sec:    14462, Lr: 0.000300\n","2021-09-20 09:29:54,866 - INFO - joeynmt.training - Epoch  63, Step:    45600, Batch Loss:     1.539724, Tokens per Sec:    14596, Lr: 0.000300\n","2021-09-20 09:30:08,360 - INFO - joeynmt.training - Epoch  63, Step:    45700, Batch Loss:     1.601921, Tokens per Sec:    14565, Lr: 0.000300\n","2021-09-20 09:30:21,928 - INFO - joeynmt.training - Epoch  63, Step:    45800, Batch Loss:     1.470280, Tokens per Sec:    14569, Lr: 0.000300\n","2021-09-20 09:30:35,514 - INFO - joeynmt.training - Epoch  63, Step:    45900, Batch Loss:     1.695784, Tokens per Sec:    14431, Lr: 0.000300\n","2021-09-20 09:30:49,186 - INFO - joeynmt.training - Epoch  63, Step:    46000, Batch Loss:     1.543202, Tokens per Sec:    14456, Lr: 0.000300\n","2021-09-20 09:30:57,129 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:30:57,130 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:30:57,130 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:30:57,135 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:30:57,510 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/44000.ckpt\n","2021-09-20 09:30:57,529 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:30:57,529 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:30:57,530 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:30:57,530 - INFO - joeynmt.training - \tHypothesis: The requirement of Rs. 143.604 crore for a period of one year during 2018-19 will be required .\n","2021-09-20 09:30:57,530 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:30:57,530 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:30:57,530 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:30:57,530 - INFO - joeynmt.training - \tHypothesis: These exams are trying that we are not trying to be realized , our momentum is not just that they are doing .\n","2021-09-20 09:30:57,530 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:30:57,530 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:30:57,530 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:30:57,530 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange programmes for cooperation in Human Resource Development\n","2021-09-20 09:30:57,531 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:30:57,531 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:30:57,531 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:30:57,531 - INFO - joeynmt.training - \tHypothesis: I also thank them for their desire to show the valuable part of our heritage .\n","2021-09-20 09:30:57,531 - INFO - joeynmt.training - Validation result (greedy) at epoch  63, step    46000: bleu:  27.88, loss: 25322.7383, ppl:   5.3007, duration: 8.3449s\n","2021-09-20 09:30:59,996 - INFO - joeynmt.training - Epoch  63: total training loss 1096.92\n","2021-09-20 09:30:59,997 - INFO - joeynmt.training - EPOCH 64\n","2021-09-20 09:31:11,467 - INFO - joeynmt.training - Epoch  64, Step:    46100, Batch Loss:     1.701561, Tokens per Sec:    14074, Lr: 0.000300\n","2021-09-20 09:31:25,074 - INFO - joeynmt.training - Epoch  64, Step:    46200, Batch Loss:     1.423826, Tokens per Sec:    14565, Lr: 0.000300\n","2021-09-20 09:31:38,874 - INFO - joeynmt.training - Epoch  64, Step:    46300, Batch Loss:     1.530185, Tokens per Sec:    14312, Lr: 0.000300\n","2021-09-20 09:31:52,506 - INFO - joeynmt.training - Epoch  64, Step:    46400, Batch Loss:     1.637040, Tokens per Sec:    14490, Lr: 0.000300\n","2021-09-20 09:32:06,019 - INFO - joeynmt.training - Epoch  64, Step:    46500, Batch Loss:     1.485037, Tokens per Sec:    14638, Lr: 0.000300\n","2021-09-20 09:32:19,848 - INFO - joeynmt.training - Epoch  64, Step:    46600, Batch Loss:     1.621415, Tokens per Sec:    14287, Lr: 0.000300\n","2021-09-20 09:32:33,367 - INFO - joeynmt.training - Epoch  64, Step:    46700, Batch Loss:     1.425590, Tokens per Sec:    14633, Lr: 0.000300\n","2021-09-20 09:32:39,875 - INFO - joeynmt.training - Epoch  64: total training loss 1092.74\n","2021-09-20 09:32:39,875 - INFO - joeynmt.training - EPOCH 65\n","2021-09-20 09:32:47,042 - INFO - joeynmt.training - Epoch  65, Step:    46800, Batch Loss:     1.463882, Tokens per Sec:    14319, Lr: 0.000300\n","2021-09-20 09:33:00,614 - INFO - joeynmt.training - Epoch  65, Step:    46900, Batch Loss:     1.450969, Tokens per Sec:    14516, Lr: 0.000300\n","2021-09-20 09:33:14,222 - INFO - joeynmt.training - Epoch  65, Step:    47000, Batch Loss:     1.412365, Tokens per Sec:    14625, Lr: 0.000300\n","2021-09-20 09:33:22,247 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:33:22,248 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:33:22,248 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:33:22,616 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/43000.ckpt\n","2021-09-20 09:33:22,637 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:33:22,637 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:33:22,637 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:33:22,637 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 09:33:22,638 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:33:22,638 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:33:22,638 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:33:22,638 - INFO - joeynmt.training - \tHypothesis: These exams are going to be realized that we are not going to say that it is not just a single pace , our momentum is not just that it is not just a single .\n","2021-09-20 09:33:22,638 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:33:22,638 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:33:22,638 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:33:22,638 - INFO - joeynmt.training - \tHypothesis: . To establish programmes for cooperation in Human Resource Development\n","2021-09-20 09:33:22,638 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:33:22,639 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:33:22,639 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:33:22,639 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing their valuable part of our heritage .\n","2021-09-20 09:33:22,639 - INFO - joeynmt.training - Validation result (greedy) at epoch  65, step    47000: bleu:  27.94, loss: 25410.2637, ppl:   5.3313, duration: 8.4161s\n","2021-09-20 09:33:36,242 - INFO - joeynmt.training - Epoch  65, Step:    47100, Batch Loss:     1.581309, Tokens per Sec:    14553, Lr: 0.000300\n","2021-09-20 09:33:49,818 - INFO - joeynmt.training - Epoch  65, Step:    47200, Batch Loss:     1.410841, Tokens per Sec:    14432, Lr: 0.000300\n","2021-09-20 09:34:03,437 - INFO - joeynmt.training - Epoch  65, Step:    47300, Batch Loss:     1.620957, Tokens per Sec:    14519, Lr: 0.000300\n","2021-09-20 09:34:17,092 - INFO - joeynmt.training - Epoch  65, Step:    47400, Batch Loss:     1.379150, Tokens per Sec:    14449, Lr: 0.000300\n","2021-09-20 09:34:27,836 - INFO - joeynmt.training - Epoch  65: total training loss 1089.68\n","2021-09-20 09:34:27,836 - INFO - joeynmt.training - EPOCH 66\n","2021-09-20 09:34:30,807 - INFO - joeynmt.training - Epoch  66, Step:    47500, Batch Loss:     1.539547, Tokens per Sec:    13960, Lr: 0.000300\n","2021-09-20 09:34:44,494 - INFO - joeynmt.training - Epoch  66, Step:    47600, Batch Loss:     1.441725, Tokens per Sec:    14459, Lr: 0.000300\n","2021-09-20 09:34:58,112 - INFO - joeynmt.training - Epoch  66, Step:    47700, Batch Loss:     1.377896, Tokens per Sec:    14545, Lr: 0.000300\n","2021-09-20 09:35:11,874 - INFO - joeynmt.training - Epoch  66, Step:    47800, Batch Loss:     1.552108, Tokens per Sec:    14208, Lr: 0.000300\n","2021-09-20 09:35:25,474 - INFO - joeynmt.training - Epoch  66, Step:    47900, Batch Loss:     1.517666, Tokens per Sec:    14494, Lr: 0.000300\n","2021-09-20 09:35:39,289 - INFO - joeynmt.training - Epoch  66, Step:    48000, Batch Loss:     1.525524, Tokens per Sec:    14385, Lr: 0.000300\n","2021-09-20 09:35:47,294 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:35:47,295 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:35:47,295 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:35:47,662 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/45000.ckpt\n","2021-09-20 09:35:47,683 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:35:47,683 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:35:47,683 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:35:47,683 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 09:35:47,684 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:35:47,684 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:35:47,684 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:35:47,684 - INFO - joeynmt.training - \tHypothesis: These exams are going to be realized that we are not going to realize it , it is not a pace of our pace , but it is not a single instalment .\n","2021-09-20 09:35:47,684 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:35:47,684 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:35:47,684 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:35:47,684 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange programmes for cooperation in human resources development .\n","2021-09-20 09:35:47,684 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:35:47,685 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:35:47,685 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:35:47,685 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing the valuable part of our heritage .\n","2021-09-20 09:35:47,685 - INFO - joeynmt.training - Validation result (greedy) at epoch  66, step    48000: bleu:  27.34, loss: 25322.8672, ppl:   5.3007, duration: 8.3954s\n","2021-09-20 09:36:01,332 - INFO - joeynmt.training - Epoch  66, Step:    48100, Batch Loss:     1.629758, Tokens per Sec:    14458, Lr: 0.000300\n","2021-09-20 09:36:15,258 - INFO - joeynmt.training - Epoch  66, Step:    48200, Batch Loss:     1.470116, Tokens per Sec:    14211, Lr: 0.000300\n","2021-09-20 09:36:16,557 - INFO - joeynmt.training - Epoch  66: total training loss 1084.83\n","2021-09-20 09:36:16,558 - INFO - joeynmt.training - EPOCH 67\n","2021-09-20 09:36:28,889 - INFO - joeynmt.training - Epoch  67, Step:    48300, Batch Loss:     1.351100, Tokens per Sec:    14340, Lr: 0.000300\n","2021-09-20 09:36:42,716 - INFO - joeynmt.training - Epoch  67, Step:    48400, Batch Loss:     1.507578, Tokens per Sec:    14166, Lr: 0.000300\n","2021-09-20 09:36:56,481 - INFO - joeynmt.training - Epoch  67, Step:    48500, Batch Loss:     1.358655, Tokens per Sec:    14459, Lr: 0.000300\n","2021-09-20 09:37:10,136 - INFO - joeynmt.training - Epoch  67, Step:    48600, Batch Loss:     1.540466, Tokens per Sec:    14577, Lr: 0.000300\n","2021-09-20 09:37:23,866 - INFO - joeynmt.training - Epoch  67, Step:    48700, Batch Loss:     1.513915, Tokens per Sec:    14314, Lr: 0.000300\n","2021-09-20 09:37:37,577 - INFO - joeynmt.training - Epoch  67, Step:    48800, Batch Loss:     1.416090, Tokens per Sec:    14461, Lr: 0.000300\n","2021-09-20 09:37:51,257 - INFO - joeynmt.training - Epoch  67, Step:    48900, Batch Loss:     1.637204, Tokens per Sec:    14495, Lr: 0.000300\n","2021-09-20 09:37:56,811 - INFO - joeynmt.training - Epoch  67: total training loss 1080.53\n","2021-09-20 09:37:56,811 - INFO - joeynmt.training - EPOCH 68\n","2021-09-20 09:38:04,865 - INFO - joeynmt.training - Epoch  68, Step:    49000, Batch Loss:     1.433305, Tokens per Sec:    14526, Lr: 0.000300\n","2021-09-20 09:38:13,242 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:38:13,242 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:38:13,242 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:38:13,614 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/47000.ckpt\n","2021-09-20 09:38:13,635 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:38:13,635 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:38:13,635 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:38:13,635 - INFO - joeynmt.training - \tHypothesis: The requirement of Rs. 143.604 crore for a period of a year 2018-19 will be required .\n","2021-09-20 09:38:13,635 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:38:13,636 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:38:13,636 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:38:13,636 - INFO - joeynmt.training - \tHypothesis: These exams are being trying that we are not going to be realized that it is not just a single pace .\n","2021-09-20 09:38:13,636 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:38:13,636 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:38:13,636 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:38:13,636 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in Human Resource Development .\n","2021-09-20 09:38:13,636 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:38:13,636 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:38:13,636 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:38:13,636 - INFO - joeynmt.training - \tHypothesis: I also thank him for showing the valuable part of our heritage .\n","2021-09-20 09:38:13,637 - INFO - joeynmt.training - Validation result (greedy) at epoch  68, step    49000: bleu:  27.68, loss: 25394.7500, ppl:   5.3259, duration: 8.7708s\n","2021-09-20 09:38:27,156 - INFO - joeynmt.training - Epoch  68, Step:    49100, Batch Loss:     1.494097, Tokens per Sec:    14620, Lr: 0.000300\n","2021-09-20 09:38:40,820 - INFO - joeynmt.training - Epoch  68, Step:    49200, Batch Loss:     1.534380, Tokens per Sec:    14554, Lr: 0.000300\n","2021-09-20 09:38:54,405 - INFO - joeynmt.training - Epoch  68, Step:    49300, Batch Loss:     1.460688, Tokens per Sec:    14545, Lr: 0.000300\n","2021-09-20 09:39:08,017 - INFO - joeynmt.training - Epoch  68, Step:    49400, Batch Loss:     1.611342, Tokens per Sec:    14500, Lr: 0.000300\n","2021-09-20 09:39:21,558 - INFO - joeynmt.training - Epoch  68, Step:    49500, Batch Loss:     1.481410, Tokens per Sec:    14517, Lr: 0.000300\n","2021-09-20 09:39:35,190 - INFO - joeynmt.training - Epoch  68, Step:    49600, Batch Loss:     1.383959, Tokens per Sec:    14355, Lr: 0.000300\n","2021-09-20 09:39:45,175 - INFO - joeynmt.training - Epoch  68: total training loss 1077.32\n","2021-09-20 09:39:45,176 - INFO - joeynmt.training - EPOCH 69\n","2021-09-20 09:39:48,988 - INFO - joeynmt.training - Epoch  69, Step:    49700, Batch Loss:     1.274785, Tokens per Sec:    14292, Lr: 0.000300\n","2021-09-20 09:40:02,538 - INFO - joeynmt.training - Epoch  69, Step:    49800, Batch Loss:     1.501367, Tokens per Sec:    14516, Lr: 0.000300\n","2021-09-20 09:40:16,253 - INFO - joeynmt.training - Epoch  69, Step:    49900, Batch Loss:     1.531612, Tokens per Sec:    14352, Lr: 0.000300\n","2021-09-20 09:40:30,079 - INFO - joeynmt.training - Epoch  69, Step:    50000, Batch Loss:     1.447224, Tokens per Sec:    14339, Lr: 0.000300\n","2021-09-20 09:40:37,851 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:40:37,851 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:40:37,851 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:40:37,857 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:40:38,214 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/49000.ckpt\n","2021-09-20 09:40:38,234 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:40:38,235 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:40:38,235 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:40:38,235 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of one year during 2018-19 .\n","2021-09-20 09:40:38,235 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:40:38,235 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:40:38,235 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:40:38,235 - INFO - joeynmt.training - \tHypothesis: These exams are trying to be right that they are not just because of our pace , it is not just a silos .\n","2021-09-20 09:40:38,235 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:40:38,236 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:40:38,236 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:40:38,236 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in Human Resource Development .\n","2021-09-20 09:40:38,236 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:40:38,236 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:40:38,236 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:40:38,236 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing the multi-value of our heritage .\n","2021-09-20 09:40:38,236 - INFO - joeynmt.training - Validation result (greedy) at epoch  69, step    50000: bleu:  27.58, loss: 25182.2031, ppl:   5.2518, duration: 8.1564s\n","2021-09-20 09:40:51,875 - INFO - joeynmt.training - Epoch  69, Step:    50100, Batch Loss:     1.352842, Tokens per Sec:    14371, Lr: 0.000300\n","2021-09-20 09:41:05,485 - INFO - joeynmt.training - Epoch  69, Step:    50200, Batch Loss:     1.532317, Tokens per Sec:    14522, Lr: 0.000300\n","2021-09-20 09:41:18,943 - INFO - joeynmt.training - Epoch  69, Step:    50300, Batch Loss:     1.447843, Tokens per Sec:    14706, Lr: 0.000300\n","2021-09-20 09:41:32,617 - INFO - joeynmt.training - Epoch  69, Step:    50400, Batch Loss:     1.384037, Tokens per Sec:    14519, Lr: 0.000300\n","2021-09-20 09:41:33,012 - INFO - joeynmt.training - Epoch  69: total training loss 1072.19\n","2021-09-20 09:41:33,012 - INFO - joeynmt.training - EPOCH 70\n","2021-09-20 09:41:46,332 - INFO - joeynmt.training - Epoch  70, Step:    50500, Batch Loss:     1.394493, Tokens per Sec:    14474, Lr: 0.000300\n","2021-09-20 09:42:00,003 - INFO - joeynmt.training - Epoch  70, Step:    50600, Batch Loss:     1.574905, Tokens per Sec:    14540, Lr: 0.000300\n","2021-09-20 09:42:13,601 - INFO - joeynmt.training - Epoch  70, Step:    50700, Batch Loss:     1.400498, Tokens per Sec:    14609, Lr: 0.000300\n","2021-09-20 09:42:27,209 - INFO - joeynmt.training - Epoch  70, Step:    50800, Batch Loss:     1.477951, Tokens per Sec:    14485, Lr: 0.000300\n","2021-09-20 09:42:41,070 - INFO - joeynmt.training - Epoch  70, Step:    50900, Batch Loss:     1.541305, Tokens per Sec:    14135, Lr: 0.000300\n","2021-09-20 09:42:54,669 - INFO - joeynmt.training - Epoch  70, Step:    51000, Batch Loss:     1.490667, Tokens per Sec:    14632, Lr: 0.000300\n","2021-09-20 09:43:02,711 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:43:02,711 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:43:02,711 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:43:02,717 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:43:03,068 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/48000.ckpt\n","2021-09-20 09:43:03,090 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:43:03,091 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:43:03,091 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:43:03,091 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of one year during 2018-19 .\n","2021-09-20 09:43:03,091 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:43:03,091 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:43:03,091 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:43:03,091 - INFO - joeynmt.training - \tHypothesis: These exams are trying to be realized that we are not going to realize that our momentum , our momentum is not a single instalment .\n","2021-09-20 09:43:03,091 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:43:03,092 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:43:03,092 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:43:03,092 - INFO - joeynmt.training - \tHypothesis: 4 . To establish exchange programmes for cooperation in Human Resource Development .\n","2021-09-20 09:43:03,092 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:43:03,092 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:43:03,092 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:43:03,092 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing their valuable part of our heritage .\n","2021-09-20 09:43:03,092 - INFO - joeynmt.training - Validation result (greedy) at epoch  70, step    51000: bleu:  27.57, loss: 25076.1680, ppl:   5.2153, duration: 8.4227s\n","2021-09-20 09:43:16,809 - INFO - joeynmt.training - Epoch  70, Step:    51100, Batch Loss:     1.489072, Tokens per Sec:    14407, Lr: 0.000300\n","2021-09-20 09:43:21,252 - INFO - joeynmt.training - Epoch  70: total training loss 1065.95\n","2021-09-20 09:43:21,252 - INFO - joeynmt.training - EPOCH 71\n","2021-09-20 09:43:30,601 - INFO - joeynmt.training - Epoch  71, Step:    51200, Batch Loss:     1.439661, Tokens per Sec:    14267, Lr: 0.000300\n","2021-09-20 09:43:44,330 - INFO - joeynmt.training - Epoch  71, Step:    51300, Batch Loss:     1.421982, Tokens per Sec:    14426, Lr: 0.000300\n","2021-09-20 09:43:57,991 - INFO - joeynmt.training - Epoch  71, Step:    51400, Batch Loss:     1.350544, Tokens per Sec:    14453, Lr: 0.000300\n","2021-09-20 09:44:11,691 - INFO - joeynmt.training - Epoch  71, Step:    51500, Batch Loss:     1.490417, Tokens per Sec:    14514, Lr: 0.000300\n","2021-09-20 09:44:25,243 - INFO - joeynmt.training - Epoch  71, Step:    51600, Batch Loss:     1.528547, Tokens per Sec:    14520, Lr: 0.000300\n","2021-09-20 09:44:38,906 - INFO - joeynmt.training - Epoch  71, Step:    51700, Batch Loss:     1.388391, Tokens per Sec:    14385, Lr: 0.000300\n","2021-09-20 09:44:52,616 - INFO - joeynmt.training - Epoch  71, Step:    51800, Batch Loss:     1.449625, Tokens per Sec:    14438, Lr: 0.000300\n","2021-09-20 09:45:01,256 - INFO - joeynmt.training - Epoch  71: total training loss 1065.61\n","2021-09-20 09:45:01,256 - INFO - joeynmt.training - EPOCH 72\n","2021-09-20 09:45:06,394 - INFO - joeynmt.training - Epoch  72, Step:    51900, Batch Loss:     1.492133, Tokens per Sec:    14070, Lr: 0.000300\n","2021-09-20 09:45:20,046 - INFO - joeynmt.training - Epoch  72, Step:    52000, Batch Loss:     1.428171, Tokens per Sec:    14511, Lr: 0.000300\n","2021-09-20 09:45:28,283 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:45:28,284 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:45:28,284 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:45:28,290 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:45:28,679 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/46000.ckpt\n","2021-09-20 09:45:28,699 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:45:28,700 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:45:28,700 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:45:28,700 - INFO - joeynmt.training - \tHypothesis: During 2018-19 , the requirement of Rs. 143.604 crore will be required for a period of one year .\n","2021-09-20 09:45:28,700 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:45:28,700 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:45:28,701 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:45:28,701 - INFO - joeynmt.training - \tHypothesis: These exams are trying to be realized that they are not going to realize that our pace is not just a single stalwart .\n","2021-09-20 09:45:28,701 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:45:28,701 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:45:28,701 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:45:28,701 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in Human Resource Development .\n","2021-09-20 09:45:28,702 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:45:28,702 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:45:28,702 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:45:28,702 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing their valuable part of our heritage .\n","2021-09-20 09:45:28,702 - INFO - joeynmt.training - Validation result (greedy) at epoch  72, step    52000: bleu:  28.38, loss: 24957.4785, ppl:   5.1747, duration: 8.6553s\n","2021-09-20 09:45:42,430 - INFO - joeynmt.training - Epoch  72, Step:    52100, Batch Loss:     1.541384, Tokens per Sec:    14281, Lr: 0.000300\n","2021-09-20 09:45:56,058 - INFO - joeynmt.training - Epoch  72, Step:    52200, Batch Loss:     1.557320, Tokens per Sec:    14445, Lr: 0.000300\n","2021-09-20 09:46:09,802 - INFO - joeynmt.training - Epoch  72, Step:    52300, Batch Loss:     1.600947, Tokens per Sec:    14319, Lr: 0.000300\n","2021-09-20 09:46:23,362 - INFO - joeynmt.training - Epoch  72, Step:    52400, Batch Loss:     1.360213, Tokens per Sec:    14533, Lr: 0.000300\n","2021-09-20 09:46:37,081 - INFO - joeynmt.training - Epoch  72, Step:    52500, Batch Loss:     1.420535, Tokens per Sec:    14478, Lr: 0.000300\n","2021-09-20 09:46:49,924 - INFO - joeynmt.training - Epoch  72: total training loss 1061.01\n","2021-09-20 09:46:49,924 - INFO - joeynmt.training - EPOCH 73\n","2021-09-20 09:46:50,834 - INFO - joeynmt.training - Epoch  73, Step:    52600, Batch Loss:     1.398868, Tokens per Sec:    13365, Lr: 0.000300\n","2021-09-20 09:47:04,602 - INFO - joeynmt.training - Epoch  73, Step:    52700, Batch Loss:     1.400353, Tokens per Sec:    14406, Lr: 0.000300\n","2021-09-20 09:47:18,343 - INFO - joeynmt.training - Epoch  73, Step:    52800, Batch Loss:     1.575148, Tokens per Sec:    14401, Lr: 0.000300\n","2021-09-20 09:47:32,032 - INFO - joeynmt.training - Epoch  73, Step:    52900, Batch Loss:     1.685746, Tokens per Sec:    14517, Lr: 0.000300\n","2021-09-20 09:47:45,615 - INFO - joeynmt.training - Epoch  73, Step:    53000, Batch Loss:     1.424166, Tokens per Sec:    14504, Lr: 0.000300\n","2021-09-20 09:47:53,946 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:47:53,946 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:47:53,946 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:47:54,317 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/50000.ckpt\n","2021-09-20 09:47:54,337 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:47:54,338 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:47:54,338 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:47:54,338 - INFO - joeynmt.training - \tHypothesis: During 2018-19 , the amount of Rs. 143.604 crore will be required for a period of one year .\n","2021-09-20 09:47:54,338 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:47:54,338 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:47:54,338 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:47:54,338 - INFO - joeynmt.training - \tHypothesis: These exams are being right that we are not going to be realized that it is our pace that it is not just a single instalment .\n","2021-09-20 09:47:54,338 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:47:54,339 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:47:54,339 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:47:54,339 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange programmes for cooperation in Human Resource Development\n","2021-09-20 09:47:54,339 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:47:54,339 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:47:54,339 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:47:54,339 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing their valuable part of our heritage .\n","2021-09-20 09:47:54,339 - INFO - joeynmt.training - Validation result (greedy) at epoch  73, step    53000: bleu:  27.79, loss: 25048.7812, ppl:   5.2059, duration: 8.7237s\n","2021-09-20 09:48:08,076 - INFO - joeynmt.training - Epoch  73, Step:    53100, Batch Loss:     1.360609, Tokens per Sec:    14281, Lr: 0.000300\n","2021-09-20 09:48:21,697 - INFO - joeynmt.training - Epoch  73, Step:    53200, Batch Loss:     1.361363, Tokens per Sec:    14536, Lr: 0.000300\n","2021-09-20 09:48:35,352 - INFO - joeynmt.training - Epoch  73, Step:    53300, Batch Loss:     1.507852, Tokens per Sec:    14430, Lr: 0.000300\n","2021-09-20 09:48:38,645 - INFO - joeynmt.training - Epoch  73: total training loss 1056.32\n","2021-09-20 09:48:38,645 - INFO - joeynmt.training - EPOCH 74\n","2021-09-20 09:48:49,063 - INFO - joeynmt.training - Epoch  74, Step:    53400, Batch Loss:     1.368049, Tokens per Sec:    14523, Lr: 0.000300\n","2021-09-20 09:49:02,793 - INFO - joeynmt.training - Epoch  74, Step:    53500, Batch Loss:     1.500334, Tokens per Sec:    14349, Lr: 0.000300\n","2021-09-20 09:49:16,475 - INFO - joeynmt.training - Epoch  74, Step:    53600, Batch Loss:     1.570486, Tokens per Sec:    14417, Lr: 0.000300\n","2021-09-20 09:49:30,107 - INFO - joeynmt.training - Epoch  74, Step:    53700, Batch Loss:     1.561219, Tokens per Sec:    14500, Lr: 0.000300\n","2021-09-20 09:49:43,762 - INFO - joeynmt.training - Epoch  74, Step:    53800, Batch Loss:     1.497560, Tokens per Sec:    14408, Lr: 0.000300\n","2021-09-20 09:49:57,331 - INFO - joeynmt.training - Epoch  74, Step:    53900, Batch Loss:     1.476107, Tokens per Sec:    14587, Lr: 0.000300\n","2021-09-20 09:50:10,986 - INFO - joeynmt.training - Epoch  74, Step:    54000, Batch Loss:     1.462577, Tokens per Sec:    14558, Lr: 0.000300\n","2021-09-20 09:50:18,878 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:50:18,879 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:50:18,879 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:50:19,238 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/51000.ckpt\n","2021-09-20 09:50:19,258 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:50:19,259 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:50:19,259 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:50:19,259 - INFO - joeynmt.training - \tHypothesis: The requirement of Rs. 143.604 crore for a period of a year 2018-19 will be required .\n","2021-09-20 09:50:19,259 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:50:19,259 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:50:19,259 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:50:19,259 - INFO - joeynmt.training - \tHypothesis: These exams are being right to ensure that we are not going to be realized , our pace does not have a single stalwart .\n","2021-09-20 09:50:19,259 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:50:19,259 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:50:19,259 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:50:19,260 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in Human Resource Development .\n","2021-09-20 09:50:19,260 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:50:19,260 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:50:19,260 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:50:19,260 - INFO - joeynmt.training - \tHypothesis: I also thank him for showing their valuable part of our heritage .\n","2021-09-20 09:50:19,260 - INFO - joeynmt.training - Validation result (greedy) at epoch  74, step    54000: bleu:  28.01, loss: 25048.2188, ppl:   5.2057, duration: 8.2734s\n","2021-09-20 09:50:26,429 - INFO - joeynmt.training - Epoch  74: total training loss 1050.68\n","2021-09-20 09:50:26,430 - INFO - joeynmt.training - EPOCH 75\n","2021-09-20 09:50:32,934 - INFO - joeynmt.training - Epoch  75, Step:    54100, Batch Loss:     1.368859, Tokens per Sec:    14492, Lr: 0.000300\n","2021-09-20 09:50:46,655 - INFO - joeynmt.training - Epoch  75, Step:    54200, Batch Loss:     1.427918, Tokens per Sec:    14380, Lr: 0.000300\n","2021-09-20 09:51:00,299 - INFO - joeynmt.training - Epoch  75, Step:    54300, Batch Loss:     1.428494, Tokens per Sec:    14614, Lr: 0.000300\n","2021-09-20 09:51:14,148 - INFO - joeynmt.training - Epoch  75, Step:    54400, Batch Loss:     1.470559, Tokens per Sec:    14165, Lr: 0.000300\n","2021-09-20 09:51:27,822 - INFO - joeynmt.training - Epoch  75, Step:    54500, Batch Loss:     1.414852, Tokens per Sec:    14438, Lr: 0.000300\n","2021-09-20 09:51:41,643 - INFO - joeynmt.training - Epoch  75, Step:    54600, Batch Loss:     1.438146, Tokens per Sec:    14266, Lr: 0.000300\n","2021-09-20 09:51:55,239 - INFO - joeynmt.training - Epoch  75, Step:    54700, Batch Loss:     1.431620, Tokens per Sec:    14463, Lr: 0.000300\n","2021-09-20 09:52:06,780 - INFO - joeynmt.training - Epoch  75: total training loss 1050.95\n","2021-09-20 09:52:06,781 - INFO - joeynmt.training - EPOCH 76\n","2021-09-20 09:52:09,016 - INFO - joeynmt.training - Epoch  76, Step:    54800, Batch Loss:     1.323527, Tokens per Sec:    14121, Lr: 0.000300\n","2021-09-20 09:52:22,586 - INFO - joeynmt.training - Epoch  76, Step:    54900, Batch Loss:     1.353194, Tokens per Sec:    14557, Lr: 0.000300\n","2021-09-20 09:52:36,271 - INFO - joeynmt.training - Epoch  76, Step:    55000, Batch Loss:     1.569608, Tokens per Sec:    14439, Lr: 0.000300\n","2021-09-20 09:52:46,015 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:52:46,015 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:52:46,015 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:52:46,021 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:52:46,022 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:52:46,022 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:52:46,022 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of one year during 2018-19 .\n","2021-09-20 09:52:46,022 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:52:46,022 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:52:46,022 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:52:46,023 - INFO - joeynmt.training - \tHypothesis: These exams are right that we are not going to be realized , our momentum is not just that it is not just a silos .\n","2021-09-20 09:52:46,023 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:52:46,023 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:52:46,023 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:52:46,023 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in Human Resource Development .\n","2021-09-20 09:52:46,023 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:52:46,023 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:52:46,023 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:52:46,024 - INFO - joeynmt.training - \tHypothesis: I also thank him for showing them ’ s valuable part of our heritage .\n","2021-09-20 09:52:46,024 - INFO - joeynmt.training - Validation result (greedy) at epoch  76, step    55000: bleu:  28.46, loss: 25057.1172, ppl:   5.2088, duration: 9.7524s\n","2021-09-20 09:52:59,555 - INFO - joeynmt.training - Epoch  76, Step:    55100, Batch Loss:     1.345567, Tokens per Sec:    14600, Lr: 0.000300\n","2021-09-20 09:53:13,348 - INFO - joeynmt.training - Epoch  76, Step:    55200, Batch Loss:     1.409830, Tokens per Sec:    14248, Lr: 0.000300\n","2021-09-20 09:53:26,987 - INFO - joeynmt.training - Epoch  76, Step:    55300, Batch Loss:     1.411694, Tokens per Sec:    14553, Lr: 0.000300\n","2021-09-20 09:53:40,789 - INFO - joeynmt.training - Epoch  76, Step:    55400, Batch Loss:     1.549631, Tokens per Sec:    14425, Lr: 0.000300\n","2021-09-20 09:53:54,538 - INFO - joeynmt.training - Epoch  76, Step:    55500, Batch Loss:     1.457709, Tokens per Sec:    14223, Lr: 0.000300\n","2021-09-20 09:53:56,531 - INFO - joeynmt.training - Epoch  76: total training loss 1046.85\n","2021-09-20 09:53:56,532 - INFO - joeynmt.training - EPOCH 77\n","2021-09-20 09:54:08,433 - INFO - joeynmt.training - Epoch  77, Step:    55600, Batch Loss:     1.524479, Tokens per Sec:    14103, Lr: 0.000300\n","2021-09-20 09:54:22,241 - INFO - joeynmt.training - Epoch  77, Step:    55700, Batch Loss:     1.417622, Tokens per Sec:    14384, Lr: 0.000300\n","2021-09-20 09:54:35,780 - INFO - joeynmt.training - Epoch  77, Step:    55800, Batch Loss:     1.455298, Tokens per Sec:    14503, Lr: 0.000300\n","2021-09-20 09:54:49,366 - INFO - joeynmt.training - Epoch  77, Step:    55900, Batch Loss:     1.452399, Tokens per Sec:    14545, Lr: 0.000300\n","2021-09-20 09:55:03,049 - INFO - joeynmt.training - Epoch  77, Step:    56000, Batch Loss:     1.472170, Tokens per Sec:    14548, Lr: 0.000300\n","2021-09-20 09:55:11,316 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:55:11,317 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:55:11,317 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:55:11,322 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:55:11,685 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/53000.ckpt\n","2021-09-20 09:55:11,706 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:55:11,706 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:55:11,706 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:55:11,706 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore for a period of one year in 2018-19 will be required .\n","2021-09-20 09:55:11,706 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:55:11,707 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:55:11,707 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:55:11,707 - INFO - joeynmt.training - \tHypothesis: These exams are being right that we are not going to be realized , our pace is not just that it is not just because of it is not .\n","2021-09-20 09:55:11,707 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:55:11,707 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:55:11,707 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:55:11,707 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in human resource development .\n","2021-09-20 09:55:11,707 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:55:11,708 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:55:11,708 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:55:11,708 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing the valuable part of our heritage .\n","2021-09-20 09:55:11,708 - INFO - joeynmt.training - Validation result (greedy) at epoch  77, step    56000: bleu:  27.69, loss: 24881.9375, ppl:   5.1490, duration: 8.6584s\n","2021-09-20 09:55:25,366 - INFO - joeynmt.training - Epoch  77, Step:    56100, Batch Loss:     1.424649, Tokens per Sec:    14439, Lr: 0.000300\n","2021-09-20 09:55:39,106 - INFO - joeynmt.training - Epoch  77, Step:    56200, Batch Loss:     1.469357, Tokens per Sec:    14501, Lr: 0.000300\n","2021-09-20 09:55:45,268 - INFO - joeynmt.training - Epoch  77: total training loss 1041.29\n","2021-09-20 09:55:45,269 - INFO - joeynmt.training - EPOCH 78\n","2021-09-20 09:55:52,888 - INFO - joeynmt.training - Epoch  78, Step:    56300, Batch Loss:     1.423125, Tokens per Sec:    14447, Lr: 0.000300\n","2021-09-20 09:56:06,525 - INFO - joeynmt.training - Epoch  78, Step:    56400, Batch Loss:     1.404461, Tokens per Sec:    14583, Lr: 0.000300\n","2021-09-20 09:56:20,304 - INFO - joeynmt.training - Epoch  78, Step:    56500, Batch Loss:     1.432235, Tokens per Sec:    14259, Lr: 0.000300\n","2021-09-20 09:56:34,002 - INFO - joeynmt.training - Epoch  78, Step:    56600, Batch Loss:     1.454796, Tokens per Sec:    14283, Lr: 0.000300\n","2021-09-20 09:56:47,603 - INFO - joeynmt.training - Epoch  78, Step:    56700, Batch Loss:     1.453797, Tokens per Sec:    14518, Lr: 0.000300\n","2021-09-20 09:57:01,349 - INFO - joeynmt.training - Epoch  78, Step:    56800, Batch Loss:     1.538221, Tokens per Sec:    14380, Lr: 0.000300\n","2021-09-20 09:57:15,165 - INFO - joeynmt.training - Epoch  78, Step:    56900, Batch Loss:     1.420098, Tokens per Sec:    14244, Lr: 0.000300\n","2021-09-20 09:57:25,559 - INFO - joeynmt.training - Epoch  78: total training loss 1040.03\n","2021-09-20 09:57:25,560 - INFO - joeynmt.training - EPOCH 79\n","2021-09-20 09:57:28,904 - INFO - joeynmt.training - Epoch  79, Step:    57000, Batch Loss:     1.496099, Tokens per Sec:    14225, Lr: 0.000300\n","2021-09-20 09:57:37,257 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 09:57:37,257 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 09:57:37,257 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 09:57:37,262 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 09:57:37,625 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/54000.ckpt\n","2021-09-20 09:57:37,644 - INFO - joeynmt.training - Example #0\n","2021-09-20 09:57:37,645 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 09:57:37,645 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 09:57:37,645 - INFO - joeynmt.training - \tHypothesis: During 2018-19 , the requirement of Rs. 143.604 crore will be required for a period of one year .\n","2021-09-20 09:57:37,645 - INFO - joeynmt.training - Example #1\n","2021-09-20 09:57:37,645 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 09:57:37,645 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 09:57:37,645 - INFO - joeynmt.training - \tHypothesis: These exams are being true that we are not going to be realized that our momentum is not just a single stage , but it is not just a single stalwart .\n","2021-09-20 09:57:37,646 - INFO - joeynmt.training - Example #2\n","2021-09-20 09:57:37,646 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 09:57:37,646 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 09:57:37,646 - INFO - joeynmt.training - \tHypothesis: . To exchange programmes for cooperation in human resource development .\n","2021-09-20 09:57:37,646 - INFO - joeynmt.training - Example #3\n","2021-09-20 09:57:37,646 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 09:57:37,646 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 09:57:37,646 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing their valuable part of our heritage .\n","2021-09-20 09:57:37,647 - INFO - joeynmt.training - Validation result (greedy) at epoch  79, step    57000: bleu:  28.37, loss: 24763.3223, ppl:   5.1089, duration: 8.7420s\n","2021-09-20 09:57:51,288 - INFO - joeynmt.training - Epoch  79, Step:    57100, Batch Loss:     1.391481, Tokens per Sec:    14506, Lr: 0.000300\n","2021-09-20 09:58:04,922 - INFO - joeynmt.training - Epoch  79, Step:    57200, Batch Loss:     1.375135, Tokens per Sec:    14448, Lr: 0.000300\n","2021-09-20 09:58:18,721 - INFO - joeynmt.training - Epoch  79, Step:    57300, Batch Loss:     1.497196, Tokens per Sec:    14298, Lr: 0.000300\n","2021-09-20 09:58:32,317 - INFO - joeynmt.training - Epoch  79, Step:    57400, Batch Loss:     1.304285, Tokens per Sec:    14508, Lr: 0.000300\n","2021-09-20 09:58:46,001 - INFO - joeynmt.training - Epoch  79, Step:    57500, Batch Loss:     1.439503, Tokens per Sec:    14416, Lr: 0.000300\n","2021-09-20 09:58:59,830 - INFO - joeynmt.training - Epoch  79, Step:    57600, Batch Loss:     1.561920, Tokens per Sec:    14303, Lr: 0.000300\n","2021-09-20 09:59:13,497 - INFO - joeynmt.training - Epoch  79, Step:    57700, Batch Loss:     1.402744, Tokens per Sec:    14395, Lr: 0.000300\n","2021-09-20 09:59:14,464 - INFO - joeynmt.training - Epoch  79: total training loss 1037.02\n","2021-09-20 09:59:14,465 - INFO - joeynmt.training - EPOCH 80\n","2021-09-20 09:59:27,230 - INFO - joeynmt.training - Epoch  80, Step:    57800, Batch Loss:     1.285758, Tokens per Sec:    14304, Lr: 0.000300\n","2021-09-20 09:59:41,006 - INFO - joeynmt.training - Epoch  80, Step:    57900, Batch Loss:     1.437662, Tokens per Sec:    14330, Lr: 0.000300\n","2021-09-20 09:59:54,530 - INFO - joeynmt.training - Epoch  80, Step:    58000, Batch Loss:     1.476115, Tokens per Sec:    14586, Lr: 0.000300\n","2021-09-20 10:00:03,071 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:00:03,071 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:00:03,072 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:00:03,448 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/52000.ckpt\n","2021-09-20 10:00:03,469 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:00:03,469 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:00:03,470 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:00:03,470 - INFO - joeynmt.training - \tHypothesis: During 2018-19 , an amount of Rs. 143.604 crore will be required for a period of one year .\n","2021-09-20 10:00:03,470 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:00:03,470 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:00:03,470 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:00:03,470 - INFO - joeynmt.training - \tHypothesis: These exams are being trying that we are not trying to ensure that it is not a single pace , our pace is not just that it is not a single instalment .\n","2021-09-20 10:00:03,470 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:00:03,470 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:00:03,470 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:00:03,470 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in human resources development .\n","2021-09-20 10:00:03,471 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:00:03,471 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:00:03,471 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:00:03,471 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing them the valuable part of our heritage .\n","2021-09-20 10:00:03,471 - INFO - joeynmt.training - Validation result (greedy) at epoch  80, step    58000: bleu:  29.01, loss: 24829.1895, ppl:   5.1311, duration: 8.9410s\n","2021-09-20 10:00:16,989 - INFO - joeynmt.training - Epoch  80, Step:    58100, Batch Loss:     1.319685, Tokens per Sec:    14652, Lr: 0.000300\n","2021-09-20 10:00:30,640 - INFO - joeynmt.training - Epoch  80, Step:    58200, Batch Loss:     1.540453, Tokens per Sec:    14485, Lr: 0.000300\n","2021-09-20 10:00:44,339 - INFO - joeynmt.training - Epoch  80, Step:    58300, Batch Loss:     1.274604, Tokens per Sec:    14456, Lr: 0.000300\n","2021-09-20 10:00:57,927 - INFO - joeynmt.training - Epoch  80, Step:    58400, Batch Loss:     1.241729, Tokens per Sec:    14700, Lr: 0.000300\n","2021-09-20 10:01:02,950 - INFO - joeynmt.training - Epoch  80: total training loss 1031.84\n","2021-09-20 10:01:02,951 - INFO - joeynmt.training - EPOCH 81\n","2021-09-20 10:01:11,616 - INFO - joeynmt.training - Epoch  81, Step:    58500, Batch Loss:     1.386579, Tokens per Sec:    14318, Lr: 0.000300\n","2021-09-20 10:01:25,294 - INFO - joeynmt.training - Epoch  81, Step:    58600, Batch Loss:     1.319828, Tokens per Sec:    14485, Lr: 0.000300\n","2021-09-20 10:01:38,859 - INFO - joeynmt.training - Epoch  81, Step:    58700, Batch Loss:     1.469343, Tokens per Sec:    14519, Lr: 0.000300\n","2021-09-20 10:01:52,584 - INFO - joeynmt.training - Epoch  81, Step:    58800, Batch Loss:     1.315552, Tokens per Sec:    14379, Lr: 0.000300\n","2021-09-20 10:02:06,255 - INFO - joeynmt.training - Epoch  81, Step:    58900, Batch Loss:     1.549755, Tokens per Sec:    14385, Lr: 0.000300\n","2021-09-20 10:02:20,026 - INFO - joeynmt.training - Epoch  81, Step:    59000, Batch Loss:     1.426506, Tokens per Sec:    14353, Lr: 0.000300\n","2021-09-20 10:02:29,530 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:02:29,530 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:02:29,531 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:02:29,534 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 10:02:29,923 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/56000.ckpt\n","2021-09-20 10:02:29,943 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:02:29,943 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:02:29,943 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:02:29,943 - INFO - joeynmt.training - \tHypothesis: During 2018-19 , the amount of Rs. 143.604 crore will be required for a period of one year .\n","2021-09-20 10:02:29,943 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:02:29,944 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:02:29,944 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:02:29,944 - INFO - joeynmt.training - \tHypothesis: These exams are being right to ensure that they are not going to be realized , our momentum is not just a single instalment that it is not just a single instalment .\n","2021-09-20 10:02:29,944 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:02:29,944 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:02:29,944 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:02:29,944 - INFO - joeynmt.training - \tHypothesis: . To establish programmes for cooperation in Human Resource Development .\n","2021-09-20 10:02:29,944 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:02:29,945 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:02:29,945 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:02:29,945 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing them the valuable part of our heritage .\n","2021-09-20 10:02:29,945 - INFO - joeynmt.training - Validation result (greedy) at epoch  81, step    59000: bleu:  28.55, loss: 24760.9668, ppl:   5.1081, duration: 9.9187s\n","2021-09-20 10:02:43,559 - INFO - joeynmt.training - Epoch  81, Step:    59100, Batch Loss:     1.373114, Tokens per Sec:    14430, Lr: 0.000300\n","2021-09-20 10:02:52,937 - INFO - joeynmt.training - Epoch  81: total training loss 1031.99\n","2021-09-20 10:02:52,937 - INFO - joeynmt.training - EPOCH 82\n","2021-09-20 10:02:57,208 - INFO - joeynmt.training - Epoch  82, Step:    59200, Batch Loss:     1.265377, Tokens per Sec:    14465, Lr: 0.000300\n","2021-09-20 10:03:11,049 - INFO - joeynmt.training - Epoch  82, Step:    59300, Batch Loss:     1.469143, Tokens per Sec:    14324, Lr: 0.000300\n","2021-09-20 10:03:24,644 - INFO - joeynmt.training - Epoch  82, Step:    59400, Batch Loss:     1.455670, Tokens per Sec:    14435, Lr: 0.000300\n","2021-09-20 10:03:38,409 - INFO - joeynmt.training - Epoch  82, Step:    59500, Batch Loss:     1.252332, Tokens per Sec:    14552, Lr: 0.000300\n","2021-09-20 10:03:52,127 - INFO - joeynmt.training - Epoch  82, Step:    59600, Batch Loss:     1.418895, Tokens per Sec:    14486, Lr: 0.000300\n","2021-09-20 10:04:05,920 - INFO - joeynmt.training - Epoch  82, Step:    59700, Batch Loss:     1.438825, Tokens per Sec:    14292, Lr: 0.000300\n","2021-09-20 10:04:19,568 - INFO - joeynmt.training - Epoch  82, Step:    59800, Batch Loss:     1.382253, Tokens per Sec:    14482, Lr: 0.000300\n","2021-09-20 10:04:33,174 - INFO - joeynmt.training - Epoch  82: total training loss 1025.73\n","2021-09-20 10:04:33,174 - INFO - joeynmt.training - EPOCH 83\n","2021-09-20 10:04:33,371 - INFO - joeynmt.training - Epoch  83, Step:    59900, Batch Loss:     1.347551, Tokens per Sec:    11061, Lr: 0.000300\n","2021-09-20 10:04:47,079 - INFO - joeynmt.training - Epoch  83, Step:    60000, Batch Loss:     1.238077, Tokens per Sec:    14395, Lr: 0.000300\n","2021-09-20 10:04:56,439 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:04:56,440 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:04:56,440 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:04:56,835 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/58000.ckpt\n","2021-09-20 10:04:56,855 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:04:56,855 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:04:56,855 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:04:56,856 - INFO - joeynmt.training - \tHypothesis: During 2018-19 , the requirement of Rs. 143.604 crore will be required for a period of one year .\n","2021-09-20 10:04:56,856 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:04:56,856 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:04:56,856 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:04:56,856 - INFO - joeynmt.training - \tHypothesis: These exams are being true that they are not going to say that it is not just a scenario and our pace that is not just a single instance .\n","2021-09-20 10:04:56,856 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:04:56,857 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:04:56,857 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:04:56,857 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in human resource development .\n","2021-09-20 10:04:56,857 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:04:56,857 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:04:56,857 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:04:56,857 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing them a valuable part of our heritage .\n","2021-09-20 10:04:56,857 - INFO - joeynmt.training - Validation result (greedy) at epoch  83, step    60000: bleu:  28.11, loss: 24798.3809, ppl:   5.1207, duration: 9.7782s\n","2021-09-20 10:05:10,734 - INFO - joeynmt.training - Epoch  83, Step:    60100, Batch Loss:     1.453072, Tokens per Sec:    14193, Lr: 0.000300\n","2021-09-20 10:05:24,515 - INFO - joeynmt.training - Epoch  83, Step:    60200, Batch Loss:     1.243564, Tokens per Sec:    14364, Lr: 0.000300\n","2021-09-20 10:05:38,124 - INFO - joeynmt.training - Epoch  83, Step:    60300, Batch Loss:     1.398881, Tokens per Sec:    14552, Lr: 0.000300\n","2021-09-20 10:05:51,811 - INFO - joeynmt.training - Epoch  83, Step:    60400, Batch Loss:     1.414879, Tokens per Sec:    14435, Lr: 0.000300\n","2021-09-20 10:06:05,600 - INFO - joeynmt.training - Epoch  83, Step:    60500, Batch Loss:     1.513478, Tokens per Sec:    14343, Lr: 0.000300\n","2021-09-20 10:06:19,324 - INFO - joeynmt.training - Epoch  83, Step:    60600, Batch Loss:     1.484155, Tokens per Sec:    14488, Lr: 0.000300\n","2021-09-20 10:06:23,189 - INFO - joeynmt.training - Epoch  83: total training loss 1022.41\n","2021-09-20 10:06:23,190 - INFO - joeynmt.training - EPOCH 84\n","2021-09-20 10:06:33,139 - INFO - joeynmt.training - Epoch  84, Step:    60700, Batch Loss:     1.329088, Tokens per Sec:    14278, Lr: 0.000300\n","2021-09-20 10:06:46,962 - INFO - joeynmt.training - Epoch  84, Step:    60800, Batch Loss:     1.311591, Tokens per Sec:    14308, Lr: 0.000300\n","2021-09-20 10:07:00,591 - INFO - joeynmt.training - Epoch  84, Step:    60900, Batch Loss:     1.258827, Tokens per Sec:    14478, Lr: 0.000300\n","2021-09-20 10:07:14,354 - INFO - joeynmt.training - Epoch  84, Step:    61000, Batch Loss:     1.336872, Tokens per Sec:    14332, Lr: 0.000300\n","2021-09-20 10:07:22,145 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:07:22,145 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:07:22,146 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:07:22,150 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 10:07:22,518 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/60000.ckpt\n","2021-09-20 10:07:22,539 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:07:22,539 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:07:22,539 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:07:22,539 - INFO - joeynmt.training - \tHypothesis: During 2018-19 , the amount of Rs. 143.604 crore will be required for a period of one year .\n","2021-09-20 10:07:22,539 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:07:22,539 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:07:22,539 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:07:22,540 - INFO - joeynmt.training - \tHypothesis: These exams are being trying to ensure that they are not going to be done , our pace is not just that they are not pace .\n","2021-09-20 10:07:22,540 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:07:22,540 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:07:22,540 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:07:22,540 - INFO - joeynmt.training - \tHypothesis: 4 . To exchange programmes for cooperation in Human Resource Development\n","2021-09-20 10:07:22,540 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:07:22,540 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:07:22,540 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:07:22,540 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing them the valuable part of our heritage .\n","2021-09-20 10:07:22,540 - INFO - joeynmt.training - Validation result (greedy) at epoch  84, step    61000: bleu:  28.52, loss: 24700.7500, ppl:   5.0879, duration: 8.1863s\n","2021-09-20 10:07:36,368 - INFO - joeynmt.training - Epoch  84, Step:    61100, Batch Loss:     1.350289, Tokens per Sec:    14299, Lr: 0.000300\n","2021-09-20 10:07:50,096 - INFO - joeynmt.training - Epoch  84, Step:    61200, Batch Loss:     1.395654, Tokens per Sec:    14337, Lr: 0.000300\n","2021-09-20 10:08:03,776 - INFO - joeynmt.training - Epoch  84, Step:    61300, Batch Loss:     1.358895, Tokens per Sec:    14450, Lr: 0.000300\n","2021-09-20 10:08:11,907 - INFO - joeynmt.training - Epoch  84: total training loss 1021.32\n","2021-09-20 10:08:11,907 - INFO - joeynmt.training - EPOCH 85\n","2021-09-20 10:08:17,548 - INFO - joeynmt.training - Epoch  85, Step:    61400, Batch Loss:     1.340685, Tokens per Sec:    14526, Lr: 0.000300\n","2021-09-20 10:08:31,198 - INFO - joeynmt.training - Epoch  85, Step:    61500, Batch Loss:     1.437577, Tokens per Sec:    14390, Lr: 0.000300\n","2021-09-20 10:08:44,889 - INFO - joeynmt.training - Epoch  85, Step:    61600, Batch Loss:     1.414584, Tokens per Sec:    14450, Lr: 0.000300\n","2021-09-20 10:08:58,559 - INFO - joeynmt.training - Epoch  85, Step:    61700, Batch Loss:     1.505772, Tokens per Sec:    14566, Lr: 0.000300\n","2021-09-20 10:09:12,167 - INFO - joeynmt.training - Epoch  85, Step:    61800, Batch Loss:     1.369763, Tokens per Sec:    14495, Lr: 0.000300\n","2021-09-20 10:09:25,852 - INFO - joeynmt.training - Epoch  85, Step:    61900, Batch Loss:     1.460379, Tokens per Sec:    14384, Lr: 0.000300\n","2021-09-20 10:09:39,499 - INFO - joeynmt.training - Epoch  85, Step:    62000, Batch Loss:     1.497336, Tokens per Sec:    14531, Lr: 0.000300\n","2021-09-20 10:09:47,742 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:09:47,742 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:09:47,743 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:09:47,748 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 10:09:48,143 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/57000.ckpt\n","2021-09-20 10:09:48,164 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:09:48,164 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:09:48,165 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:09:48,165 - INFO - joeynmt.training - \tHypothesis: The requirement of Rs. 143.604 crore for a period of a year 2018-19 will be required .\n","2021-09-20 10:09:48,165 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:09:48,165 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:09:48,165 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:09:48,165 - INFO - joeynmt.training - \tHypothesis: These exams are being true that we are not going to ensure that our pace is not going to be realized , our pace is not just that it is not a single instalment .\n","2021-09-20 10:09:48,165 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:09:48,166 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:09:48,166 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:09:48,166 - INFO - joeynmt.training - \tHypothesis: . To establish exchange programmes for cooperation in human resource development .\n","2021-09-20 10:09:48,166 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:09:48,166 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:09:48,166 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:09:48,166 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing their valuable part of our heritage .\n","2021-09-20 10:09:48,166 - INFO - joeynmt.training - Validation result (greedy) at epoch  85, step    62000: bleu:  28.69, loss: 24596.3945, ppl:   5.0531, duration: 8.6665s\n","2021-09-20 10:10:00,197 - INFO - joeynmt.training - Epoch  85: total training loss 1016.70\n","2021-09-20 10:10:00,197 - INFO - joeynmt.training - EPOCH 86\n","2021-09-20 10:10:01,836 - INFO - joeynmt.training - Epoch  86, Step:    62100, Batch Loss:     1.433040, Tokens per Sec:    13484, Lr: 0.000300\n","2021-09-20 10:10:15,439 - INFO - joeynmt.training - Epoch  86, Step:    62200, Batch Loss:     1.216379, Tokens per Sec:    14608, Lr: 0.000300\n","2021-09-20 10:10:29,210 - INFO - joeynmt.training - Epoch  86, Step:    62300, Batch Loss:     1.358601, Tokens per Sec:    14330, Lr: 0.000300\n","2021-09-20 10:10:42,942 - INFO - joeynmt.training - Epoch  86, Step:    62400, Batch Loss:     1.310179, Tokens per Sec:    14287, Lr: 0.000300\n","2021-09-20 10:10:56,557 - INFO - joeynmt.training - Epoch  86, Step:    62500, Batch Loss:     1.495244, Tokens per Sec:    14331, Lr: 0.000300\n","2021-09-20 10:11:10,335 - INFO - joeynmt.training - Epoch  86, Step:    62600, Batch Loss:     1.233490, Tokens per Sec:    14394, Lr: 0.000300\n","2021-09-20 10:11:24,204 - INFO - joeynmt.training - Epoch  86, Step:    62700, Batch Loss:     1.316042, Tokens per Sec:    14282, Lr: 0.000300\n","2021-09-20 10:11:37,828 - INFO - joeynmt.training - Epoch  86, Step:    62800, Batch Loss:     1.430747, Tokens per Sec:    14534, Lr: 0.000300\n","2021-09-20 10:11:40,519 - INFO - joeynmt.training - Epoch  86: total training loss 1015.71\n","2021-09-20 10:11:40,519 - INFO - joeynmt.training - EPOCH 87\n","2021-09-20 10:11:51,659 - INFO - joeynmt.training - Epoch  87, Step:    62900, Batch Loss:     1.299885, Tokens per Sec:    14165, Lr: 0.000300\n","2021-09-20 10:12:05,395 - INFO - joeynmt.training - Epoch  87, Step:    63000, Batch Loss:     1.254802, Tokens per Sec:    14410, Lr: 0.000300\n","2021-09-20 10:12:13,156 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:12:13,156 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:12:13,156 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:12:13,544 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/59000.ckpt\n","2021-09-20 10:12:13,564 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:12:13,565 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:12:13,565 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:12:13,565 - INFO - joeynmt.training - \tHypothesis: During 2018-19 , an amount of Rs. 143.604 crore will be required for a period of one year .\n","2021-09-20 10:12:13,565 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:12:13,565 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:12:13,565 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:12:13,565 - INFO - joeynmt.training - \tHypothesis: These exams are being trying to ensure that they are not going to be realized , our pace is not just that it is not just a single instalment .\n","2021-09-20 10:12:13,565 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:12:13,566 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:12:13,566 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:12:13,566 - INFO - joeynmt.training - \tHypothesis: . To establish programmes for cooperation in human resources development .\n","2021-09-20 10:12:13,566 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:12:13,566 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:12:13,566 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:12:13,566 - INFO - joeynmt.training - \tHypothesis: I also thank him for showing the multi-modest part of our heritage .\n","2021-09-20 10:12:13,566 - INFO - joeynmt.training - Validation result (greedy) at epoch  87, step    63000: bleu:  28.64, loss: 24720.1836, ppl:   5.0944, duration: 8.1712s\n","2021-09-20 10:12:27,478 - INFO - joeynmt.training - Epoch  87, Step:    63100, Batch Loss:     1.265918, Tokens per Sec:    14134, Lr: 0.000300\n","2021-09-20 10:12:41,128 - INFO - joeynmt.training - Epoch  87, Step:    63200, Batch Loss:     1.433913, Tokens per Sec:    14447, Lr: 0.000300\n","2021-09-20 10:12:55,108 - INFO - joeynmt.training - Epoch  87, Step:    63300, Batch Loss:     1.386402, Tokens per Sec:    14136, Lr: 0.000300\n","2021-09-20 10:13:08,698 - INFO - joeynmt.training - Epoch  87, Step:    63400, Batch Loss:     1.427166, Tokens per Sec:    14572, Lr: 0.000300\n","2021-09-20 10:13:22,310 - INFO - joeynmt.training - Epoch  87, Step:    63500, Batch Loss:     1.362540, Tokens per Sec:    14483, Lr: 0.000300\n","2021-09-20 10:13:29,232 - INFO - joeynmt.training - Epoch  87: total training loss 1012.77\n","2021-09-20 10:13:29,233 - INFO - joeynmt.training - EPOCH 88\n","2021-09-20 10:13:36,117 - INFO - joeynmt.training - Epoch  88, Step:    63600, Batch Loss:     1.357765, Tokens per Sec:    14057, Lr: 0.000300\n","2021-09-20 10:13:49,786 - INFO - joeynmt.training - Epoch  88, Step:    63700, Batch Loss:     1.327816, Tokens per Sec:    14419, Lr: 0.000300\n","2021-09-20 10:14:03,573 - INFO - joeynmt.training - Epoch  88, Step:    63800, Batch Loss:     1.450841, Tokens per Sec:    14277, Lr: 0.000300\n","2021-09-20 10:14:17,343 - INFO - joeynmt.training - Epoch  88, Step:    63900, Batch Loss:     1.292920, Tokens per Sec:    14371, Lr: 0.000300\n","2021-09-20 10:14:31,111 - INFO - joeynmt.training - Epoch  88, Step:    64000, Batch Loss:     1.361325, Tokens per Sec:    14287, Lr: 0.000300\n","2021-09-20 10:14:39,661 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:14:39,661 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:14:39,661 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:14:39,667 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:14:39,668 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:14:39,668 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:14:39,668 - INFO - joeynmt.training - \tHypothesis: During 2018-19 , an amount of Rs. 143.604 crore will be required for a period of one year .\n","2021-09-20 10:14:39,668 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:14:39,668 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:14:39,668 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:14:39,668 - INFO - joeynmt.training - \tHypothesis: These exams are being true that we are not going to say that it is not just a sleep and instalment that our pace is not just rather than it is .\n","2021-09-20 10:14:39,668 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:14:39,668 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:14:39,669 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:14:39,669 - INFO - joeynmt.training - \tHypothesis: . To establish programmes for cooperation in human resource development .\n","2021-09-20 10:14:39,669 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:14:39,669 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:14:39,669 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:14:39,669 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing their valuable part of our heritage .\n","2021-09-20 10:14:39,669 - INFO - joeynmt.training - Validation result (greedy) at epoch  88, step    64000: bleu:  28.99, loss: 24734.4844, ppl:   5.0992, duration: 8.5572s\n","2021-09-20 10:14:53,451 - INFO - joeynmt.training - Epoch  88, Step:    64100, Batch Loss:     1.431147, Tokens per Sec:    14402, Lr: 0.000300\n","2021-09-20 10:15:07,203 - INFO - joeynmt.training - Epoch  88, Step:    64200, Batch Loss:     1.444898, Tokens per Sec:    14473, Lr: 0.000300\n","2021-09-20 10:15:18,285 - INFO - joeynmt.training - Epoch  88: total training loss 1010.29\n","2021-09-20 10:15:18,286 - INFO - joeynmt.training - EPOCH 89\n","2021-09-20 10:15:20,808 - INFO - joeynmt.training - Epoch  89, Step:    64300, Batch Loss:     1.395220, Tokens per Sec:    14035, Lr: 0.000300\n","2021-09-20 10:15:34,458 - INFO - joeynmt.training - Epoch  89, Step:    64400, Batch Loss:     1.460773, Tokens per Sec:    14518, Lr: 0.000300\n","2021-09-20 10:15:48,190 - INFO - joeynmt.training - Epoch  89, Step:    64500, Batch Loss:     1.273284, Tokens per Sec:    14357, Lr: 0.000300\n","2021-09-20 10:16:01,925 - INFO - joeynmt.training - Epoch  89, Step:    64600, Batch Loss:     1.321549, Tokens per Sec:    14306, Lr: 0.000300\n","2021-09-20 10:16:15,497 - INFO - joeynmt.training - Epoch  89, Step:    64700, Batch Loss:     1.381250, Tokens per Sec:    14540, Lr: 0.000300\n","2021-09-20 10:16:29,255 - INFO - joeynmt.training - Epoch  89, Step:    64800, Batch Loss:     1.423284, Tokens per Sec:    14406, Lr: 0.000300\n","2021-09-20 10:16:42,895 - INFO - joeynmt.training - Epoch  89, Step:    64900, Batch Loss:     1.285964, Tokens per Sec:    14448, Lr: 0.000300\n","2021-09-20 10:16:56,686 - INFO - joeynmt.training - Epoch  89, Step:    65000, Batch Loss:     1.420460, Tokens per Sec:    14335, Lr: 0.000300\n","2021-09-20 10:17:04,825 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:17:04,826 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:17:04,826 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:17:05,187 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/63000.ckpt\n","2021-09-20 10:17:05,205 - INFO - joeynmt.helpers - delete /content/joeynmt/models/hien_transformer_pmi_nhs_backtranslate/63000.ckpt\n","2021-09-20 10:17:05,205 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/joeynmt/models/hien_transformer_pmi_nhs_backtranslate/63000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/joeynmt/models/hien_transformer_pmi_nhs_backtranslate/63000.ckpt')\n","2021-09-20 10:17:05,206 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:17:05,207 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:17:05,207 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:17:05,207 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 10:17:05,207 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:17:05,207 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:17:05,207 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:17:05,208 - INFO - joeynmt.training - \tHypothesis: These exams are being made right that we are not going to add that our pace is not just that we are not going to stop it .\n","2021-09-20 10:17:05,208 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:17:05,208 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:17:05,208 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:17:05,208 - INFO - joeynmt.training - \tHypothesis: . To establish exchange programmes for cooperation in Human Resource Development .\n","2021-09-20 10:17:05,208 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:17:05,208 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:17:05,208 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:17:05,209 - INFO - joeynmt.training - \tHypothesis: I also thank him for showing the valuable part of our heritage .\n","2021-09-20 10:17:05,209 - INFO - joeynmt.training - Validation result (greedy) at epoch  89, step    65000: bleu:  28.47, loss: 24674.3730, ppl:   5.0791, duration: 8.5220s\n","2021-09-20 10:17:06,933 - INFO - joeynmt.training - Epoch  89: total training loss 1007.29\n","2021-09-20 10:17:06,933 - INFO - joeynmt.training - EPOCH 90\n","2021-09-20 10:17:18,918 - INFO - joeynmt.training - Epoch  90, Step:    65100, Batch Loss:     1.355555, Tokens per Sec:    14514, Lr: 0.000300\n","2021-09-20 10:17:32,526 - INFO - joeynmt.training - Epoch  90, Step:    65200, Batch Loss:     1.542651, Tokens per Sec:    14447, Lr: 0.000300\n","2021-09-20 10:17:46,268 - INFO - joeynmt.training - Epoch  90, Step:    65300, Batch Loss:     1.391723, Tokens per Sec:    14441, Lr: 0.000300\n","2021-09-20 10:18:00,038 - INFO - joeynmt.training - Epoch  90, Step:    65400, Batch Loss:     1.384433, Tokens per Sec:    14281, Lr: 0.000300\n","2021-09-20 10:18:13,773 - INFO - joeynmt.training - Epoch  90, Step:    65500, Batch Loss:     1.356750, Tokens per Sec:    14400, Lr: 0.000300\n","2021-09-20 10:18:27,398 - INFO - joeynmt.training - Epoch  90, Step:    65600, Batch Loss:     1.449474, Tokens per Sec:    14504, Lr: 0.000300\n","2021-09-20 10:18:40,934 - INFO - joeynmt.training - Epoch  90, Step:    65700, Batch Loss:     1.284716, Tokens per Sec:    14504, Lr: 0.000300\n","2021-09-20 10:18:46,746 - INFO - joeynmt.training - Epoch  90: total training loss 1003.73\n","2021-09-20 10:18:46,747 - INFO - joeynmt.training - EPOCH 91\n","2021-09-20 10:18:54,613 - INFO - joeynmt.training - Epoch  91, Step:    65800, Batch Loss:     1.232251, Tokens per Sec:    14294, Lr: 0.000300\n","2021-09-20 10:19:08,250 - INFO - joeynmt.training - Epoch  91, Step:    65900, Batch Loss:     1.404189, Tokens per Sec:    14609, Lr: 0.000300\n","2021-09-20 10:19:21,875 - INFO - joeynmt.training - Epoch  91, Step:    66000, Batch Loss:     1.258174, Tokens per Sec:    14413, Lr: 0.000300\n","2021-09-20 10:19:30,239 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:19:30,239 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:19:30,239 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:19:30,245 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:19:30,246 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:19:30,246 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:19:30,246 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of one year 2018-19 .\n","2021-09-20 10:19:30,246 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:19:30,246 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:19:30,246 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:19:30,246 - INFO - joeynmt.training - \tHypothesis: These exams are being true that we are not trying to be realized , our pace is not just that our pace , it is not just a single instalment .\n","2021-09-20 10:19:30,246 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:19:30,247 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:19:30,247 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:19:30,247 - INFO - joeynmt.training - \tHypothesis: 4 . To establish exchange of programmes for cooperation in Human Resource Development .\n","2021-09-20 10:19:30,247 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:19:30,247 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:19:30,247 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:19:30,247 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing their valuable part of our heritage .\n","2021-09-20 10:19:30,247 - INFO - joeynmt.training - Validation result (greedy) at epoch  91, step    66000: bleu:  28.91, loss: 24701.2559, ppl:   5.0881, duration: 8.3721s\n","2021-09-20 10:19:43,928 - INFO - joeynmt.training - Epoch  91, Step:    66100, Batch Loss:     1.346795, Tokens per Sec:    14415, Lr: 0.000300\n","2021-09-20 10:19:57,607 - INFO - joeynmt.training - Epoch  91, Step:    66200, Batch Loss:     1.432191, Tokens per Sec:    14508, Lr: 0.000300\n","2021-09-20 10:20:11,311 - INFO - joeynmt.training - Epoch  91, Step:    66300, Batch Loss:     1.332863, Tokens per Sec:    14403, Lr: 0.000300\n","2021-09-20 10:20:25,056 - INFO - joeynmt.training - Epoch  91, Step:    66400, Batch Loss:     1.314087, Tokens per Sec:    14332, Lr: 0.000300\n","2021-09-20 10:20:35,045 - INFO - joeynmt.training - Epoch  91: total training loss 1002.01\n","2021-09-20 10:20:35,046 - INFO - joeynmt.training - EPOCH 92\n","2021-09-20 10:20:38,672 - INFO - joeynmt.training - Epoch  92, Step:    66500, Batch Loss:     1.443172, Tokens per Sec:    14438, Lr: 0.000300\n","2021-09-20 10:20:52,141 - INFO - joeynmt.training - Epoch  92, Step:    66600, Batch Loss:     1.370178, Tokens per Sec:    14790, Lr: 0.000300\n","2021-09-20 10:21:05,839 - INFO - joeynmt.training - Epoch  92, Step:    66700, Batch Loss:     1.235338, Tokens per Sec:    14332, Lr: 0.000300\n","2021-09-20 10:21:19,568 - INFO - joeynmt.training - Epoch  92, Step:    66800, Batch Loss:     1.311567, Tokens per Sec:    14371, Lr: 0.000300\n","2021-09-20 10:21:33,264 - INFO - joeynmt.training - Epoch  92, Step:    66900, Batch Loss:     1.359630, Tokens per Sec:    14482, Lr: 0.000300\n","2021-09-20 10:21:46,959 - INFO - joeynmt.training - Epoch  92, Step:    67000, Batch Loss:     1.385204, Tokens per Sec:    14482, Lr: 0.000300\n","2021-09-20 10:21:55,151 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:21:55,151 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:21:55,151 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:21:55,156 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 10:21:55,531 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/61000.ckpt\n","2021-09-20 10:21:55,550 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:21:55,551 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:21:55,551 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:21:55,551 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of one year during 2018-19 .\n","2021-09-20 10:21:55,551 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:21:55,551 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:21:55,551 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:21:55,552 - INFO - joeynmt.training - \tHypothesis: These exams are being trying to be realized that we are not going to say that our pace is not just a sluck , and our pace does not have a slum .\n","2021-09-20 10:21:55,552 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:21:55,552 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:21:55,552 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:21:55,552 - INFO - joeynmt.training - \tHypothesis: . To establish programmes for cooperation in Human Resource Development .\n","2021-09-20 10:21:55,552 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:21:55,552 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:21:55,552 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:21:55,553 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing their valuable part of our heritage .\n","2021-09-20 10:21:55,553 - INFO - joeynmt.training - Validation result (greedy) at epoch  92, step    67000: bleu:  28.97, loss: 24578.6562, ppl:   5.0472, duration: 8.5928s\n","2021-09-20 10:22:09,309 - INFO - joeynmt.training - Epoch  92, Step:    67100, Batch Loss:     1.376628, Tokens per Sec:    14277, Lr: 0.000300\n","2021-09-20 10:22:23,088 - INFO - joeynmt.training - Epoch  92, Step:    67200, Batch Loss:     1.377435, Tokens per Sec:    14366, Lr: 0.000300\n","2021-09-20 10:22:23,583 - INFO - joeynmt.training - Epoch  92: total training loss 1000.71\n","2021-09-20 10:22:23,583 - INFO - joeynmt.training - EPOCH 93\n","2021-09-20 10:22:36,729 - INFO - joeynmt.training - Epoch  93, Step:    67300, Batch Loss:     1.386530, Tokens per Sec:    14556, Lr: 0.000300\n","2021-09-20 10:22:50,341 - INFO - joeynmt.training - Epoch  93, Step:    67400, Batch Loss:     1.292952, Tokens per Sec:    14626, Lr: 0.000300\n","2021-09-20 10:23:03,900 - INFO - joeynmt.training - Epoch  93, Step:    67500, Batch Loss:     1.356060, Tokens per Sec:    14393, Lr: 0.000300\n","2021-09-20 10:23:17,504 - INFO - joeynmt.training - Epoch  93, Step:    67600, Batch Loss:     1.417495, Tokens per Sec:    14540, Lr: 0.000300\n","2021-09-20 10:23:31,219 - INFO - joeynmt.training - Epoch  93, Step:    67700, Batch Loss:     1.354186, Tokens per Sec:    14502, Lr: 0.000300\n","2021-09-20 10:23:44,922 - INFO - joeynmt.training - Epoch  93, Step:    67800, Batch Loss:     1.331645, Tokens per Sec:    14332, Lr: 0.000300\n","2021-09-20 10:23:58,716 - INFO - joeynmt.training - Epoch  93, Step:    67900, Batch Loss:     1.540144, Tokens per Sec:    14261, Lr: 0.000300\n","2021-09-20 10:24:03,296 - INFO - joeynmt.training - Epoch  93: total training loss 998.53\n","2021-09-20 10:24:03,296 - INFO - joeynmt.training - EPOCH 94\n","2021-09-20 10:24:12,268 - INFO - joeynmt.training - Epoch  94, Step:    68000, Batch Loss:     1.333797, Tokens per Sec:    14539, Lr: 0.000300\n","2021-09-20 10:24:20,404 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:24:20,405 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:24:20,405 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:24:20,410 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 10:24:20,771 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/65000.ckpt\n","2021-09-20 10:24:20,792 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:24:20,793 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:24:20,793 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:24:20,793 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of one year 2018-19 .\n","2021-09-20 10:24:20,793 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:24:20,793 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:24:20,793 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:24:20,794 - INFO - joeynmt.training - \tHypothesis: These exams are trying to be realized that we are not going to say that our pace is not just because of our pace , and our pace is not just that they are indeed .\n","2021-09-20 10:24:20,794 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:24:20,794 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:24:20,794 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:24:20,794 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in Human Resource Development .\n","2021-09-20 10:24:20,794 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:24:20,794 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:24:20,795 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:24:20,795 - INFO - joeynmt.training - \tHypothesis: I also thank him for showing them the valuable part of our heritage .\n","2021-09-20 10:24:20,795 - INFO - joeynmt.training - Validation result (greedy) at epoch  94, step    68000: bleu:  28.66, loss: 24552.1055, ppl:   5.0384, duration: 8.5263s\n","2021-09-20 10:24:34,526 - INFO - joeynmt.training - Epoch  94, Step:    68100, Batch Loss:     1.288510, Tokens per Sec:    14360, Lr: 0.000300\n","2021-09-20 10:24:48,155 - INFO - joeynmt.training - Epoch  94, Step:    68200, Batch Loss:     1.232616, Tokens per Sec:    14507, Lr: 0.000300\n","2021-09-20 10:25:01,768 - INFO - joeynmt.training - Epoch  94, Step:    68300, Batch Loss:     1.241702, Tokens per Sec:    14581, Lr: 0.000300\n","2021-09-20 10:25:15,461 - INFO - joeynmt.training - Epoch  94, Step:    68400, Batch Loss:     1.432490, Tokens per Sec:    14463, Lr: 0.000300\n","2021-09-20 10:25:29,146 - INFO - joeynmt.training - Epoch  94, Step:    68500, Batch Loss:     1.376918, Tokens per Sec:    14454, Lr: 0.000300\n","2021-09-20 10:25:42,909 - INFO - joeynmt.training - Epoch  94, Step:    68600, Batch Loss:     1.301812, Tokens per Sec:    14225, Lr: 0.000300\n","2021-09-20 10:25:51,634 - INFO - joeynmt.training - Epoch  94: total training loss 994.17\n","2021-09-20 10:25:51,635 - INFO - joeynmt.training - EPOCH 95\n","2021-09-20 10:25:56,541 - INFO - joeynmt.training - Epoch  95, Step:    68700, Batch Loss:     1.294099, Tokens per Sec:    14157, Lr: 0.000300\n","2021-09-20 10:26:10,155 - INFO - joeynmt.training - Epoch  95, Step:    68800, Batch Loss:     1.410615, Tokens per Sec:    14465, Lr: 0.000300\n","2021-09-20 10:26:23,840 - INFO - joeynmt.training - Epoch  95, Step:    68900, Batch Loss:     1.375866, Tokens per Sec:    14464, Lr: 0.000300\n","2021-09-20 10:26:37,506 - INFO - joeynmt.training - Epoch  95, Step:    69000, Batch Loss:     1.305976, Tokens per Sec:    14467, Lr: 0.000300\n","2021-09-20 10:26:45,998 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:26:45,998 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:26:45,998 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:26:46,004 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 10:26:46,355 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/62000.ckpt\n","2021-09-20 10:26:46,374 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:26:46,374 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:26:46,374 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:26:46,374 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of one year 2018-19 .\n","2021-09-20 10:26:46,374 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:26:46,375 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:26:46,375 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:26:46,375 - INFO - joeynmt.training - \tHypothesis: These exams are being trying to ensure that we are not going to say that it is not just a scenario and our pace is not just that it is not just a reflection .\n","2021-09-20 10:26:46,375 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:26:46,375 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:26:46,375 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:26:46,375 - INFO - joeynmt.training - \tHypothesis: 4 . To establish programmes for cooperation in Human Resource Development .\n","2021-09-20 10:26:46,375 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:26:46,375 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:26:46,375 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:26:46,375 - INFO - joeynmt.training - \tHypothesis: I also thank him for showing them the valuable part of our heritage .\n","2021-09-20 10:26:46,376 - INFO - joeynmt.training - Validation result (greedy) at epoch  95, step    69000: bleu:  28.91, loss: 24510.7188, ppl:   5.0246, duration: 8.8687s\n","2021-09-20 10:26:59,995 - INFO - joeynmt.training - Epoch  95, Step:    69100, Batch Loss:     1.306334, Tokens per Sec:    14579, Lr: 0.000300\n","2021-09-20 10:27:13,558 - INFO - joeynmt.training - Epoch  95, Step:    69200, Batch Loss:     1.349767, Tokens per Sec:    14541, Lr: 0.000300\n","2021-09-20 10:27:26,986 - INFO - joeynmt.training - Epoch  95, Step:    69300, Batch Loss:     1.345085, Tokens per Sec:    14766, Lr: 0.000300\n","2021-09-20 10:27:39,837 - INFO - joeynmt.training - Epoch  95: total training loss 991.46\n","2021-09-20 10:27:39,838 - INFO - joeynmt.training - EPOCH 96\n","2021-09-20 10:27:40,584 - INFO - joeynmt.training - Epoch  96, Step:    69400, Batch Loss:     1.391933, Tokens per Sec:    13222, Lr: 0.000300\n","2021-09-20 10:27:54,235 - INFO - joeynmt.training - Epoch  96, Step:    69500, Batch Loss:     1.400705, Tokens per Sec:    14433, Lr: 0.000300\n","2021-09-20 10:28:07,907 - INFO - joeynmt.training - Epoch  96, Step:    69600, Batch Loss:     1.293317, Tokens per Sec:    14459, Lr: 0.000300\n","2021-09-20 10:28:21,456 - INFO - joeynmt.training - Epoch  96, Step:    69700, Batch Loss:     1.419263, Tokens per Sec:    14501, Lr: 0.000300\n","2021-09-20 10:28:34,979 - INFO - joeynmt.training - Epoch  96, Step:    69800, Batch Loss:     1.308608, Tokens per Sec:    14644, Lr: 0.000300\n","2021-09-20 10:28:48,502 - INFO - joeynmt.training - Epoch  96, Step:    69900, Batch Loss:     1.285858, Tokens per Sec:    14671, Lr: 0.000300\n","2021-09-20 10:29:01,995 - INFO - joeynmt.training - Epoch  96, Step:    70000, Batch Loss:     1.312663, Tokens per Sec:    14609, Lr: 0.000300\n","2021-09-20 10:29:09,185 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:29:09,186 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:29:09,186 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:29:09,191 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 10:29:09,543 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/67000.ckpt\n","2021-09-20 10:29:09,563 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:29:09,563 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:29:09,564 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:29:09,564 - INFO - joeynmt.training - \tHypothesis: The amount of Rs. 143.604 crore will be required for a period of a year 2018-19 .\n","2021-09-20 10:29:09,564 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:29:09,564 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:29:09,564 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:29:09,564 - INFO - joeynmt.training - \tHypothesis: These exams are trying to be realized that we are not going to say that our pace is not just going to be realized , but it is not just a reflection of its pace .\n","2021-09-20 10:29:09,564 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:29:09,565 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:29:09,565 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:29:09,565 - INFO - joeynmt.training - \tHypothesis: . To establish exchange programmes for cooperation in Human Resource Development .\n","2021-09-20 10:29:09,565 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:29:09,565 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:29:09,565 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:29:09,565 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing them the valuable part of our heritage .\n","2021-09-20 10:29:09,565 - INFO - joeynmt.training - Validation result (greedy) at epoch  96, step    70000: bleu:  28.70, loss: 24492.0332, ppl:   5.0185, duration: 7.5702s\n","2021-09-20 10:29:23,224 - INFO - joeynmt.training - Epoch  96, Step:    70100, Batch Loss:     1.376281, Tokens per Sec:    14434, Lr: 0.000300\n","2021-09-20 10:29:26,645 - INFO - joeynmt.training - Epoch  96: total training loss 989.23\n","2021-09-20 10:29:26,646 - INFO - joeynmt.training - EPOCH 97\n","2021-09-20 10:29:36,921 - INFO - joeynmt.training - Epoch  97, Step:    70200, Batch Loss:     1.439234, Tokens per Sec:    14236, Lr: 0.000300\n","2021-09-20 10:29:50,337 - INFO - joeynmt.training - Epoch  97, Step:    70300, Batch Loss:     1.381584, Tokens per Sec:    14822, Lr: 0.000300\n","2021-09-20 10:30:03,914 - INFO - joeynmt.training - Epoch  97, Step:    70400, Batch Loss:     1.437023, Tokens per Sec:    14561, Lr: 0.000300\n","2021-09-20 10:30:17,438 - INFO - joeynmt.training - Epoch  97, Step:    70500, Batch Loss:     1.470219, Tokens per Sec:    14635, Lr: 0.000300\n","2021-09-20 10:30:31,131 - INFO - joeynmt.training - Epoch  97, Step:    70600, Batch Loss:     1.451849, Tokens per Sec:    14483, Lr: 0.000300\n","2021-09-20 10:30:44,491 - INFO - joeynmt.training - Epoch  97, Step:    70700, Batch Loss:     1.340219, Tokens per Sec:    14890, Lr: 0.000300\n","2021-09-20 10:30:57,751 - INFO - joeynmt.training - Epoch  97, Step:    70800, Batch Loss:     1.405432, Tokens per Sec:    14856, Lr: 0.000300\n","2021-09-20 10:31:05,052 - INFO - joeynmt.training - Epoch  97: total training loss 984.80\n","2021-09-20 10:31:05,053 - INFO - joeynmt.training - EPOCH 98\n","2021-09-20 10:31:11,240 - INFO - joeynmt.training - Epoch  98, Step:    70900, Batch Loss:     1.298091, Tokens per Sec:    14409, Lr: 0.000300\n","2021-09-20 10:31:24,589 - INFO - joeynmt.training - Epoch  98, Step:    71000, Batch Loss:     1.241604, Tokens per Sec:    14805, Lr: 0.000300\n","2021-09-20 10:31:32,380 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:31:32,380 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:31:32,380 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:31:32,385 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:31:32,385 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:31:32,385 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:31:32,385 - INFO - joeynmt.training - \tHypothesis: During 2018-19 , an amount of Rs. 143.604 crore will be required for a period of one year period .\n","2021-09-20 10:31:32,386 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:31:32,386 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:31:32,386 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:31:32,386 - INFO - joeynmt.training - \tHypothesis: These exams are being trying to ensure that we are not going to be able to say that our pace is not just a sluck , it is our pace .\n","2021-09-20 10:31:32,386 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:31:32,386 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:31:32,386 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:31:32,386 - INFO - joeynmt.training - \tHypothesis: 4 . To establish exchange of programmes for cooperation in Human Resource Development .\n","2021-09-20 10:31:32,386 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:31:32,386 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:31:32,387 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:31:32,387 - INFO - joeynmt.training - \tHypothesis: I also thank them for showing their valuable part of our heritage .\n","2021-09-20 10:31:32,387 - INFO - joeynmt.training - Validation result (greedy) at epoch  98, step    71000: bleu:  28.74, loss: 24626.4863, ppl:   5.0631, duration: 7.7976s\n","2021-09-20 10:31:45,738 - INFO - joeynmt.training - Epoch  98, Step:    71100, Batch Loss:     1.268817, Tokens per Sec:    14795, Lr: 0.000300\n","2021-09-20 10:31:59,014 - INFO - joeynmt.training - Epoch  98, Step:    71200, Batch Loss:     1.363424, Tokens per Sec:    14722, Lr: 0.000300\n","2021-09-20 10:32:12,282 - INFO - joeynmt.training - Epoch  98, Step:    71300, Batch Loss:     1.423182, Tokens per Sec:    14896, Lr: 0.000300\n","2021-09-20 10:32:25,670 - INFO - joeynmt.training - Epoch  98, Step:    71400, Batch Loss:     1.253279, Tokens per Sec:    14928, Lr: 0.000300\n","2021-09-20 10:32:39,223 - INFO - joeynmt.training - Epoch  98, Step:    71500, Batch Loss:     1.318596, Tokens per Sec:    14561, Lr: 0.000300\n","2021-09-20 10:32:50,820 - INFO - joeynmt.training - Epoch  98: total training loss 986.13\n","2021-09-20 10:32:50,820 - INFO - joeynmt.training - EPOCH 99\n","2021-09-20 10:32:52,773 - INFO - joeynmt.training - Epoch  99, Step:    71600, Batch Loss:     1.391761, Tokens per Sec:    14133, Lr: 0.000300\n","2021-09-20 10:33:06,105 - INFO - joeynmt.training - Epoch  99, Step:    71700, Batch Loss:     1.396579, Tokens per Sec:    14863, Lr: 0.000300\n","2021-09-20 10:33:19,621 - INFO - joeynmt.training - Epoch  99, Step:    71800, Batch Loss:     1.483048, Tokens per Sec:    14622, Lr: 0.000300\n","2021-09-20 10:33:33,046 - INFO - joeynmt.training - Epoch  99, Step:    71900, Batch Loss:     1.290344, Tokens per Sec:    14710, Lr: 0.000300\n","2021-09-20 10:33:46,331 - INFO - joeynmt.training - Epoch  99, Step:    72000, Batch Loss:     1.256447, Tokens per Sec:    14973, Lr: 0.000300\n","2021-09-20 10:33:53,991 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:33:53,991 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:33:53,991 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:33:53,998 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:33:53,998 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:33:53,998 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:33:53,998 - INFO - joeynmt.training - \tHypothesis: During 2018-19 , a sum of Rs. 143.604 crore will be required for a period of one year .\n","2021-09-20 10:33:53,998 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:33:53,999 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:33:53,999 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:33:53,999 - INFO - joeynmt.training - \tHypothesis: These exams are being trying to be realized that we are not going to say that our pace is not just because of it is not just a single instalment .\n","2021-09-20 10:33:53,999 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:33:53,999 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:33:53,999 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:33:53,999 - INFO - joeynmt.training - \tHypothesis: . To establish programmes for cooperation in human resource development .\n","2021-09-20 10:33:53,999 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:33:53,999 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:33:54,000 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:33:54,000 - INFO - joeynmt.training - \tHypothesis: I also thank him for showing the valuable part of our heritage .\n","2021-09-20 10:33:54,000 - INFO - joeynmt.training - Validation result (greedy) at epoch  99, step    72000: bleu:  28.83, loss: 24574.1172, ppl:   5.0457, duration: 7.6684s\n","2021-09-20 10:34:07,351 - INFO - joeynmt.training - Epoch  99, Step:    72100, Batch Loss:     1.259106, Tokens per Sec:    14783, Lr: 0.000300\n","2021-09-20 10:34:20,580 - INFO - joeynmt.training - Epoch  99, Step:    72200, Batch Loss:     1.297808, Tokens per Sec:    14948, Lr: 0.000300\n","2021-09-20 10:34:33,935 - INFO - joeynmt.training - Epoch  99, Step:    72300, Batch Loss:     1.288615, Tokens per Sec:    14703, Lr: 0.000300\n","2021-09-20 10:34:36,046 - INFO - joeynmt.training - Epoch  99: total training loss 980.87\n","2021-09-20 10:34:36,046 - INFO - joeynmt.training - EPOCH 100\n","2021-09-20 10:34:47,496 - INFO - joeynmt.training - Epoch 100, Step:    72400, Batch Loss:     1.293599, Tokens per Sec:    14514, Lr: 0.000300\n","2021-09-20 10:35:00,874 - INFO - joeynmt.training - Epoch 100, Step:    72500, Batch Loss:     1.365859, Tokens per Sec:    14881, Lr: 0.000300\n","2021-09-20 10:35:14,326 - INFO - joeynmt.training - Epoch 100, Step:    72600, Batch Loss:     1.277848, Tokens per Sec:    14683, Lr: 0.000300\n","2021-09-20 10:35:27,744 - INFO - joeynmt.training - Epoch 100, Step:    72700, Batch Loss:     1.256096, Tokens per Sec:    14856, Lr: 0.000300\n","2021-09-20 10:35:41,012 - INFO - joeynmt.training - Epoch 100, Step:    72800, Batch Loss:     1.383632, Tokens per Sec:    14707, Lr: 0.000300\n","2021-09-20 10:35:54,457 - INFO - joeynmt.training - Epoch 100, Step:    72900, Batch Loss:     1.335228, Tokens per Sec:    14786, Lr: 0.000300\n","2021-09-20 10:36:07,714 - INFO - joeynmt.training - Epoch 100, Step:    73000, Batch Loss:     1.479517, Tokens per Sec:    14884, Lr: 0.000300\n","2021-09-20 10:36:15,966 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:36:15,967 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:36:15,967 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:36:15,972 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n","2021-09-20 10:36:16,332 - INFO - joeynmt.helpers - delete models/hien_transformer_pmi_nhs_backtranslate/68000.ckpt\n","2021-09-20 10:36:16,351 - INFO - joeynmt.training - Example #0\n","2021-09-20 10:36:16,351 - INFO - joeynmt.training - \tSource:     2018 - 19 के दौरान एक वर्ष की अवधि के लिए 143.604 करोड़ रुपये की राशि की आवश्यकता होगी ।\n","2021-09-20 10:36:16,351 - INFO - joeynmt.training - \tReference:  An amount of Rs.143.604 crore will be required for the period of one year during 2018-19 .\n","2021-09-20 10:36:16,351 - INFO - joeynmt.training - \tHypothesis: The requirement of Rs. 143.604 crore for a period of a year 2018-19 will be required .\n","2021-09-20 10:36:16,351 - INFO - joeynmt.training - Example #1\n","2021-09-20 10:36:16,352 - INFO - joeynmt.training - \tSource:     ये परीक्षाएँ , वो तो हम सही जा रहे हैं कि नहीं जा रहे , उसका हिसाब - किताब करती हैं हमारी गति ठीक है कि नहीं है , उसका हिसाब - किताब करती हैं ।\n","2021-09-20 10:36:16,352 - INFO - joeynmt.training - \tReference:  Exams are there to only gauge whether we are going the right way or not , whether we are moving at the right speed or not .\n","2021-09-20 10:36:16,352 - INFO - joeynmt.training - \tHypothesis: These exams are going to be right that we are not going to say that our pace is not just to be silos , but it is not a single instalment .\n","2021-09-20 10:36:16,352 - INFO - joeynmt.training - Example #2\n","2021-09-20 10:36:16,352 - INFO - joeynmt.training - \tSource:     4 मानव संसाधन विकास में सहयोग के लिए कार्यक्रमों का आदान - प्रदान स्थापित करना ।\n","2021-09-20 10:36:16,352 - INFO - joeynmt.training - \tReference:  . Establishing exchange of programmes for cooperation in Human Resources Development .\n","2021-09-20 10:36:16,352 - INFO - joeynmt.training - \tHypothesis: . To establish programmes for cooperation in Human Resource Development .\n","2021-09-20 10:36:16,353 - INFO - joeynmt.training - Example #3\n","2021-09-20 10:36:16,353 - INFO - joeynmt.training - \tSource:     मैं उन्हें हमारी विरासत के बहुमूल्य हिस्से को दिखाने के लिए भी धन्यवाद देता हूं ।\n","2021-09-20 10:36:16,353 - INFO - joeynmt.training - \tReference:  I also thank him for returning to us a precious piece of our heritage .\n","2021-09-20 10:36:16,353 - INFO - joeynmt.training - \tHypothesis: I also thank him for showing the valuable part of our heritage .\n","2021-09-20 10:36:16,353 - INFO - joeynmt.training - Validation result (greedy) at epoch 100, step    73000: bleu:  29.17, loss: 24394.4531, ppl:   4.9863, duration: 8.6384s\n","2021-09-20 10:36:22,544 - INFO - joeynmt.training - Epoch 100: total training loss 979.31\n","2021-09-20 10:36:22,545 - INFO - joeynmt.training - Training ended after 100 epochs.\n","2021-09-20 10:36:22,545 - INFO - joeynmt.training - Best validation result (greedy) at step    73000:   4.99 ppl.\n","2021-09-20 10:36:22,567 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 1, batch_size per device: 3600\n","2021-09-20 10:36:22,567 - INFO - joeynmt.prediction - Loading model from models/hien_transformer_pmi_nhs_backtranslate/73000.ckpt\n","2021-09-20 10:36:22,771 - INFO - joeynmt.model - Building an encoder-decoder model...\n","2021-09-20 10:36:23,002 - INFO - joeynmt.model - Enc-dec model built.\n","2021-09-20 10:36:23,072 - INFO - joeynmt.prediction - Decoding on dev set (data/hien/dev.bpe.en)...\n","2021-09-20 10:36:36,060 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:36:36,061 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:36:36,061 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:36:36,065 - INFO - joeynmt.prediction -  dev bleu[13a]:  30.14 [Beam search decoding with beam size = 5 and alpha = 1.0]\n","2021-09-20 10:36:36,066 - INFO - joeynmt.prediction - Translations saved to: models/hien_transformer_pmi_nhs_backtranslate/00073000.hyps.dev\n","2021-09-20 10:36:36,066 - INFO - joeynmt.prediction - Decoding on test set (data/hien/test.bpe.en)...\n","2021-09-20 10:36:47,927 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:36:47,927 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:36:47,927 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:36:47,932 - INFO - joeynmt.prediction - test bleu[13a]:   8.22 [Beam search decoding with beam size = 5 and alpha = 1.0]\n","2021-09-20 10:36:47,933 - INFO - joeynmt.prediction - Translations saved to: models/hien_transformer_pmi_nhs_backtranslate/00073000.hyps.test\n"]}]},{"cell_type":"code","metadata":{"id":"TOT3wXKs6O0v"},"source":["copy_model_to = \"/content/drive/MyDrive/DA/model_\" + tag + \"_100epochs_new\"\n","!mkdir -p $copy_model_to\n","os.environ[\"copy_model_to\"] = copy_model_to\n","\n","!cp -R /content/joeynmt/models/hien_transformer_pmi_nhs_backtranslate/ $copy_model_to"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0nZ-u0Gk7SyP","executionInfo":{"status":"ok","timestamp":1632135421650,"user_tz":-60,"elapsed":319,"user":{"displayName":"prathyusha emilya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5IYFecnx3cxca5vOVpF0DuHxaxAztIW-WIhNSRA=s64","userId":"01406194847381075901"}},"outputId":"63f270a4-0076-43d6-827d-1c9f74e88c8b"},"source":["# Output our validation accuracy\n","! cat \"/content/joeynmt/models/hien_transformer_pmi_nhs_backtranslate/validations.txt\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Steps: 1000\tLoss: 64276.76562\tPPL: 68.95605\tbleu: 2.79564\tLR: 0.00030000\t*\n","Steps: 2000\tLoss: 55564.67969\tPPL: 38.84829\tbleu: 3.91061\tLR: 0.00030000\t*\n","Steps: 3000\tLoss: 49832.80078\tPPL: 26.63283\tbleu: 6.70130\tLR: 0.00030000\t*\n","Steps: 4000\tLoss: 46200.20703\tPPL: 20.96576\tbleu: 9.25595\tLR: 0.00030000\t*\n","Steps: 5000\tLoss: 43347.49219\tPPL: 17.37447\tbleu: 10.83246\tLR: 0.00030000\t*\n","Steps: 6000\tLoss: 41301.51172\tPPL: 15.18408\tbleu: 11.52533\tLR: 0.00030000\t*\n","Steps: 7000\tLoss: 39700.00781\tPPL: 13.66403\tbleu: 13.73440\tLR: 0.00030000\t*\n","Steps: 8000\tLoss: 37927.91797\tPPL: 12.15878\tbleu: 14.03402\tLR: 0.00030000\t*\n","Steps: 9000\tLoss: 36775.52734\tPPL: 11.27008\tbleu: 15.08603\tLR: 0.00030000\t*\n","Steps: 10000\tLoss: 35372.87109\tPPL: 10.27556\tbleu: 16.80411\tLR: 0.00030000\t*\n","Steps: 11000\tLoss: 34592.82031\tPPL: 9.76097\tbleu: 17.81658\tLR: 0.00030000\t*\n","Steps: 12000\tLoss: 33810.75391\tPPL: 9.27092\tbleu: 18.71653\tLR: 0.00030000\t*\n","Steps: 13000\tLoss: 32919.25391\tPPL: 8.74223\tbleu: 19.34017\tLR: 0.00030000\t*\n","Steps: 14000\tLoss: 32132.45312\tPPL: 8.30074\tbleu: 20.13454\tLR: 0.00030000\t*\n","Steps: 15000\tLoss: 31521.75195\tPPL: 7.97348\tbleu: 21.04886\tLR: 0.00030000\t*\n","Steps: 16000\tLoss: 30931.33984\tPPL: 7.66938\tbleu: 21.38340\tLR: 0.00030000\t*\n","Steps: 17000\tLoss: 30741.55078\tPPL: 7.57410\tbleu: 21.46838\tLR: 0.00030000\t*\n","Steps: 18000\tLoss: 29987.39453\tPPL: 7.20708\tbleu: 21.60627\tLR: 0.00030000\t*\n","Steps: 19000\tLoss: 29567.75781\tPPL: 7.01061\tbleu: 22.73439\tLR: 0.00030000\t*\n","Steps: 20000\tLoss: 29192.87695\tPPL: 6.83964\tbleu: 22.83968\tLR: 0.00030000\t*\n","Steps: 21000\tLoss: 28989.10547\tPPL: 6.74846\tbleu: 23.03821\tLR: 0.00030000\t*\n","Steps: 22000\tLoss: 28722.67188\tPPL: 6.63106\tbleu: 23.59841\tLR: 0.00030000\t*\n","Steps: 23000\tLoss: 28387.77734\tPPL: 6.48640\tbleu: 23.84540\tLR: 0.00030000\t*\n","Steps: 24000\tLoss: 28137.90234\tPPL: 6.38053\tbleu: 24.38742\tLR: 0.00030000\t*\n","Steps: 25000\tLoss: 27878.57227\tPPL: 6.27247\tbleu: 24.12212\tLR: 0.00030000\t*\n","Steps: 26000\tLoss: 27803.89062\tPPL: 6.24169\tbleu: 24.56712\tLR: 0.00030000\t*\n","Steps: 27000\tLoss: 27398.69141\tPPL: 6.07732\tbleu: 25.00611\tLR: 0.00030000\t*\n","Steps: 28000\tLoss: 27371.80469\tPPL: 6.06657\tbleu: 25.24067\tLR: 0.00030000\t*\n","Steps: 29000\tLoss: 27071.52930\tPPL: 5.94777\tbleu: 25.60932\tLR: 0.00030000\t*\n","Steps: 30000\tLoss: 27100.87305\tPPL: 5.95927\tbleu: 24.96185\tLR: 0.00030000\t\n","Steps: 31000\tLoss: 26678.37500\tPPL: 5.79573\tbleu: 25.54315\tLR: 0.00030000\t*\n","Steps: 32000\tLoss: 26651.72852\tPPL: 5.78557\tbleu: 26.02329\tLR: 0.00030000\t*\n","Steps: 33000\tLoss: 26613.23828\tPPL: 5.77092\tbleu: 26.05766\tLR: 0.00030000\t*\n","Steps: 34000\tLoss: 26382.21680\tPPL: 5.68377\tbleu: 25.93196\tLR: 0.00030000\t*\n","Steps: 35000\tLoss: 26256.51758\tPPL: 5.63691\tbleu: 26.22124\tLR: 0.00030000\t*\n","Steps: 36000\tLoss: 26121.78711\tPPL: 5.58711\tbleu: 26.00050\tLR: 0.00030000\t*\n","Steps: 37000\tLoss: 26016.49609\tPPL: 5.54850\tbleu: 26.61641\tLR: 0.00030000\t*\n","Steps: 38000\tLoss: 25928.65625\tPPL: 5.51650\tbleu: 26.74005\tLR: 0.00030000\t*\n","Steps: 39000\tLoss: 25955.60547\tPPL: 5.52630\tbleu: 26.65574\tLR: 0.00030000\t\n","Steps: 40000\tLoss: 25849.69922\tPPL: 5.48788\tbleu: 27.19861\tLR: 0.00030000\t*\n","Steps: 41000\tLoss: 25907.02344\tPPL: 5.50864\tbleu: 27.06086\tLR: 0.00030000\t\n","Steps: 42000\tLoss: 25734.43750\tPPL: 5.44638\tbleu: 26.68696\tLR: 0.00030000\t*\n","Steps: 43000\tLoss: 25518.43555\tPPL: 5.36944\tbleu: 27.85252\tLR: 0.00030000\t*\n","Steps: 44000\tLoss: 25658.58203\tPPL: 5.41924\tbleu: 27.42309\tLR: 0.00030000\t\n","Steps: 45000\tLoss: 25422.83398\tPPL: 5.33574\tbleu: 27.22859\tLR: 0.00030000\t*\n","Steps: 46000\tLoss: 25322.73828\tPPL: 5.30068\tbleu: 27.88312\tLR: 0.00030000\t*\n","Steps: 47000\tLoss: 25410.26367\tPPL: 5.33132\tbleu: 27.94028\tLR: 0.00030000\t\n","Steps: 48000\tLoss: 25322.86719\tPPL: 5.30072\tbleu: 27.34054\tLR: 0.00030000\t\n","Steps: 49000\tLoss: 25394.75000\tPPL: 5.32588\tbleu: 27.68427\tLR: 0.00030000\t\n","Steps: 50000\tLoss: 25182.20312\tPPL: 5.25184\tbleu: 27.58242\tLR: 0.00030000\t*\n","Steps: 51000\tLoss: 25076.16797\tPPL: 5.21529\tbleu: 27.57323\tLR: 0.00030000\t*\n","Steps: 52000\tLoss: 24957.47852\tPPL: 5.17468\tbleu: 28.37610\tLR: 0.00030000\t*\n","Steps: 53000\tLoss: 25048.78125\tPPL: 5.20589\tbleu: 27.79326\tLR: 0.00030000\t\n","Steps: 54000\tLoss: 25048.21875\tPPL: 5.20570\tbleu: 28.00708\tLR: 0.00030000\t\n","Steps: 55000\tLoss: 25057.11719\tPPL: 5.20875\tbleu: 28.46212\tLR: 0.00030000\t\n","Steps: 56000\tLoss: 24881.93750\tPPL: 5.14900\tbleu: 27.69491\tLR: 0.00030000\t*\n","Steps: 57000\tLoss: 24763.32227\tPPL: 5.10893\tbleu: 28.37289\tLR: 0.00030000\t*\n","Steps: 58000\tLoss: 24829.18945\tPPL: 5.13114\tbleu: 29.00866\tLR: 0.00030000\t\n","Steps: 59000\tLoss: 24760.96680\tPPL: 5.10814\tbleu: 28.55410\tLR: 0.00030000\t*\n","Steps: 60000\tLoss: 24798.38086\tPPL: 5.12074\tbleu: 28.11050\tLR: 0.00030000\t\n","Steps: 61000\tLoss: 24700.75000\tPPL: 5.08792\tbleu: 28.51762\tLR: 0.00030000\t*\n","Steps: 62000\tLoss: 24596.39453\tPPL: 5.05307\tbleu: 28.69264\tLR: 0.00030000\t*\n","Steps: 63000\tLoss: 24720.18359\tPPL: 5.09444\tbleu: 28.64079\tLR: 0.00030000\t\n","Steps: 64000\tLoss: 24734.48438\tPPL: 5.09924\tbleu: 28.98785\tLR: 0.00030000\t\n","Steps: 65000\tLoss: 24674.37305\tPPL: 5.07909\tbleu: 28.47033\tLR: 0.00030000\t\n","Steps: 66000\tLoss: 24701.25586\tPPL: 5.08809\tbleu: 28.90531\tLR: 0.00030000\t\n","Steps: 67000\tLoss: 24578.65625\tPPL: 5.04717\tbleu: 28.96782\tLR: 0.00030000\t*\n","Steps: 68000\tLoss: 24552.10547\tPPL: 5.03835\tbleu: 28.65981\tLR: 0.00030000\t*\n","Steps: 69000\tLoss: 24510.71875\tPPL: 5.02464\tbleu: 28.91361\tLR: 0.00030000\t*\n","Steps: 70000\tLoss: 24492.03320\tPPL: 5.01846\tbleu: 28.69581\tLR: 0.00030000\t*\n","Steps: 71000\tLoss: 24626.48633\tPPL: 5.06309\tbleu: 28.74233\tLR: 0.00030000\t\n","Steps: 72000\tLoss: 24574.11719\tPPL: 5.04566\tbleu: 28.82526\tLR: 0.00030000\t\n","Steps: 73000\tLoss: 24394.45312\tPPL: 4.98631\tbleu: 29.17087\tLR: 0.00030000\t*\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CUZ24mJw8FFj","executionInfo":{"status":"ok","timestamp":1632135402708,"user_tz":-60,"elapsed":31732,"user":{"displayName":"prathyusha emilya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5IYFecnx3cxca5vOVpF0DuHxaxAztIW-WIhNSRA=s64","userId":"01406194847381075901"}},"outputId":"c42dece3-691f-47e8-fc8c-04de927f9d3c"},"source":["# Test our model\n","! cd joeynmt; python3 -m joeynmt test \"/content/joeynmt/models/hien_transformer_pmi_nhs_backtranslate/config.yaml\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-09-20 10:56:12,699 - INFO - root - Hello! This is Joey-NMT (version 1.3).\n","2021-09-20 10:56:12,700 - INFO - joeynmt.data - Building vocabulary...\n","2021-09-20 10:56:13,180 - INFO - joeynmt.data - Loading dev data...\n","2021-09-20 10:56:13,187 - INFO - joeynmt.data - Loading test data...\n","2021-09-20 10:56:13,195 - INFO - joeynmt.data - Data loaded.\n","2021-09-20 10:56:13,219 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 1, batch_size per device: 3600\n","2021-09-20 10:56:13,219 - INFO - joeynmt.prediction - Loading model from models/hien_transformer_pmi_nhs_backtranslate/best.ckpt\n","2021-09-20 10:56:16,548 - INFO - joeynmt.model - Building an encoder-decoder model...\n","2021-09-20 10:56:16,785 - INFO - joeynmt.model - Enc-dec model built.\n","2021-09-20 10:56:16,858 - INFO - joeynmt.prediction - Decoding on dev set (data/hien/dev.bpe.en)...\n","2021-09-20 10:56:30,069 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:56:30,069 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:56:30,069 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:56:30,072 - INFO - joeynmt.prediction -  dev bleu[13a]:  30.14 [Beam search decoding with beam size = 5 and alpha = 1.0]\n","2021-09-20 10:56:30,072 - INFO - joeynmt.prediction - Decoding on test set (data/hien/test.bpe.en)...\n","2021-09-20 10:56:41,954 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n","2021-09-20 10:56:41,954 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-09-20 10:56:41,955 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n","2021-09-20 10:56:41,957 - INFO - joeynmt.prediction - test bleu[13a]:   8.22 [Beam search decoding with beam size = 5 and alpha = 1.0]\n"]}]}]}